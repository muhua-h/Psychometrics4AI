{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Study 3: Multi-Model Personality Simulation (Facet-Level)\n",
    "\n",
    "This notebook simulates new participant data at runtime using facet-level parameter extraction, then runs multi-model LLM simulations.\n",
    "\n",
    "## Workflow:\n",
    "1. Load empirical data and perform reverse coding\n",
    "2. Extract facet-level parameters\n",
    "3. Simulate new participant data (200 participants)\n",
    "4. Run multi-model LLM simulations\n",
    "5. Save results for analysis\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1. Setup and Data Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T09:49:36.426545Z",
     "start_time": "2025-07-11T09:49:35.968562Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Add shared modules to path\n",
    "sys.path.append('../shared')\n",
    "\n",
    "print(\"Setup complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T09:49:36.458945Z",
     "start_time": "2025-07-11T09:49:36.436820Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded empirical data: (470, 704)\n",
      "Columns: ['case_id', 'age', 'sex', 'ethnicity', 'rel_acquaintance', 'rel_friend', 'rel_roommate', 'rel_boygirlfriend', 'rel_relative', 'rel_other']...\n"
     ]
    }
   ],
   "source": [
    "# Load the original empirical data\n",
    "empirical_data_path = Path('../../study_3/expanded_format/data.csv')\n",
    "if not empirical_data_path.exists():\n",
    "    raise FileNotFoundError(f'Empirical data not found: {empirical_data_path}')\n",
    "\n",
    "data = pd.read_csv(empirical_data_path)\n",
    "print(f'Loaded empirical data: {data.shape}')\n",
    "print(f'Columns: {list(data.columns)[:10]}...')  # Show first 10 columns\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. Reverse Coding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T09:49:36.509919Z",
     "start_time": "2025-07-11T09:49:36.496923Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reverse coding applied successfully\n"
     ]
    }
   ],
   "source": [
    "# Reverse coding mapping\n",
    "reverse_coding_map = {\n",
    "    'bfi1': 'reversed_bfi1', 'bfi2': 'reversed_bfi2', 'bfi3R': 'reversed_bfi3', 'bfi4R': 'reversed_bfi4',\n",
    "    'bfi5R': 'reversed_bfi5', 'bfi6': 'reversed_bfi6', 'bfi7': 'reversed_bfi7', 'bfi8R': 'reversed_bfi8',\n",
    "    'bfi9R': 'reversed_bfi9', 'bfi10': 'reversed_bfi10', 'bfi11R': 'reversed_bfi11', 'bfi12R': 'reversed_bfi12',\n",
    "    'bfi13': 'reversed_bfi13', 'bfi14': 'reversed_bfi14', 'bfi15': 'reversed_bfi15', 'bfi16R': 'reversed_bfi16',\n",
    "    'bfi17R': 'reversed_bfi17', 'bfi18': 'reversed_bfi18', 'bfi19': 'reversed_bfi19', 'bfi20': 'reversed_bfi20',\n",
    "    'bfi21': 'reversed_bfi21', 'bfi22R': 'reversed_bfi22', 'bfi23R': 'reversed_bfi23', 'bfi24R': 'reversed_bfi24',\n",
    "    'bfi25R': 'reversed_bfi25', 'bfi26R': 'reversed_bfi26', 'bfi27': 'reversed_bfi27', 'bfi28R': 'reversed_bfi28',\n",
    "    'bfi29R': 'reversed_bfi29', 'bfi30R': 'reversed_bfi30', 'bfi31R': 'reversed_bfi31', 'bfi32': 'reversed_bfi32',\n",
    "    'bfi33': 'reversed_bfi33', 'bfi34': 'reversed_bfi34', 'bfi35': 'reversed_bfi35', 'bfi36R': 'reversed_bfi36',\n",
    "    'bfi37R': 'reversed_bfi37', 'bfi38': 'reversed_bfi38', 'bfi39': 'reversed_bfi39', 'bfi40': 'reversed_bfi40',\n",
    "    'bfi41': 'reversed_bfi41', 'bfi42R': 'reversed_bfi42', 'bfi43': 'reversed_bfi43', 'bfi44R': 'reversed_bfi44',\n",
    "    'bfi45R': 'reversed_bfi45', 'bfi46': 'reversed_bfi46', 'bfi47R': 'reversed_bfi47', 'bfi48R': 'reversed_bfi48',\n",
    "    'bfi49R': 'reversed_bfi49', 'bfi50R': 'reversed_bfi50', 'bfi51R': 'reversed_bfi51', 'bfi52': 'reversed_bfi52',\n",
    "    'bfi53': 'reversed_bfi53', 'bfi54': 'reversed_bfi54', 'bfi55R': 'reversed_bfi55', 'bfi56': 'reversed_bfi56',\n",
    "    'bfi57': 'reversed_bfi57', 'bfi58R': 'reversed_bfi58', 'bfi59': 'reversed_bfi59', 'bfi60': 'reversed_bfi60'\n",
    "}\n",
    "\n",
    "# Apply reverse coding\n",
    "for original, reversed_var in reverse_coding_map.items():\n",
    "    if original.endswith('R'):\n",
    "        data[reversed_var] = 6 - data[original[:-1]]\n",
    "    else:\n",
    "        data[reversed_var] = data[original]\n",
    "\n",
    "print(\"Reverse coding applied successfully\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. Helper Functions for Parameter Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T09:49:36.526194Z",
     "start_time": "2025-07-11T09:49:36.522768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined\n"
     ]
    }
   ],
   "source": [
    "def domain_stats(df, domain_prefix):\n",
    "    \"\"\"Compute mean and standard deviation for domain facets.\"\"\"\n",
    "    filtered_columns = [col for col in df.columns if col.startswith(domain_prefix)]\n",
    "    domain_df = df[filtered_columns]\n",
    "    means = domain_df.mean()\n",
    "    std_devs = domain_df.std()\n",
    "    result_df = pd.DataFrame([means, std_devs], index=[\"Mean\", \"Standard Deviation\"])\n",
    "    return result_df\n",
    "\n",
    "def domain_correlation(df, domain_prefix):\n",
    "    \"\"\"Compute correlation matrix for domain facets.\"\"\"\n",
    "    filtered_columns = [col for col in df.columns if col.startswith(domain_prefix)]\n",
    "    filtered_columns = filtered_columns[:3]  # Take first 3 facets\n",
    "    domain_df = df[filtered_columns]\n",
    "    correlation_matrix = domain_df.corr()\n",
    "    return correlation_matrix.iloc[:3, :3]\n",
    "\n",
    "def average_correlation(items):\n",
    "    \"\"\"Calculate average correlation within a facet.\"\"\"\n",
    "    subset = data[items]\n",
    "    corr_matrix = subset.corr()\n",
    "    correlations = corr_matrix.values[np.triu_indices_from(corr_matrix, k=1)]\n",
    "    return np.mean(correlations)\n",
    "\n",
    "print(\"Helper functions defined\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. Calculate Domain Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T09:49:36.551805Z",
     "start_time": "2025-07-11T09:49:36.543676Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average domain correlation: 0.442\n",
      "Domain correlations: {'Extraversion': 0.4610554748141877, 'Agreeableness': 0.3821996228465807, 'Conscientiousness': 0.40613896396510524, 'Neuroticism': 0.5055967450877641, 'Openness': 0.4570178582963769}\n"
     ]
    }
   ],
   "source": [
    "# Define domains and facets\n",
    "domains = {\n",
    "    \"Extraversion\": [['reversed_bfi1', 'reversed_bfi16', 'reversed_bfi31', 'reversed_bfi46'], \n",
    "                      ['reversed_bfi6', 'reversed_bfi21', 'reversed_bfi36', 'reversed_bfi51'], \n",
    "                      ['reversed_bfi11', 'reversed_bfi26', 'reversed_bfi41', 'reversed_bfi56']],\n",
    "    \"Agreeableness\": [['reversed_bfi2', 'reversed_bfi17', 'reversed_bfi32', 'reversed_bfi47'], \n",
    "                       ['reversed_bfi7', 'reversed_bfi22', 'reversed_bfi37', 'reversed_bfi52'], \n",
    "                       ['reversed_bfi12', 'reversed_bfi27', 'reversed_bfi42', 'reversed_bfi57']],\n",
    "    \"Conscientiousness\": [['reversed_bfi3', 'reversed_bfi18', 'reversed_bfi33', 'reversed_bfi48'], \n",
    "                           ['reversed_bfi8', 'reversed_bfi23', 'reversed_bfi38', 'reversed_bfi53'], \n",
    "                           ['reversed_bfi13', 'reversed_bfi28', 'reversed_bfi43', 'reversed_bfi58']],\n",
    "    \"Neuroticism\": [['reversed_bfi4', 'reversed_bfi19', 'reversed_bfi34', 'reversed_bfi49'], \n",
    "                     ['reversed_bfi9', 'reversed_bfi24', 'reversed_bfi39', 'reversed_bfi54'], \n",
    "                     ['reversed_bfi14', 'reversed_bfi29', 'reversed_bfi44', 'reversed_bfi59']],\n",
    "    \"Openness\": [['reversed_bfi10', 'reversed_bfi25', 'reversed_bfi40', 'reversed_bfi55'], \n",
    "                  ['reversed_bfi5', 'reversed_bfi20', 'reversed_bfi35', 'reversed_bfi50'], \n",
    "                  ['reversed_bfi15', 'reversed_bfi30', 'reversed_bfi45', 'reversed_bfi60']]\n",
    "}\n",
    "\n",
    "# Calculate average domain correlations\n",
    "domain_avg_correlations = {}\n",
    "for domain, facets in domains.items():\n",
    "    avg_corrs = [average_correlation(facet) for facet in facets]\n",
    "    domain_avg_correlations[domain] = np.mean(avg_corrs)\n",
    "\n",
    "average_domain_avg_correlations = np.mean(list(domain_avg_correlations.values()))\n",
    "print(f'Average domain correlation: {average_domain_avg_correlations:.3f}')\n",
    "print(f'Domain correlations: {domain_avg_correlations}')\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. Simulation Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T09:49:36.576185Z",
     "start_time": "2025-07-11T09:49:36.572870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation function defined\n"
     ]
    }
   ],
   "source": [
    "def simulate_item_responses(means, std_devs, corr_matrix, intra_group_corr, n_simulations):\n",
    "    \"\"\"\n",
    "    Simulate item responses based on group characteristics and correlations.\n",
    "    \"\"\"\n",
    "    num_groups = len(means)\n",
    "    num_items_per_group = 4\n",
    "    num_items = num_groups * num_items_per_group\n",
    "    \n",
    "    # Construct covariance matrix\n",
    "    cov_matrix = np.outer(std_devs, std_devs) * corr_matrix\n",
    "    \n",
    "    # Generate group-level scores\n",
    "    group_scores = np.random.multivariate_normal(means, cov_matrix, size=n_simulations)\n",
    "    \n",
    "    # Initialize item scores\n",
    "    item_scores = np.zeros((n_simulations, num_items))\n",
    "    \n",
    "    # Calculate item-level standard deviation within groups\n",
    "    item_std_dev_within_group = np.sqrt((1 - intra_group_corr) * std_devs**2)\n",
    "    \n",
    "    # Generate item scores\n",
    "    for group_index in range(num_groups):\n",
    "        start_idx = group_index * num_items_per_group\n",
    "        for i in range(num_items_per_group):\n",
    "            item_errors = np.random.normal(0, item_std_dev_within_group[group_index], n_simulations)\n",
    "            item_scores[:, start_idx + i] = group_scores[:, group_index] + item_errors\n",
    "    \n",
    "    # Bound scores to [1, 5] range\n",
    "    bounded_item_scores = np.clip(np.round(item_scores), 1, 5)\n",
    "    \n",
    "    return bounded_item_scores\n",
    "\n",
    "print(\"Simulation function defined\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 6. Generate New Simulated Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T09:49:36.608554Z",
     "start_time": "2025-07-11T09:49:36.601155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating data for each domain...\n",
      "✓ Extraversion and Agreeableness simulated\n"
     ]
    }
   ],
   "source": [
    "# Simulate data for each domain\n",
    "n_simulations = 200\n",
    "\n",
    "print(\"Simulating data for each domain...\")\n",
    "\n",
    "# Extraversion\n",
    "domain_stat_e = domain_stats(data, 'bfi2_e')\n",
    "means_e = np.array(domain_stat_e.loc['Mean'].values[:3])\n",
    "std_devs_e = np.array(domain_stat_e.loc['Standard Deviation'].values[:3])\n",
    "corr_e = domain_correlation(data, 'bfi2_e')\n",
    "sim_e = simulate_item_responses(means_e, std_devs_e, corr_e, average_domain_avg_correlations, n_simulations)\n",
    "extraversion_cols = ['bfi1', 'bfi16', 'bfi31', 'bfi46', 'bfi6', 'bfi21', 'bfi36', 'bfi51', 'bfi11', 'bfi26', 'bfi41', 'bfi56']\n",
    "sim_e_df = pd.DataFrame(sim_e, columns=extraversion_cols)\n",
    "\n",
    "# Agreeableness\n",
    "domain_stat_a = domain_stats(data, 'bfi2_a')\n",
    "means_a = np.array(domain_stat_a.loc['Mean'].values[:3])\n",
    "std_devs_a = np.array(domain_stat_a.loc['Standard Deviation'].values[:3])\n",
    "corr_a = domain_correlation(data, 'bfi2_a')\n",
    "sim_a = simulate_item_responses(means_a, std_devs_a, corr_a, average_domain_avg_correlations, n_simulations)\n",
    "agreeableness_cols = ['bfi2', 'bfi17', 'bfi32', 'bfi47', 'bfi7', 'bfi22', 'bfi37', 'bfi52', 'bfi12', 'bfi27', 'bfi42', 'bfi57']\n",
    "sim_a_df = pd.DataFrame(sim_a, columns=agreeableness_cols)\n",
    "\n",
    "print(\"✓ Extraversion and Agreeableness simulated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T09:49:36.637544Z",
     "start_time": "2025-07-11T09:49:36.627732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Conscientiousness, Neuroticism, and Openness simulated\n"
     ]
    }
   ],
   "source": [
    "# Conscientiousness\n",
    "domain_stat_c = domain_stats(data, 'bfi2_c')\n",
    "means_c = np.array(domain_stat_c.loc['Mean'].values[:3])\n",
    "std_devs_c = np.array(domain_stat_c.loc['Standard Deviation'].values[:3])\n",
    "corr_c = domain_correlation(data, 'bfi2_c')\n",
    "sim_c = simulate_item_responses(means_c, std_devs_c, corr_c, average_domain_avg_correlations, n_simulations)\n",
    "conscientiousness_cols = ['bfi3', 'bfi18', 'bfi33', 'bfi48', 'bfi8', 'bfi23', 'bfi38', 'bfi53', 'bfi13', 'bfi28', 'bfi43', 'bfi58']\n",
    "sim_c_df = pd.DataFrame(sim_c, columns=conscientiousness_cols)\n",
    "\n",
    "# Neuroticism\n",
    "domain_stat_n = domain_stats(data, 'bfi2_n')\n",
    "means_n = np.array(domain_stat_n.loc['Mean'].values[:3])\n",
    "std_devs_n = np.array(domain_stat_n.loc['Standard Deviation'].values[:3])\n",
    "corr_n = domain_correlation(data, 'bfi2_n')\n",
    "sim_n = simulate_item_responses(means_n, std_devs_n, corr_n, average_domain_avg_correlations, n_simulations)\n",
    "neuroticism_cols = ['bfi4', 'bfi19', 'bfi34', 'bfi49', 'bfi9', 'bfi24', 'bfi39', 'bfi54', 'bfi14', 'bfi29', 'bfi44', 'bfi59']\n",
    "sim_n_df = pd.DataFrame(sim_n, columns=neuroticism_cols)\n",
    "\n",
    "# Openness\n",
    "domain_stat_o = domain_stats(data, 'bfi2_o')\n",
    "means_o = np.array(domain_stat_o.loc['Mean'].values[:3])\n",
    "std_devs_o = np.array(domain_stat_o.loc['Standard Deviation'].values[:3])\n",
    "corr_o = domain_correlation(data, 'bfi2_o')\n",
    "sim_o = simulate_item_responses(means_o, std_devs_o, corr_o, average_domain_avg_correlations, n_simulations)\n",
    "openness_cols = ['bfi10', 'bfi25', 'bfi40', 'bfi55', 'bfi5', 'bfi20', 'bfi35', 'bfi50', 'bfi15', 'bfi30', 'bfi45', 'bfi60']\n",
    "sim_o_df = pd.DataFrame(sim_o, columns=openness_cols)\n",
    "\n",
    "print(\"✓ Conscientiousness, Neuroticism, and Openness simulated\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 7. Combine Domains and Calculate Scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T09:49:36.670958Z",
     "start_time": "2025-07-11T09:49:36.667825Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined simulated data shape: (200, 61)\n",
      "Columns: ['bfi1', 'bfi16', 'bfi31', 'bfi46', 'bfi6', 'bfi21', 'bfi36', 'bfi51', 'bfi11', 'bfi26', 'bfi41', 'bfi56', 'bfi2', 'bfi17', 'bfi32', 'bfi47', 'bfi7', 'bfi22', 'bfi37', 'bfi52', 'bfi12', 'bfi27', 'bfi42', 'bfi57', 'bfi3', 'bfi18', 'bfi33', 'bfi48', 'bfi8', 'bfi23', 'bfi38', 'bfi53', 'bfi13', 'bfi28', 'bfi43', 'bfi58', 'bfi4', 'bfi19', 'bfi34', 'bfi49', 'bfi9', 'bfi24', 'bfi39', 'bfi54', 'bfi14', 'bfi29', 'bfi44', 'bfi59', 'bfi10', 'bfi25', 'bfi40', 'bfi55', 'bfi5', 'bfi20', 'bfi35', 'bfi50', 'bfi15', 'bfi30', 'bfi45', 'bfi60', 'participant_id']\n"
     ]
    }
   ],
   "source": [
    "# Combine all domains\n",
    "simulated_data = pd.concat([sim_e_df, sim_a_df, sim_c_df, sim_n_df, sim_o_df], axis=1)\n",
    "\n",
    "# Add participant ID\n",
    "simulated_data['participant_id'] = range(len(simulated_data))\n",
    "\n",
    "print(f\"Combined simulated data shape: {simulated_data.shape}\")\n",
    "print(f\"Columns: {list(simulated_data.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T09:49:36.711938Z",
     "start_time": "2025-07-11T09:49:36.703437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating facet scores...\n",
      "✓ Facet scores calculated\n"
     ]
    }
   ],
   "source": [
    "# Calculate facet scores\n",
    "print(\"Calculating facet scores...\")\n",
    "\n",
    "# Extraversion facets\n",
    "simulated_data['bfi_e_sociability'] = (simulated_data['bfi1'] + simulated_data['bfi16'] + simulated_data['bfi31'] + simulated_data['bfi46'])/4\n",
    "simulated_data['bfi_e_assertiveness'] = (simulated_data['bfi6'] + simulated_data['bfi21'] + simulated_data['bfi36'] + simulated_data['bfi51'])/4\n",
    "simulated_data['bfi_e_energy_level'] = (simulated_data['bfi11'] + simulated_data['bfi26'] + simulated_data['bfi41'] + simulated_data['bfi56'])/4\n",
    "\n",
    "# Agreeableness facets\n",
    "simulated_data['bfi_a_compassion'] = (simulated_data['bfi2'] + simulated_data['bfi17'] + simulated_data['bfi32'] + simulated_data['bfi47'])/4\n",
    "simulated_data['bfi_a_respectfulness'] = (simulated_data['bfi7'] + simulated_data['bfi22'] + simulated_data['bfi37'] + simulated_data['bfi52'])/4\n",
    "simulated_data['bfi_a_trust'] = (simulated_data['bfi12'] + simulated_data['bfi27'] + simulated_data['bfi42'] + simulated_data['bfi57'])/4\n",
    "\n",
    "# Conscientiousness facets\n",
    "simulated_data['bfi_c_organization'] = (simulated_data['bfi3'] + simulated_data['bfi18'] + simulated_data['bfi33'] + simulated_data['bfi48'])/4\n",
    "simulated_data['bfi_c_productiveness'] = (simulated_data['bfi8'] + simulated_data['bfi23'] + simulated_data['bfi38'] + simulated_data['bfi53'])/4\n",
    "simulated_data['bfi_c_responsibility'] = (simulated_data['bfi13'] + simulated_data['bfi28'] + simulated_data['bfi43'] + simulated_data['bfi58'])/4\n",
    "\n",
    "# Neuroticism facets\n",
    "simulated_data['bfi_n_anxiety'] = (simulated_data['bfi4'] + simulated_data['bfi19'] + simulated_data['bfi34'] + simulated_data['bfi49'])/4\n",
    "simulated_data['bfi_n_depression'] = (simulated_data['bfi9'] + simulated_data['bfi24'] + simulated_data['bfi39'] + simulated_data['bfi54'])/4\n",
    "simulated_data['bfi_n_emotional_volatility'] = (simulated_data['bfi14'] + simulated_data['bfi29'] + simulated_data['bfi44'] + simulated_data['bfi59'])/4\n",
    "\n",
    "# Openness facets\n",
    "simulated_data['bfi_o_intellectual_curiosity'] = (simulated_data['bfi10'] + simulated_data['bfi25'] + simulated_data['bfi40'] + simulated_data['bfi55'])/4\n",
    "simulated_data['bfi_o_aesthetic_sensitivity'] = (simulated_data['bfi5'] + simulated_data['bfi20'] + simulated_data['bfi35'] + simulated_data['bfi50'])/4\n",
    "simulated_data['bfi_o_creative_imagination'] = (simulated_data['bfi15'] + simulated_data['bfi30'] + simulated_data['bfi45'] + simulated_data['bfi60'])/4\n",
    "\n",
    "print(\"✓ Facet scores calculated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T09:49:36.757388Z",
     "start_time": "2025-07-11T09:49:36.744933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating domain scores...\n",
      "✓ Domain scores calculated\n",
      "\n",
      "✅ New simulated data saved to: /Users/mhhuang/Psychometrics4AI_revision/multi_model_studies/study_3/facet_lvl_simulated_data_NEW.csv\n",
      "Dataset shape: (200, 81)\n",
      "Sample data:\n",
      "   participant_id     bfi_e     bfi_a     bfi_c     bfi_n     bfi_o\n",
      "0               0  2.666667  3.833333  2.333333  3.750000  3.916667\n",
      "1               1  3.250000  2.833333  4.083333  3.500000  2.916667\n",
      "2               2  2.666667  2.750000  3.833333  3.833333  4.166667\n",
      "3               3  4.583333  3.166667  2.916667  3.583333  4.250000\n",
      "4               4  2.750000  4.333333  2.500000  3.000000  4.333333\n"
     ]
    }
   ],
   "source": [
    "# Calculate domain scores\n",
    "print(\"Calculating domain scores...\")\n",
    "\n",
    "simulated_data['bfi_e'] = (simulated_data['bfi_e_sociability'] + simulated_data['bfi_e_assertiveness'] + simulated_data['bfi_e_energy_level'])/3\n",
    "simulated_data['bfi_a'] = (simulated_data['bfi_a_compassion'] + simulated_data['bfi_a_respectfulness'] + simulated_data['bfi_a_trust'])/3\n",
    "simulated_data['bfi_c'] = (simulated_data['bfi_c_organization'] + simulated_data['bfi_c_productiveness'] + simulated_data['bfi_c_responsibility'])/3\n",
    "simulated_data['bfi_n'] = (simulated_data['bfi_n_anxiety'] + simulated_data['bfi_n_depression'] + simulated_data['bfi_n_emotional_volatility'])/3\n",
    "simulated_data['bfi_o'] = (simulated_data['bfi_o_intellectual_curiosity'] + simulated_data['bfi_o_aesthetic_sensitivity'] + simulated_data['bfi_o_creative_imagination'])/3\n",
    "\n",
    "print(\"✓ Domain scores calculated\")\n",
    "\n",
    "# Save the new simulated dataset\n",
    "sim_data_path = Path('facet_lvl_simulated_data_NEW.csv')\n",
    "simulated_data.to_csv(sim_data_path, index=False)\n",
    "print(f\"\\n✅ New simulated data saved to: {sim_data_path.resolve()}\")\n",
    "print(f\"Dataset shape: {simulated_data.shape}\")\n",
    "print(f\"Sample data:\")\n",
    "print(simulated_data[['participant_id', 'bfi_e', 'bfi_a', 'bfi_c', 'bfi_n', 'bfi_o']].head())\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 8. Multi-Model LLM Simulation Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T09:49:37.896227Z",
     "start_time": "2025-07-11T09:49:36.790542Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded new simulated data: (200, 81)\n",
      "Models to test: ['openai-gpt-3.5-turbo-0125']\n",
      "Output directory: /Users/mhhuang/Psychometrics4AI_revision/multi_model_studies/study_3/study_3_results\n"
     ]
    }
   ],
   "source": [
    "# Import simulation utilities\n",
    "from simulation_utils import (\n",
    "    SimulationConfig, \n",
    "    run_bfi_to_minimarker_simulation,\n",
    "    retry_failed_participants\n",
    ")\n",
    "from schema_bfi2 import expanded_scale\n",
    "from mini_marker_prompt import get_expanded_prompt\n",
    "\n",
    "# Reload the new simulated data\n",
    "data = pd.read_csv('facet_lvl_simulated_data_NEW.csv')\n",
    "print(f'Loaded new simulated data: {data.shape}')\n",
    "\n",
    "# Define models to test\n",
    "models = [\n",
    "    'openai-gpt-3.5-turbo-0125',\n",
    "    # \"gpt-4\",\n",
    "    # \"gpt-4o\",\n",
    "    # \"llama\",\n",
    "    # \"deepseek\"\n",
    "]\n",
    "\n",
    "print(f\"Models to test: {models}\")\n",
    "\n",
    "# Create output directories\n",
    "output_base = Path(\"study_3_results\")\n",
    "output_base.mkdir(exist_ok=True)\n",
    "print(f\"Output directory: {output_base.absolute()}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 9. Data Preprocessing for LLM Simulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T09:49:37.937584Z",
     "start_time": "2025-07-11T09:49:37.930169Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reverse coding applied for LLM simulation\n"
     ]
    }
   ],
   "source": [
    "# Apply reverse coding for LLM simulation (same as Study 2)\n",
    "reverse_coding_map_llm = {\n",
    "    'bfi1': 'bfi1', 'bfi2': 'bfi2', 'bfi3': 'bfi3R', 'bfi4': 'bfi4R', 'bfi5': 'bfi5R',\n",
    "    'bfi6': 'bfi6', 'bfi7': 'bfi7', 'bfi8': 'bfi8R', 'bfi9': 'bfi9R', 'bfi10': 'bfi10',\n",
    "    'bfi11': 'bfi11R', 'bfi12': 'bfi12R', 'bfi13': 'bfi13', 'bfi14': 'bfi14', 'bfi15': 'bfi15',\n",
    "    'bfi16': 'bfi16R', 'bfi17': 'bfi17R', 'bfi18': 'bfi18', 'bfi19': 'bfi19', 'bfi20': 'bfi20',\n",
    "    'bfi21': 'bfi21', 'bfi22': 'bfi22R', 'bfi23': 'bfi23R', 'bfi24': 'bfi24R', 'bfi25': 'bfi25R',\n",
    "    'bfi26': 'bfi26R', 'bfi27': 'bfi27', 'bfi28': 'bfi28R', 'bfi29': 'bfi29R', 'bfi30': 'bfi30R',\n",
    "    'bfi31': 'bfi31R', 'bfi32': 'bfi32', 'bfi33': 'bfi33', 'bfi34': 'bfi34', 'bfi35': 'bfi35',\n",
    "    'bfi36': 'bfi36R', 'bfi37': 'bfi37R', 'bfi38': 'bfi38', 'bfi39': 'bfi39', 'bfi40': 'bfi40',\n",
    "    'bfi41': 'bfi41', 'bfi42': 'bfi42R', 'bfi43': 'bfi43', 'bfi44': 'bfi44R', 'bfi45': 'bfi45R',\n",
    "    'bfi46': 'bfi46', 'bfi47': 'bfi47R', 'bfi48': 'bfi48R', 'bfi49': 'bfi49R', 'bfi50': 'bfi50R',\n",
    "    'bfi51': 'bfi51R', 'bfi52': 'bfi52', 'bfi53': 'bfi53', 'bfi54': 'bfi54', 'bfi55': 'bfi55R',\n",
    "    'bfi56': 'bfi56', 'bfi57': 'bfi57', 'bfi58': 'bfi58R', 'bfi59': 'bfi59', 'bfi60': 'bfi60'\n",
    "}\n",
    "\n",
    "# Apply reverse coding to ensure proper format\n",
    "for key, value in reverse_coding_map_llm.items():\n",
    "    if value.endswith('R'):  # Reverse coded\n",
    "        data[key] = 6 - data[key]\n",
    "    # else: keep original value\n",
    "\n",
    "print(\"Reverse coding applied for LLM simulation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T09:49:38.000044Z",
     "start_time": "2025-07-11T09:49:37.969571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing preprocessed data...\n",
      "Creating personality descriptions...\n",
      "Preprocessed data saved to: study_3_results/study3_preprocessed_data.csv\n",
      "Sample size for simulation: 50 participants\n",
      "Converted to list of 50 participant dicts\n",
      "Sample personality description length: 14542 characters\n"
     ]
    }
   ],
   "source": [
    "# Prepare preprocessed data for simulation\n",
    "print(\"Preparing preprocessed data...\")\n",
    "preprocessed_data = data.copy()\n",
    "\n",
    "# Select subset of participants for testing (first 50)\n",
    "n_participants = 50\n",
    "preprocessed_data = preprocessed_data.head(n_participants)\n",
    "\n",
    "# Create combined_bfi2 personality descriptions for simulation\n",
    "print(\"Creating personality descriptions...\")\n",
    "\n",
    "def create_personality_description(row):\n",
    "    \"\"\"Create expanded personality description from BFI items.\"\"\"\n",
    "    descriptions = []\n",
    "    for i in range(1, 61):\n",
    "        bfi_col = f'bfi{i}'\n",
    "        if bfi_col in row and not pd.isna(row[bfi_col]):\n",
    "            value = int(row[bfi_col])\n",
    "            if bfi_col in expanded_scale:\n",
    "                desc = expanded_scale[bfi_col]\n",
    "                descriptions.append(f\"I am {desc}\")\n",
    "    return \" \".join(descriptions)\n",
    "\n",
    "preprocessed_data['combined_bfi2'] = preprocessed_data.apply(create_personality_description, axis=1)\n",
    "\n",
    "# Convert DataFrame to list of dicts for simulation function\n",
    "participants_data = preprocessed_data.to_dict('records')\n",
    "\n",
    "# Save preprocessed data\n",
    "preprocess_path = output_base / \"study3_preprocessed_data.csv\"\n",
    "preprocessed_data.to_csv(preprocess_path, index=False)\n",
    "print(f\"Preprocessed data saved to: {preprocess_path}\")\n",
    "print(f\"Sample size for simulation: {len(preprocessed_data)} participants\")\n",
    "print(f\"Converted to list of {len(participants_data)} participant dicts\")\n",
    "print(f\"Sample personality description length: {len(participants_data[0]['combined_bfi2'])} characters\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 10. Expanded Format Simulation (\"I am...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T09:50:32.634592Z",
     "start_time": "2025-07-11T09:49:38.044968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting expanded format simulation...\n",
      "\n",
      "==================================================\n",
      "Running openai-gpt-3.5-turbo-0125 - Expanded Format\n",
      "==================================================\n",
      "Starting simulation for 50 participants using openai-gpt-3.5-turbo-0125\n",
      "Temperature: 1.0, Batch size: 10\n",
      "Processing participants 0 to 9\n",
      "Completed batch 0 to 9\n",
      "Processing participants 10 to 19\n",
      "Completed batch 10 to 19\n",
      "Processing participants 20 to 29\n",
      "Completed batch 20 to 29\n",
      "Processing participants 30 to 39\n",
      "Completed batch 30 to 39\n",
      "Processing participants 40 to 49\n",
      "Completed batch 40 to 49\n",
      "Results saved to study_3_results/study_3_expanded_results_i_am/bfi_to_minimarker_openai_gpt_3.5_turbo_0125_temp1_0.json\n",
      "✅ openai-gpt-3.5-turbo-0125 expanded format completed. Results: 50 participants.\n",
      "\n",
      "============================================================\n",
      "EXPANDED FORMAT SIMULATION COMPLETED\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Expanded format simulation for all models\n",
    "expanded_results_dir = output_base / \"study_3_expanded_results_i_am\"\n",
    "expanded_results_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Starting expanded format simulation...\")\n",
    "\n",
    "for model in models:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Running {model} - Expanded Format\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    config = SimulationConfig(\n",
    "        model=model,\n",
    "        temperature=1.0,\n",
    "        max_retries=10,\n",
    "        batch_size=10\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        results = run_bfi_to_minimarker_simulation(\n",
    "            participants_data,\n",
    "            config,\n",
    "            str(expanded_results_dir),\n",
    "            False,\n",
    "            get_expanded_prompt\n",
    "        )\n",
    "        print(f\"✅ {model} expanded format completed. Results: {len(results)} participants.\")\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f\"❌ {model} expanded format failed: {e}\")\n",
    "        traceback.print_exc()\n",
    "        \n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPANDED FORMAT SIMULATION COMPLETED\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 11. Binary Format Simulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T09:51:27.147411Z",
     "start_time": "2025-07-11T09:50:32.703193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting binary format simulation...\n",
      "\n",
      "==================================================\n",
      "Running openai-gpt-3.5-turbo-0125 - Binary Format\n",
      "==================================================\n",
      "Starting simulation for 50 participants using openai-gpt-3.5-turbo-0125\n",
      "Temperature: 1.0, Batch size: 10\n",
      "Processing participants 0 to 9\n",
      "Completed batch 0 to 9\n",
      "Processing participants 10 to 19\n",
      "Completed batch 10 to 19\n",
      "Processing participants 20 to 29\n",
      "Completed batch 20 to 29\n",
      "Processing participants 30 to 39\n",
      "Completed batch 30 to 39\n",
      "Processing participants 40 to 49\n",
      "Completed batch 40 to 49\n",
      "Results saved to study_3_results/study_3_binary_results/bfi_to_minimarker_openai_gpt_3.5_turbo_0125_temp1_0.json\n",
      "✅ openai-gpt-3.5-turbo-0125 binary format completed. Results: 50 participants.\n",
      "\n",
      "============================================================\n",
      "BINARY FORMAT SIMULATION COMPLETED\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Import binary format utilities\n",
    "from binary_baseline_prompt import get_binary_prompt\n",
    "\n",
    "# Binary format simulation for all models\n",
    "binary_results_dir = output_base / \"study_3_binary_results\"\n",
    "binary_results_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Starting binary format simulation...\")\n",
    "\n",
    "for model in models:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Running {model} - Binary Format\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    config = SimulationConfig(\n",
    "        model=model,\n",
    "        temperature=1.0,\n",
    "        max_retries=3,\n",
    "        batch_size=10\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        results = run_bfi_to_minimarker_simulation(\n",
    "            participants_data,\n",
    "            config,\n",
    "            str(binary_results_dir),\n",
    "            False,\n",
    "            get_binary_prompt\n",
    "        )\n",
    "        print(f\"✅ {model} binary format completed. Results: {len(results)} participants.\")\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f\"❌ {model} binary format failed: {e}\")\n",
    "        traceback.print_exc()\n",
    "        \n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BINARY FORMAT SIMULATION COMPLETED\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 12. Likert Format Simulation\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T16:41:05.297385Z",
     "start_time": "2025-07-11T16:40:02.549623Z"
    }
   },
   "source": [
    "# Import Likert format utilities\n",
    "from schema_bfi2 import likert_scale\n",
    "from mini_marker_prompt import get_likert_prompt\n",
    "\n",
    "# Create Likert format personality descriptions\n",
    "print(\"Creating Likert format personality descriptions...\")\n",
    "\n",
    "def create_likert_personality_description(row):\n",
    "    \"\"\"Create Likert-style personality description from BFI items.\"\"\"\n",
    "    descriptions = []\n",
    "    for i in range(1, 61):\n",
    "        bfi_col = f'bfi{i}'\n",
    "        if bfi_col in row and not pd.isna(row[bfi_col]):\n",
    "            value = int(row[bfi_col])\n",
    "            if bfi_col in likert_scale:\n",
    "                desc = likert_scale[bfi_col]\n",
    "                descriptions.append(f\"{desc} {value};\")\n",
    "    return \" \".join(descriptions)\n",
    "\n",
    "# Create Likert personality descriptions for all participants\n",
    "preprocessed_data_likert = preprocessed_data.copy()\n",
    "preprocessed_data_likert['combined_bfi2'] = preprocessed_data_likert.apply(create_likert_personality_description, axis=1)\n",
    "\n",
    "# Convert to list of dicts for simulation\n",
    "participants_data_likert = preprocessed_data_likert.to_dict('records')\n",
    "\n",
    "print(f\"Sample Likert personality description length: {len(participants_data_likert[0]['combined_bfi2'])} characters\")\n",
    "print(f\"Sample Likert description: {participants_data_likert[0]['combined_bfi2'][:200]}...\")\n",
    "\n",
    "# Likert format simulation for all models\n",
    "likert_results_dir = output_base / \"study_3_likert_results\"\n",
    "likert_results_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Starting Likert format simulation...\")\n",
    "\n",
    "for model in models:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Running {model} - Likert Format\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    config = SimulationConfig(\n",
    "        model=model,\n",
    "        temperature=1.0,\n",
    "        max_retries=3,\n",
    "        batch_size=10\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        results = run_bfi_to_minimarker_simulation(\n",
    "            participants_data_likert,\n",
    "            config,\n",
    "            str(likert_results_dir),\n",
    "            False,\n",
    "            get_likert_prompt\n",
    "        )\n",
    "        print(f\"✅ {model} Likert format completed. Results: {len(results)} participants.\")\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f\"❌ {model} Likert format failed: {e}\")\n",
    "        traceback.print_exc()\n",
    "        \n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LIKERT FORMAT SIMULATION COMPLETED\")\n",
    "print(\"=\"*60)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Likert format personality descriptions...\n",
      "Sample Likert personality description length: 2109 characters\n",
      "Sample Likert description: Is outgoing, sociable: 3; Is compassionate, has a soft heart: 4; Tends to be disorganized: 5; Is relaxed, handles stress well: 1; Has few artistic interests: 1; Has an assertive personality: 2; Is res...\n",
      "Starting Likert format simulation...\n",
      "\n",
      "==================================================\n",
      "Running openai-gpt-3.5-turbo-0125 - Likert Format\n",
      "==================================================\n",
      "Starting simulation for 50 participants using openai-gpt-3.5-turbo-0125\n",
      "Temperature: 1.0, Batch size: 10\n",
      "Processing participants 0 to 9\n",
      "Completed batch 0 to 9\n",
      "Processing participants 10 to 19\n",
      "Completed batch 10 to 19\n",
      "Processing participants 20 to 29\n",
      "Completed batch 20 to 29\n",
      "Processing participants 30 to 39\n",
      "Completed batch 30 to 39\n",
      "Processing participants 40 to 49\n",
      "Completed batch 40 to 49\n",
      "Results saved to study_3_results/study_3_likert_results/bfi_to_minimarker_openai_gpt_3.5_turbo_0125_temp1_0.json\n",
      "✅ openai-gpt-3.5-turbo-0125 Likert format completed. Results: 50 participants.\n",
      "\n",
      "============================================================\n",
      "LIKERT FORMAT SIMULATION COMPLETED\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 13. Simulation Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T09:51:27.277166Z",
     "start_time": "2025-07-11T09:51:27.274012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STUDY 3 MULTI-MODEL SIMULATION SUMMARY\n",
      "================================================================================\n",
      "\n",
      "✅ Generated new simulated dataset using facet-level parameters\n",
      "   - Sample size: 200 participants\n",
      "   - Dataset saved as: facet_lvl_simulated_data_NEW.csv\n",
      "\n",
      "✅ Multi-model LLM simulation setup:\n",
      "   - Models tested: openai-gpt-3.5-turbo-0125\n",
      "   - Sample size for LLM simulation: 50 participants\n",
      "   - Formats: Expanded ('I am...'), Binary, (Likert - placeholder)\n",
      "\n",
      "📁 Output directories created:\n",
      "   - study_3_results/study_3_expanded_results_i_am\n",
      "   - study_3_results/study_3_binary_results\n",
      "   - study_3_results/study_3_likert_results\n",
      "\n",
      "🔬 Next steps:\n",
      "   1. Run the simulation cells above\n",
      "   2. Check output files for successful completions\n",
      "   3. Run analysis scripts:\n",
      "      - study_3_expanded_convergent_analysis.py\n",
      "      - study_3_binary_convergent_analysis.py\n",
      "      - unified_convergent_analysis.py\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"STUDY 3 MULTI-MODEL SIMULATION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "print(\"✅ Generated new simulated dataset using facet-level parameters\")\n",
    "print(f\"   - Sample size: {len(simulated_data)} participants\")\n",
    "print(f\"   - Dataset saved as: facet_lvl_simulated_data_NEW.csv\")\n",
    "print()\n",
    "print(\"✅ Multi-model LLM simulation setup:\")\n",
    "print(f\"   - Models tested: {', '.join(models)}\")\n",
    "print(f\"   - Sample size for LLM simulation: {n_participants} participants\")\n",
    "print(f\"   - Formats: Expanded ('I am...'), Binary, Likert (all implemented)\")\n",
    "print()\n",
    "print(\"📁 Output directories created:\")\n",
    "print(f\"   - {expanded_results_dir}\")\n",
    "print(f\"   - {binary_results_dir}\")\n",
    "print(f\"   - {likert_results_dir}\")\n",
    "print()\n",
    "print(\"🔬 Next steps:\")\n",
    "print(\"   1. Run the simulation cells above\")\n",
    "print(\"   2. Check output files for successful completions\")\n",
    "print(\"   3. Run analysis scripts:\")\n",
    "print(\"      - study_3_expanded_convergent_analysis.py\")\n",
    "print(\"      - study_3_binary_convergent_analysis.py\")\n",
    "print(\"      - unified_convergent_analysis.py\")\n",
    "print()\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T09:51:27.323058Z",
     "start_time": "2025-07-11T09:51:27.321841Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GenAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
