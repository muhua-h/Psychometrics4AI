{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Study 3 Multi-Model Personality Simulation (Binary Baseline Format)\n",
    "\n",
    "This notebook implements Study 3's BFI-2 to Mini-Marker simulation using **Binary baseline format** personality descriptions across multiple LLM models.\n",
    "\n",
    "## Study 3 Overview\n",
    "Study 3 has three main components:\n",
    "1. **Statistical Simulation**: Extract parameters from Soto's study and simulate new dataset (completed by `bfi2_facet_level_parameter_extraction_and_simulation.py`)\n",
    "2. **LLM Simulation**: Use simulated personality data to generate Mini-Marker responses across multiple models\n",
    "3. **Analysis**: Compare results across models and formats\n",
    "\n",
    "## Models to Test\n",
    "- GPT-3.5-Turbo\n",
    "- GPT-4\n",
    "- GPT-4o  \n",
    "- Llama-3.3-70B-Instruct\n",
    "- DeepSeek-V3\n",
    "\n",
    "## Data Flow\n",
    "1. Load statistically simulated BFI-2 data (from `facet_lvl_simulated_data.csv`)\n",
    "2. Convert BFI-2 domain scores to **Binary baseline format** descriptions\n",
    "3. Generate personality simulation prompts\n",
    "4. Run simulations across multiple models with enhanced validation\n",
    "5. Save results for analysis\n",
    "\n",
    "## Key Features\n",
    "- Uses statistically simulated data (not empirical Soto data)\n",
    "- Binary baseline personality descriptions (\"You are high/low in...\")\n",
    "- Parallel multi-model execution\n",
    "- Enhanced validation and retry logic\n",
    "- Comprehensive error handling\n",
    "\n",
    "## Key Differences from Expanded/Likert Formats\n",
    "- **Simplified descriptions**: Uses only high/low classifications for each Big Five domain\n",
    "- **Threshold-based**: Converts continuous scores to binary (high/low) using 2.5 threshold\n",
    "- **Baseline comparison**: Serves as a simple baseline to compare against more complex formats\n",
    "- Uses `get_binary_prompt` instead of `get_expanded_prompt` or `get_likert_prompt`\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T01:53:48.412733Z",
     "start_time": "2025-07-15T01:53:46.573301Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Add shared modules to path\n",
    "sys.path.append('../shared')\n",
    "\n",
    "from simulation_utils import (\n",
    "    SimulationConfig, \n",
    "    run_batch_simulation,\n",
    "    run_enhanced_bfi_to_minimarker_simulation\n",
    ")\n",
    "from binary_baseline_prompt import (\n",
    "    generate_binary_personality_description,\n",
    "    get_binary_prompt,\n",
    "    create_binary_participant_data\n",
    ")\n",
    "\n",
    "print(\"Setup complete!\")\n",
    "print(f\"Analysis started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n",
      "Analysis started at: 2025-07-15 09:53:48\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Data Loading and Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T01:53:48.448097Z",
     "start_time": "2025-07-15T01:53:48.426655Z"
    }
   },
   "source": [
    "# Load the statistically simulated BFI-2 data\n",
    "data_path = Path('facet_lvl_simulated_data.csv')\n",
    "if not data_path.exists():\n",
    "    print(f\"Simulated data file not found at {data_path}\")\n",
    "    print(\"Please run bfi2_facet_level_parameter_extraction_and_simulation.py first to generate the data\")\n",
    "    raise FileNotFoundError(f\"Data file not found: {data_path}\")\n",
    "\n",
    "data = pd.read_csv(data_path)\n",
    "print(f\"Loaded simulated data shape: {data.shape}\")\n",
    "print(f\"Columns: {list(data.columns[:10])}...\")  # Show first 10 columns\n",
    "print(f\"Domain score columns: {[col for col in data.columns if col.startswith('bfi_') and len(col) == 5]}\")\n",
    "print(f\"Domain score range: {data[['bfi_e', 'bfi_a', 'bfi_c', 'bfi_n', 'bfi_o']].min().min():.2f} to {data[['bfi_e', 'bfi_a', 'bfi_c', 'bfi_n', 'bfi_o']].max().max():.2f}\")\n",
    "data.head()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded simulated data shape: (200, 80)\n",
      "Columns: ['bfi1', 'bfi16', 'bfi31', 'bfi46', 'bfi6', 'bfi21', 'bfi36', 'bfi51', 'bfi11', 'bfi26']...\n",
      "Domain score columns: ['bfi_e', 'bfi_a', 'bfi_c', 'bfi_n', 'bfi_o']\n",
      "Domain score range: 1.33 to 5.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   bfi1  bfi16  bfi31  bfi46  bfi6  bfi21  bfi36  bfi51  bfi11  bfi26  ...  \\\n",
       "0   3.0    2.0    4.0    3.0   2.0    2.0    3.0    5.0    3.0    2.0  ...   \n",
       "1   4.0    2.0    3.0    3.0   3.0    3.0    3.0    2.0    3.0    4.0  ...   \n",
       "2   3.0    3.0    4.0    1.0   1.0    2.0    3.0    4.0    2.0    3.0  ...   \n",
       "3   5.0    1.0    2.0    5.0   5.0    5.0    1.0    1.0    2.0    2.0  ...   \n",
       "4   3.0    4.0    3.0    3.0   1.0    2.0    4.0    3.0    2.0    4.0  ...   \n",
       "\n",
       "   bfi_n_depression  bfi_n_emotional_volatility  bfi_o_intellectual_curiosity  \\\n",
       "0              2.00                        4.50                          4.00   \n",
       "1              2.75                        4.50                          2.50   \n",
       "2              2.00                        4.50                          3.50   \n",
       "3              4.25                        2.25                          4.75   \n",
       "4              3.00                        1.75                          4.50   \n",
       "\n",
       "   bfi_o_aesthetic_sensitivity  bfi_o_creative_imagination     bfi_e  \\\n",
       "0                         4.50                        3.25  2.666667   \n",
       "1                         3.25                        3.00  3.250000   \n",
       "2                         4.75                        4.25  2.666667   \n",
       "3                         4.25                        3.75  4.583333   \n",
       "4                         4.00                        4.50  2.750000   \n",
       "\n",
       "      bfi_a     bfi_c     bfi_n     bfi_o  \n",
       "0  3.833333  2.333333  3.750000  3.916667  \n",
       "1  2.833333  4.083333  3.500000  2.916667  \n",
       "2  2.750000  3.833333  3.833333  4.166667  \n",
       "3  3.166667  2.916667  3.583333  4.250000  \n",
       "4  4.333333  2.500000  3.000000  4.333333  \n",
       "\n",
       "[5 rows x 80 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bfi1</th>\n",
       "      <th>bfi16</th>\n",
       "      <th>bfi31</th>\n",
       "      <th>bfi46</th>\n",
       "      <th>bfi6</th>\n",
       "      <th>bfi21</th>\n",
       "      <th>bfi36</th>\n",
       "      <th>bfi51</th>\n",
       "      <th>bfi11</th>\n",
       "      <th>bfi26</th>\n",
       "      <th>...</th>\n",
       "      <th>bfi_n_depression</th>\n",
       "      <th>bfi_n_emotional_volatility</th>\n",
       "      <th>bfi_o_intellectual_curiosity</th>\n",
       "      <th>bfi_o_aesthetic_sensitivity</th>\n",
       "      <th>bfi_o_creative_imagination</th>\n",
       "      <th>bfi_e</th>\n",
       "      <th>bfi_a</th>\n",
       "      <th>bfi_c</th>\n",
       "      <th>bfi_n</th>\n",
       "      <th>bfi_o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.50</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>3.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.75</td>\n",
       "      <td>4.50</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>4.083333</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.25</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>4.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.25</td>\n",
       "      <td>2.25</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.25</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4.583333</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>2.916667</td>\n",
       "      <td>3.583333</td>\n",
       "      <td>4.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.75</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.50</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Data Preparation for Binary Baseline Format\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T01:53:48.535451Z",
     "start_time": "2025-07-15T01:53:48.526556Z"
    }
   },
   "source": [
    "# Prepare participant data for binary baseline format\n",
    "print(\"Preparing participant data for binary baseline format...\")\n",
    "\n",
    "# Create participant data with correct column names for binary format\n",
    "participants_data = []\n",
    "for idx, row in data.iterrows():\n",
    "    participant = {\n",
    "        'participant_id': idx,\n",
    "        'bfi2_e': row['bfi_e'],\n",
    "        'bfi2_a': row['bfi_a'],\n",
    "        'bfi2_c': row['bfi_c'],\n",
    "        'bfi2_n': row['bfi_n'],\n",
    "        'bfi2_o': row['bfi_o']\n",
    "    }\n",
    "    participants_data.append(participant)\n",
    "\n",
    "print(f\"Created {len(participants_data)} participant records\")\n",
    "\n",
    "# Show sample participant data\n",
    "print(\"\\nSample participant data:\")\n",
    "for i in range(min(3, len(participants_data))):\n",
    "    print(f\"Participant {i+1}: {participants_data[i]}\")\n",
    "\n",
    "# Generate binary personality descriptions using threshold approach\n",
    "print(\"\\n=== GENERATING BINARY BASELINE DESCRIPTIONS ===\")\n",
    "participants_with_binary = create_binary_participant_data(participants_data, threshold=2.5)\n",
    "\n",
    "# Display sample binary descriptions\n",
    "print(\"\\nSample binary baseline personality descriptions:\")\n",
    "for i, p in enumerate(participants_with_binary[:3]):\n",
    "    print(f\"\\nParticipant {i+1}:\")\n",
    "    print(f\"Domain scores: E={p['bfi2_e']:.2f}, A={p['bfi2_a']:.2f}, C={p['bfi2_c']:.2f}, N={p['bfi2_n']:.2f}, O={p['bfi2_o']:.2f}\")\n",
    "    print(f\"Binary description: {p['binary_personality']}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing participant data for binary baseline format...\n",
      "Created 200 participant records\n",
      "\n",
      "Sample participant data:\n",
      "Participant 1: {'participant_id': 0, 'bfi2_e': 2.6666666666666665, 'bfi2_a': 3.8333333333333335, 'bfi2_c': 2.3333333333333335, 'bfi2_n': 3.75, 'bfi2_o': 3.9166666666666665}\n",
      "Participant 2: {'participant_id': 1, 'bfi2_e': 3.25, 'bfi2_a': 2.8333333333333335, 'bfi2_c': 4.083333333333333, 'bfi2_n': 3.5, 'bfi2_o': 2.9166666666666665}\n",
      "Participant 3: {'participant_id': 2, 'bfi2_e': 2.6666666666666665, 'bfi2_a': 2.75, 'bfi2_c': 3.8333333333333335, 'bfi2_n': 3.8333333333333335, 'bfi2_o': 4.166666666666667}\n",
      "\n",
      "=== GENERATING BINARY BASELINE DESCRIPTIONS ===\n",
      "\n",
      "Sample binary baseline personality descriptions:\n",
      "\n",
      "Participant 1:\n",
      "Domain scores: E=2.67, A=3.83, C=2.33, N=3.75, O=3.92\n",
      "Binary description: You are high in Extraversion. You are high in Agreeableness. You are low in Conscientiousness. You are high in Neuroticism. You are high in Openness.\n",
      "\n",
      "Participant 2:\n",
      "Domain scores: E=3.25, A=2.83, C=4.08, N=3.50, O=2.92\n",
      "Binary description: You are high in Extraversion. You are high in Agreeableness. You are high in Conscientiousness. You are high in Neuroticism. You are high in Openness.\n",
      "\n",
      "Participant 3:\n",
      "Domain scores: E=2.67, A=2.75, C=3.83, N=3.83, O=4.17\n",
      "Binary description: You are high in Extraversion. You are high in Agreeableness. You are high in Conscientiousness. You are high in Neuroticism. You are high in Openness.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Test Prompt Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T01:53:48.589725Z",
     "start_time": "2025-07-15T01:53:48.586845Z"
    }
   },
   "source": [
    "# Test prompt generation with first participant\n",
    "if participants_with_binary:\n",
    "    sample_personality = participants_with_binary[0]['binary_personality']\n",
    "    sample_prompt = get_binary_prompt(sample_personality)\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"COMPLETE BINARY BASELINE PROMPT SENT TO LLM\")\n",
    "    print(\"=\" * 80)\n",
    "    print(sample_prompt)\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Prompt length: {len(sample_prompt)} characters\")\n",
    "    print(f\"Prompt word count: {len(sample_prompt.split())} words\")\n",
    "else:\n",
    "    print(\"No participants available for testing\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPLETE BINARY BASELINE PROMPT SENT TO LLM\n",
      "================================================================================\n",
      "### Your Assigned Personality ### \n",
      "Based on your personality profile below, please rate yourself on the following traits.\n",
      "You are high in Extraversion. You are high in Agreeableness. You are low in Conscientiousness. You are high in Neuroticism. You are high in Openness.\n",
      "\n",
      "### Context and Objective ###\n",
      "You are participating in a study to help us understand human personality.\n",
      "\n",
      "Your job is to fill out a personality questionnaire below. Your questionnaire answers should be reflective of your assigned personalities.\n",
      "\n",
      "### Response Format ###\n",
      "IMPORTANT: You must provide ratings for ALL 40 traits listed below.\n",
      "Return ONLY a JSON object where:\n",
      "- Keys are the exact trait names (e.g., \"Bashful\", \"Bold\", etc.)\n",
      "- Values are numbers from 1-9 based on the rating scale\n",
      "- Include ALL 40 traits - no more, no less\n",
      "- Do NOT include personality domains like \"Extraversion\" or \"Agreeableness\"\n",
      "- Do NOT add any text outside the JSON\n",
      "\n",
      "Example format:\n",
      "{\n",
      "    \"Bashful\": 7,\n",
      "    \"Bold\": 3,\n",
      "    \"Careless\": 2,\n",
      "    ...\n",
      "    \"Withdrawn\": 4\n",
      "}\n",
      "\n",
      "### Questionnaire Instruction ###\n",
      "I will provide you a list of descriptive traits. For each trait, take a deep breath and think about what personality you are assigned with then, choose a number indicating how accurately that trait describes you. Using the following rating scale:\n",
      "1 - Extremely Inaccurate \n",
      "2 - Very Inaccurate\n",
      "3 - Moderately Inaccurate\n",
      "4 - Slightly Inaccurate\n",
      "5 - Neutral / Not Applicable\n",
      "6 - Slightly Accurate\n",
      "7 - Moderately Accurate\n",
      "8 - Very Accurate\n",
      "9 - Extremely Accurate\n",
      "\n",
      "### Questionnaire Item ###\n",
      "1. Bashful _\n",
      "2. Bold _\n",
      "3. Careless _\n",
      "4. Cold _\n",
      "5. Complex _\n",
      "6. Cooperative _\n",
      "7. Creative _\n",
      "8. Deep _\n",
      "9. Disorganized _\n",
      "10. Efficient _\n",
      "11. Energetic _\n",
      "12. Envious _\n",
      "13. Extraverted _\n",
      "14. Fretful _\n",
      "15. Harsh _\n",
      "16. Imaginative _\n",
      "17. Inefficient _\n",
      "18. Intellectual _\n",
      "19. Jealous _\n",
      "20. Kind _\n",
      "21. Moody _\n",
      "22. Organized _\n",
      "23. Philosophical _\n",
      "24. Practical _\n",
      "25. Quiet _\n",
      "26. Relaxed _\n",
      "27. Rude _\n",
      "28. Shy _\n",
      "29. Sloppy _\n",
      "30. Sympathetic _\n",
      "31. Systematic _\n",
      "32. Talkative _\n",
      "33. Temperamental _\n",
      "34. Touchy _\n",
      "35. Uncreative _\n",
      "36. Unenvious _\n",
      "37. Unintellectual _\n",
      "38. Unsympathetic _\n",
      "39. Warm _\n",
      "40. Withdrawn _\n",
      "\n",
      "================================================================================\n",
      "Prompt length: 2142 characters\n",
      "Prompt word count: 372 words\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Multi-Model Simulation Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T01:53:48.637025Z",
     "start_time": "2025-07-15T01:53:48.634036Z"
    }
   },
   "source": [
    "# Configuration for different models and temperatures\n",
    "models_to_test = [\n",
    "    'openai-gpt-3.5-turbo-0125',\n",
    "    'gpt-4',\n",
    "    'gpt-4o',\n",
    "    'llama',\n",
    "    'deepseek'\n",
    "]\n",
    "temperatures = [1]  # Use temperature 1 for stochastic responses\n",
    "batch_size = 25  # Smaller batch size for stability across different APIs\n",
    "\n",
    "print(f\"Simulation Configuration:\")\n",
    "print(f\"  Models to test: {models_to_test}\")\n",
    "print(f\"  Temperatures: {temperatures}\")\n",
    "print(f\"  Batch size: {batch_size}\")\n",
    "print(f\"  Total combinations: {len(models_to_test) * len(temperatures)}\")\n",
    "print(f\"  Participants: {len(participants_with_binary)}\")\n",
    "\n",
    "# Verify participant data structure\n",
    "print(f\"\\nSample participant data keys: {list(participants_with_binary[0].keys())}\")\n",
    "print(f\"Has 'binary_personality' key: {'binary_personality' in participants_with_binary[0]}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation Configuration:\n",
      "  Models to test: ['openai-gpt-3.5-turbo-0125', 'gpt-4', 'gpt-4o', 'llama', 'deepseek']\n",
      "  Temperatures: [1]\n",
      "  Batch size: 25\n",
      "  Total combinations: 5\n",
      "  Participants: 200\n",
      "\n",
      "Sample participant data keys: ['participant_id', 'bfi2_e', 'bfi2_a', 'bfi2_c', 'bfi2_n', 'bfi2_o', 'binary_personality']\n",
      "Has 'binary_personality' key: True\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Run Multi-Model Simulations\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T03:27:04.375450Z",
     "start_time": "2025-07-15T01:53:48.700182Z"
    }
   },
   "source": [
    "import threading\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "\n",
    "# Thread-safe logging\n",
    "log_lock = threading.Lock()\n",
    "\n",
    "def safe_print(message, prefix=\"INFO\"):\n",
    "    \"\"\"Thread-safe printing with timestamp and prefix\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    with log_lock:\n",
    "        print(f\"[{timestamp}] {prefix}: {message}\")\n",
    "\n",
    "def run_simulation(model, temperature):\n",
    "    \"\"\"Run simulation for a single model-temperature combination.\"\"\"\n",
    "    simulation_id = f\"{model}_temp{temperature}\"\n",
    "    \n",
    "    # Start message\n",
    "    safe_print(f\"Starting simulation: {model} (temp={temperature})\", \"START\")\n",
    "    \n",
    "    config = SimulationConfig(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        batch_size=batch_size,\n",
    "        max_workers=10,\n",
    "        max_retries=5,  # Enhanced retry logic\n",
    "        base_wait_time=2.0,\n",
    "        max_wait_time=60.0\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Use run_batch_simulation with the correct personality_key for binary format\n",
    "        results = run_batch_simulation(\n",
    "            participants_data=participants_with_binary,\n",
    "            prompt_generator=get_binary_prompt,\n",
    "            config=config,\n",
    "            personality_key='binary_personality',  # Correct key for binary format\n",
    "            output_dir=\"study_3_binary_results\",\n",
    "            output_filename=\"bfi_to_minimarker_binary\"\n",
    "        )\n",
    "        \n",
    "        # Check for failures\n",
    "        failed_count = sum(1 for r in results if isinstance(r, dict) and 'error' in r)\n",
    "        duration = time.time() - start_time\n",
    "        \n",
    "        if failed_count > 0:\n",
    "            safe_print(f\"Completed {simulation_id} in {duration:.1f}s - WARNING: {failed_count} participants failed\", \"WARN\")\n",
    "        else:\n",
    "            safe_print(f\"Completed {simulation_id} in {duration:.1f}s - All participants successful\", \"SUCCESS\")\n",
    "        \n",
    "        return (simulation_id, results)\n",
    "        \n",
    "    except Exception as e:\n",
    "        duration = time.time() - start_time\n",
    "        safe_print(f\"Failed {simulation_id} after {duration:.1f}s - Error: {str(e)}\", \"ERROR\")\n",
    "        return (simulation_id, {\"error\": str(e)})\n",
    "\n",
    "# Main execution\n",
    "print(\"=\" * 80)\n",
    "print(\"STARTING ENHANCED BINARY BASELINE SIMULATIONS FOR STUDY 3\")\n",
    "print(f\"Models: {models_to_test}\")\n",
    "print(f\"Temperatures: {temperatures}\")\n",
    "print(f\"Total combinations: {len(models_to_test) * len(temperatures)}\")\n",
    "print(f\"Participants: {len(participants_with_binary)}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "all_results = {}\n",
    "start_time = time.time()\n",
    "\n",
    "# Use ThreadPoolExecutor for parallel execution\n",
    "with ThreadPoolExecutor(max_workers=len(models_to_test)) as executor:\n",
    "    # Submit all jobs\n",
    "    futures = [\n",
    "        executor.submit(run_simulation, model, temperature)\n",
    "        for model in models_to_test\n",
    "        for temperature in temperatures\n",
    "    ]\n",
    "    \n",
    "    # Collect results as they complete\n",
    "    completed_count = 0\n",
    "    total_jobs = len(futures)\n",
    "    \n",
    "    for future in as_completed(futures):\n",
    "        key, result = future.result()\n",
    "        all_results[key] = result\n",
    "        completed_count += 1\n",
    "        \n",
    "        # Progress update\n",
    "        safe_print(f\"Progress: {completed_count}/{total_jobs} simulations completed\", \"PROGRESS\")\n",
    "\n",
    "total_duration = time.time() - start_time\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"ALL SIMULATIONS COMPLETED IN {total_duration:.1f} SECONDS\")\n",
    "print(f\"Results keys: {list(all_results.keys())}\")\n",
    "print(\"=\" * 80)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STARTING ENHANCED BINARY BASELINE SIMULATIONS FOR STUDY 3\n",
      "Models: ['openai-gpt-3.5-turbo-0125', 'gpt-4', 'gpt-4o', 'llama', 'deepseek']\n",
      "Temperatures: [1]\n",
      "Total combinations: 5\n",
      "Participants: 200\n",
      "================================================================================\n",
      "[09:53:48] START: Starting simulation: openai-gpt-3.5-turbo-0125 (temp=1)\n",
      "Starting simulation for 200 participants using openai-gpt-3.5-turbo-0125\n",
      "Temperature: 1, Batch size: 25\n",
      "Processing participants 0 to 24\n",
      "[09:53:48] START: Starting simulation: gpt-4 (temp=1)\n",
      "Starting simulation for 200 participants using gpt-4\n",
      "Temperature: 1, Batch size: 25\n",
      "Processing participants 0 to 24\n",
      "[09:53:48] START: Starting simulation: gpt-4o (temp=1)\n",
      "Starting simulation for 200 participants using gpt-4o\n",
      "Temperature: 1, Batch size: 25\n",
      "Processing participants 0 to 24\n",
      "[09:53:48] START: Starting simulation: llama (temp=1)\n",
      "Starting simulation for 200 participants using llama\n",
      "Temperature: 1, Batch size: 25\n",
      "Processing participants 0 to 24\n",
      "[09:53:48] START: Starting simulation: deepseek (temp=1)\n",
      "Starting simulation for 200 participants using deepseek\n",
      "Temperature: 1, Batch size: 25\n",
      "Processing participants 0 to 24\n",
      "Completed batch 0 to 24\n",
      "Completed batch 0 to 24\n",
      "Processing participants 25 to 49\n",
      "Processing participants 25 to 49\n",
      "Completed batch 0 to 24\n",
      "Processing participants 25 to 49\n",
      "Completed batch 0 to 24\n",
      "Processing participants 25 to 49\n",
      "Completed batch 25 to 49\n",
      "Processing participants 50 to 74\n",
      "Completed batch 25 to 49\n",
      "Processing participants 50 to 74\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Completed batch 25 to 49\n",
      "Processing participants 50 to 74\n",
      "Completed batch 50 to 74\n",
      "Processing participants 75 to 99\n",
      "Completed batch 25 to 49\n",
      "Completed batch 50 to 74\n",
      "Processing participants 50 to 74\n",
      "Processing participants 75 to 99\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Completed batch 50 to 74\n",
      "Processing participants 75 to 99\n",
      "Completed batch 75 to 99\n",
      "Processing participants 100 to 124\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Completed batch 75 to 99\n",
      "Processing participants 100 to 124\n",
      "Completed batch 100 to 124\n",
      "Processing participants 125 to 149\n",
      "Completed batch 75 to 99\n",
      "Processing participants 100 to 124\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Completed batch 50 to 74\n",
      "Processing participants 75 to 99\n",
      "Completed batch 125 to 149\n",
      "Completed batch 100 to 124\n",
      "Processing participants 150 to 174\n",
      "Processing participants 125 to 149\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Completed batch 100 to 124\n",
      "Processing participants 125 to 149\n",
      "Completed batch 150 to 174\n",
      "Processing participants 175 to 199\n",
      "Completed batch 125 to 149\n",
      "Completed batch 75 to 99\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Processing participants 150 to 174\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Processing participants 100 to 124\n",
      "Completed batch 125 to 149\n",
      "Processing participants 150 to 174\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Completed batch 175 to 199\n",
      "Results saved to study_3_binary_results/bfi_to_minimarker_binary_openai_gpt_3.5_turbo_0125_temp1.json\n",
      "[09:57:24] SUCCESS: Completed openai-gpt-3.5-turbo-0125_temp1 in 216.1s - All participants successful\n",
      "[09:57:24] PROGRESS: Progress: 1/5 simulations completed\n",
      "Completed batch 150 to 174\n",
      "Processing participants 175 to 199\n",
      "Completed batch 150 to 174\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Processing participants 175 to 199\n",
      "Completed batch 100 to 124\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Processing participants 125 to 149\n",
      "Completed batch 175 to 199\n",
      "Results saved to study_3_binary_results/bfi_to_minimarker_binary_gpt_4o_temp1.json\n",
      "[09:57:50] SUCCESS: Completed gpt-4o_temp1 in 241.4s - All participants successful\n",
      "[09:57:50] PROGRESS: Progress: 2/5 simulations completed\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Completed batch 175 to 199\n",
      "Results saved to study_3_binary_results/bfi_to_minimarker_binary_deepseek_temp1.json\n",
      "[09:58:11] SUCCESS: Completed deepseek_temp1 in 262.9s - All participants successful\n",
      "[09:58:11] PROGRESS: Progress: 3/5 simulations completed\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Completed batch 125 to 149\n",
      "Processing participants 150 to 174\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Completed batch 150 to 174\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Processing participants 175 to 199\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Completed batch 175 to 199\n",
      "Results saved to study_3_binary_results/bfi_to_minimarker_binary_gpt_4_temp1.json\n",
      "[09:59:24] SUCCESS: Completed gpt-4_temp1 in 336.1s - All participants successful\n",
      "[09:59:24] PROGRESS: Progress: 4/5 simulations completed\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error processing participant: RetryError[<Future at 0x32f638be0 state=finished raised HttpResponseError>]\n",
      "Completed batch 0 to 24\n",
      "Processing participants 25 to 49\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Completed batch 25 to 49\n",
      "Processing participants 50 to 74\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error processing participant: RetryError[<Future at 0x316912f80 state=finished raised ServiceRequestError>]\n",
      "Completed batch 50 to 74\n",
      "Processing participants 75 to 99\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Completed batch 75 to 99\n",
      "Processing participants 100 to 124\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Completed batch 100 to 124\n",
      "Processing participants 125 to 149\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error processing participant: RetryError[<Future at 0x3592b69e0 state=finished raised HttpResponseError>]\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Completed batch 125 to 149\n",
      "Processing participants 150 to 174\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error processing participant: RetryError[<Future at 0x309a66aa0 state=finished raised ServiceRequestError>]\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error processing participant: RetryError[<Future at 0x316d43100 state=finished raised ServiceRequestError>]\n",
      "Completed batch 150 to 174\n",
      "Processing participants 175 to 199\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Error in get_personality_response: Operation returned an invalid status 'Too Many Requests'\n",
      "Content: \n",
      "Please check this guide to understand why this error code might have been returned \n",
      "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-troubleshoot-online-endpoints#http-status-codes\n",
      "\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Completed batch 175 to 199\n",
      "Results saved to study_3_binary_results/bfi_to_minimarker_binary_llama_temp1.json\n",
      "[11:27:04] WARN: Completed llama_temp1 in 5595.7s - WARNING: 5 participants failed\n",
      "[11:27:04] PROGRESS: Progress: 5/5 simulations completed\n",
      "\n",
      "================================================================================\n",
      "ALL SIMULATIONS COMPLETED IN 5595.7 SECONDS\n",
      "Results keys: ['openai-gpt-3.5-turbo-0125_temp1', 'gpt-4o_temp1', 'deepseek_temp1', 'gpt-4_temp1', 'llama_temp1']\n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Retry Failed Participants\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T03:31:19.614195Z",
     "start_time": "2025-07-15T03:27:04.490584Z"
    }
   },
   "source": [
    "# Retry any failed participants\n",
    "print(\"Checking for failed participants and retrying if necessary...\")\n",
    "\n",
    "from simulation_utils import retry_failed_participants, save_simulation_results\n",
    "\n",
    "retry_count = 0\n",
    "for key, results in all_results.items():\n",
    "    if isinstance(results, list):\n",
    "        failed_count = sum(1 for r in results if isinstance(r, dict) and 'error' in r)\n",
    "        if failed_count > 0:\n",
    "            print(f\"Retrying {failed_count} failed participants for {key}\")\n",
    "            retry_count += 1\n",
    "            \n",
    "            # Extract model and temperature from key\n",
    "            model = key.split('_temp')[0]\n",
    "            temperature = float(key.split('_temp')[1])\n",
    "            \n",
    "            config = SimulationConfig(\n",
    "                model=model,\n",
    "                temperature=temperature,\n",
    "                batch_size=batch_size\n",
    "            )\n",
    "            \n",
    "            updated_results = retry_failed_participants(\n",
    "                results=results,\n",
    "                participants_data=participants_with_binary,\n",
    "                prompt_generator=get_binary_prompt,  # Use binary-specific prompt function\n",
    "                config=config,\n",
    "                personality_key='binary_personality'\n",
    "            )\n",
    "            \n",
    "            all_results[key] = updated_results\n",
    "            \n",
    "            # Save updated results\n",
    "            save_simulation_results(updated_results, \"study_3_binary_results\", \"bfi_to_minimarker_binary\", config)\n",
    "\n",
    "if retry_count == 0:\n",
    "    print(\"No failed participants found - all simulations successful!\")\n",
    "else:\n",
    "    print(f\"Retry process completed for {retry_count} model(s)\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for failed participants and retrying if necessary...\n",
      "Retrying 5 failed participants for llama_temp1\n",
      "Retrying participant 23\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Llama error: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error in get_personality_response: ('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Successfully retried participant 23\n",
      "Retrying participant 68\n",
      "Successfully retried participant 68\n",
      "Retrying participant 133\n",
      "Successfully retried participant 133\n",
      "Retrying participant 161\n",
      "Successfully retried participant 161\n",
      "Retrying participant 167\n",
      "Successfully retried participant 167\n",
      "Results saved to study_3_binary_results/bfi_to_minimarker_binary_llama_temp1_0.json\n",
      "Retry process completed for 1 model(s)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Results Summary and Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T03:31:19.659032Z",
     "start_time": "2025-07-15T03:31:19.647898Z"
    }
   },
   "source": [
    "# Summary of all results\n",
    "print(\"=\" * 80)\n",
    "print(\"STUDY 3 BINARY BASELINE SIMULATION RESULTS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for key, results in all_results.items():\n",
    "    if isinstance(results, list):\n",
    "        total_participants = len(results)\n",
    "        successful_participants = sum(1 for r in results if isinstance(r, dict) and 'error' not in r)\n",
    "        failed_participants = total_participants - successful_participants\n",
    "        \n",
    "        print(f\"\\n{key}:\")\n",
    "        print(f\"  Total participants: {total_participants}\")\n",
    "        print(f\"  Successful: {successful_participants}\")\n",
    "        print(f\"  Failed: {failed_participants}\")\n",
    "        print(f\"  Success rate: {(successful_participants/total_participants)*100:.1f}%\")\n",
    "        \n",
    "        # Sample a successful response for validation\n",
    "        successful_responses = [r for r in results if isinstance(r, dict) and 'error' not in r]\n",
    "        if successful_responses:\n",
    "            sample_response = successful_responses[0]\n",
    "            print(f\"  Sample response keys: {list(sample_response.keys())[:10]}...\")  # Show first 10 keys\n",
    "            print(f\"  Sample response length: {len(sample_response)} traits\")\n",
    "    else:\n",
    "        print(f\"\\n{key}: FAILED - {results}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STUDY 3 BINARY BASELINE SIMULATION RESULTS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "openai-gpt-3.5-turbo-0125_temp1:\n",
      "  Total participants: 200\n",
      "  Successful: 200\n",
      "  Failed: 0\n",
      "  Success rate: 100.0%\n",
      "  Sample response keys: ['Bashful', 'Bold', 'Careless', 'Cold', 'Complex', 'Cooperative', 'Creative', 'Deep', 'Disorganized', 'Efficient']...\n",
      "  Sample response length: 40 traits\n",
      "\n",
      "gpt-4o_temp1:\n",
      "  Total participants: 200\n",
      "  Successful: 200\n",
      "  Failed: 0\n",
      "  Success rate: 100.0%\n",
      "  Sample response keys: ['Bashful', 'Bold', 'Careless', 'Cold', 'Complex', 'Cooperative', 'Creative', 'Deep', 'Disorganized', 'Efficient']...\n",
      "  Sample response length: 40 traits\n",
      "\n",
      "deepseek_temp1:\n",
      "  Total participants: 200\n",
      "  Successful: 200\n",
      "  Failed: 0\n",
      "  Success rate: 100.0%\n",
      "  Sample response keys: ['Bashful', 'Bold', 'Careless', 'Cold', 'Complex', 'Cooperative', 'Creative', 'Deep', 'Disorganized', 'Efficient']...\n",
      "  Sample response length: 40 traits\n",
      "\n",
      "gpt-4_temp1:\n",
      "  Total participants: 200\n",
      "  Successful: 200\n",
      "  Failed: 0\n",
      "  Success rate: 100.0%\n",
      "  Sample response keys: ['Bashful', 'Bold', 'Careless', 'Cold', 'Complex', 'Cooperative', 'Creative', 'Deep', 'Disorganized', 'Efficient']...\n",
      "  Sample response length: 40 traits\n",
      "\n",
      "llama_temp1:\n",
      "  Total participants: 200\n",
      "  Successful: 200\n",
      "  Failed: 0\n",
      "  Success rate: 100.0%\n",
      "  Sample response keys: ['Bashful', 'Bold', 'Careless', 'Cold', 'Complex', 'Cooperative', 'Creative', 'Deep', 'Disorganized', 'Efficient']...\n",
      "  Sample response length: 40 traits\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Save Preprocessed Data and Final Results\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T03:31:19.809064Z",
     "start_time": "2025-07-15T03:31:19.766750Z"
    }
   },
   "source": [
    "# Save the preprocessed data for reference\n",
    "output_path = Path('study_3_binary_results')\n",
    "output_path.mkdir(exist_ok=True)\n",
    "\n",
    "# Save preprocessed data with binary descriptions\n",
    "binary_data = pd.DataFrame(participants_with_binary)\n",
    "binary_data.to_csv(output_path / 'study3_binary_preprocessed_data.csv', index=False)\n",
    "print(f\"Preprocessed data saved to {output_path / 'study3_binary_preprocessed_data.csv'}\")\n",
    "\n",
    "# Save simulation metadata\n",
    "metadata = {\n",
    "    'simulation_type': 'study_3_binary_baseline',\n",
    "    'models_tested': models_to_test,\n",
    "    'temperatures': temperatures,\n",
    "    'batch_size': batch_size,\n",
    "    'total_participants': len(participants_with_binary),\n",
    "    'simulation_date': datetime.now().isoformat(),\n",
    "    'data_source': 'statistically_simulated_bfi2',\n",
    "    'format': 'binary_baseline',\n",
    "    'threshold': 2.5,\n",
    "    'key_differences_from_other_formats': [\n",
    "        'Uses binary high/low classifications instead of continuous descriptions',\n",
    "        'Threshold-based conversion (2.5 cutoff) from continuous domain scores',\n",
    "        'Simplified personality descriptions for baseline comparison',\n",
    "        'Uses get_binary_prompt instead of get_expanded_prompt or get_likert_prompt',\n",
    "    ],\n",
    "    'results_summary': {\n",
    "        key: {\n",
    "            'total': len(results) if isinstance(results, list) else 0,\n",
    "            'successful': sum(1 for r in results if isinstance(r, dict) and 'error' not in r) if isinstance(results, list) else 0\n",
    "        } for key, results in all_results.items()\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(output_path / 'simulation_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"Simulation metadata saved to {output_path / 'simulation_metadata.json'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STUDY 3 BINARY BASELINE SIMULATION COMPLETE!\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Run convergent validity analysis on the results\")\n",
    "print(\"2. Compare with Study 3 Expanded and Likert results for format differences\")\n",
    "print(\"3. Compare with Study 2 binary baseline results for study differences\")\n",
    "print(\"4. Results are saved in study_3_binary_results/ directory\")\n",
    "print(\"5. Binary baseline serves as simplified comparison to complex formats\")\n",
    "print(\"=\" * 60)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data saved to study_3_binary_results/study3_binary_preprocessed_data.csv\n",
      "Simulation metadata saved to study_3_binary_results/simulation_metadata.json\n",
      "\n",
      "============================================================\n",
      "STUDY 3 BINARY BASELINE SIMULATION COMPLETE!\n",
      "\n",
      "Next steps:\n",
      "1. Run convergent validity analysis on the results\n",
      "2. Compare with Study 3 Expanded and Likert results for format differences\n",
      "3. Compare with Study 2 binary baseline results for study differences\n",
      "4. Results are saved in study_3_binary_results/ directory\n",
      "5. Binary baseline serves as simplified comparison to complex formats\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
