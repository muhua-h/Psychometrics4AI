{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Study 3 Multi-Model Personality Simulation (Likert Format)\n",
    "\n",
    "This notebook implements Study 3's BFI-2 to Mini-Marker simulation using **Likert format** personality descriptions across multiple LLM models.\n",
    "\n",
    "## Study 3 Overview\n",
    "Study 3 has three main components:\n",
    "1. **Statistical Simulation**: Extract parameters from Soto's study and simulate new dataset (completed by `study_3_statistical_simulation.py`)\n",
    "2. **LLM Simulation**: Use simulated personality data to generate Mini-Marker responses across multiple models\n",
    "3. **Analysis**: Compare results across models and formats\n",
    "\n",
    "## Models to Test\n",
    "- GPT-3.5-Turbo\n",
    "- GPT-4\n",
    "- GPT-4o  \n",
    "- Llama-3.3-70B-Instruct\n",
    "- DeepSeek-V3\n",
    "\n",
    "## Data Flow\n",
    "1. Load statistically simulated BFI-2 data (from `study3_simulated_data.csv`)\n",
    "2. Map numeric responses to **Likert format** descriptions\n",
    "3. Generate personality simulation prompts\n",
    "4. Run simulations across multiple models with enhanced validation\n",
    "5. Save results for analysis\n",
    "\n",
    "## Key Features\n",
    "- Uses statistically simulated data (not empirical Soto data)\n",
    "- Likert-style personality descriptions\n",
    "- Parallel multi-model execution\n",
    "- Enhanced validation and retry logic\n",
    "- Comprehensive error handling\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T14:47:01.885755Z",
     "start_time": "2025-07-12T14:47:00.323588Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Add shared modules to path\n",
    "sys.path.append('../shared')\n",
    "\n",
    "from simulation_utils import (\n",
    "    SimulationConfig, \n",
    "    run_bfi_to_minimarker_simulation,\n",
    "    retry_failed_participants,\n",
    "    run_enhanced_bfi_to_minimarker_simulation\n",
    ")\n",
    "from schema_bfi2 import likert_scale\n",
    "from mini_marker_prompt import get_likert_prompt\n",
    "\n",
    "print(\"Setup complete!\")\n",
    "print(f\"Analysis started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n",
      "Analysis started at: 2025-07-12 22:47:01\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Data Loading and Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T14:47:01.902631Z",
     "start_time": "2025-07-12T14:47:01.891373Z"
    }
   },
   "source": [
    "# Load the statistically simulated BFI-2 data\n",
    "data_path = Path('study3_simulated_data.csv')\n",
    "if not data_path.exists():\n",
    "    print(f\"Simulated data file not found at {data_path}\")\n",
    "    print(\"Please run study_3_statistical_simulation.py first to generate the data\")\n",
    "    raise FileNotFoundError(f\"Data file not found: {data_path}\")\n",
    "\n",
    "data = pd.read_csv(data_path)\n",
    "print(f\"Loaded simulated data shape: {data.shape}\")\n",
    "print(f\"Columns: {list(data.columns)}\")\n",
    "print(f\"Value range: {data.min().min()} to {data.max().max()}\")\n",
    "data.head()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded simulated data shape: (200, 60)\n",
      "Columns: ['reversed_bfi1', 'reversed_bfi16', 'reversed_bfi31', 'reversed_bfi46', 'reversed_bfi6', 'reversed_bfi21', 'reversed_bfi36', 'reversed_bfi51', 'reversed_bfi11', 'reversed_bfi26', 'reversed_bfi41', 'reversed_bfi56', 'reversed_bfi2', 'reversed_bfi17', 'reversed_bfi32', 'reversed_bfi47', 'reversed_bfi7', 'reversed_bfi22', 'reversed_bfi37', 'reversed_bfi52', 'reversed_bfi12', 'reversed_bfi27', 'reversed_bfi42', 'reversed_bfi57', 'reversed_bfi3', 'reversed_bfi18', 'reversed_bfi33', 'reversed_bfi48', 'reversed_bfi8', 'reversed_bfi23', 'reversed_bfi38', 'reversed_bfi53', 'reversed_bfi13', 'reversed_bfi28', 'reversed_bfi43', 'reversed_bfi58', 'reversed_bfi4', 'reversed_bfi19', 'reversed_bfi34', 'reversed_bfi49', 'reversed_bfi9', 'reversed_bfi24', 'reversed_bfi39', 'reversed_bfi54', 'reversed_bfi14', 'reversed_bfi29', 'reversed_bfi44', 'reversed_bfi59', 'reversed_bfi10', 'reversed_bfi25', 'reversed_bfi40', 'reversed_bfi55', 'reversed_bfi5', 'reversed_bfi20', 'reversed_bfi35', 'reversed_bfi50', 'reversed_bfi15', 'reversed_bfi30', 'reversed_bfi45', 'reversed_bfi60']\n",
      "Value range: 1 to 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   reversed_bfi1  reversed_bfi16  reversed_bfi31  reversed_bfi46  \\\n",
       "0              3               4               2               3   \n",
       "1              4               4               3               3   \n",
       "2              3               3               2               1   \n",
       "3              5               5               4               5   \n",
       "4              3               2               3               3   \n",
       "\n",
       "   reversed_bfi6  reversed_bfi21  reversed_bfi36  reversed_bfi51  \\\n",
       "0              2               2               3               1   \n",
       "1              3               3               3               4   \n",
       "2              1               2               3               2   \n",
       "3              5               5               5               5   \n",
       "4              1               2               2               3   \n",
       "\n",
       "   reversed_bfi11  reversed_bfi26  ...  reversed_bfi40  reversed_bfi55  \\\n",
       "0               3               4  ...               4               4   \n",
       "1               3               2  ...               2               3   \n",
       "2               4               3  ...               3               3   \n",
       "3               4               4  ...               5               5   \n",
       "4               4               2  ...               5               4   \n",
       "\n",
       "   reversed_bfi5  reversed_bfi20  reversed_bfi35  reversed_bfi50  \\\n",
       "0              5               4               4               5   \n",
       "1              4               4               3               2   \n",
       "2              5               5               5               4   \n",
       "3              5               5               4               3   \n",
       "4              4               4               4               4   \n",
       "\n",
       "   reversed_bfi15  reversed_bfi30  reversed_bfi45  reversed_bfi60  \n",
       "0               3               3               4               3  \n",
       "1               2               3               3               4  \n",
       "2               5               4               4               4  \n",
       "3               4               4               4               3  \n",
       "4               5               5               4               4  \n",
       "\n",
       "[5 rows x 60 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reversed_bfi1</th>\n",
       "      <th>reversed_bfi16</th>\n",
       "      <th>reversed_bfi31</th>\n",
       "      <th>reversed_bfi46</th>\n",
       "      <th>reversed_bfi6</th>\n",
       "      <th>reversed_bfi21</th>\n",
       "      <th>reversed_bfi36</th>\n",
       "      <th>reversed_bfi51</th>\n",
       "      <th>reversed_bfi11</th>\n",
       "      <th>reversed_bfi26</th>\n",
       "      <th>...</th>\n",
       "      <th>reversed_bfi40</th>\n",
       "      <th>reversed_bfi55</th>\n",
       "      <th>reversed_bfi5</th>\n",
       "      <th>reversed_bfi20</th>\n",
       "      <th>reversed_bfi35</th>\n",
       "      <th>reversed_bfi50</th>\n",
       "      <th>reversed_bfi15</th>\n",
       "      <th>reversed_bfi30</th>\n",
       "      <th>reversed_bfi45</th>\n",
       "      <th>reversed_bfi60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Data Preparation for Likert Format\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T14:47:01.966462Z",
     "start_time": "2025-07-12T14:47:01.959020Z"
    }
   },
   "source": [
    "# Map the reversed BFI columns to standard BFI columns for likert format\n",
    "# Create mapping from reversed_bfi* to bfi* for likert_scale compatibility\n",
    "bfi_mapping = {}\n",
    "for col in data.columns:\n",
    "    if col.startswith('reversed_bfi'):\n",
    "        bfi_num = col.replace('reversed_bfi', 'bfi')\n",
    "        bfi_mapping[col] = bfi_num\n",
    "\n",
    "print(f\"Created mapping for {len(bfi_mapping)} BFI items\")\n",
    "print(\"Sample mappings:\")\n",
    "for i, (k, v) in enumerate(list(bfi_mapping.items())[:5]):\n",
    "    print(f\"  {k} -> {v}\")\n",
    "\n",
    "# Create a copy with standard BFI column names for likert processing\n",
    "data_for_likert = data.copy()\n",
    "data_for_likert = data_for_likert.rename(columns=bfi_mapping)\n",
    "\n",
    "print(f\"\\nRenamed columns for likert processing:\")\n",
    "print(f\"New columns: {sorted([col for col in data_for_likert.columns if col.startswith('bfi')])}\")\n",
    "\n",
    "# CRITICAL FIX: The simulated data already has reverse coding applied in the statistical simulation\n",
    "# However, some items need to be \"un-reversed\" to match the likert_scale expectations\n",
    "# Items that were reverse coded in the original data need to be reversed back for proper likert descriptions\n",
    "\n",
    "# These are the items that were reverse coded in the original Soto data (marked with 'R')\n",
    "# They need to be reversed back to match the likert_scale descriptions\n",
    "reverse_coded_items = [\n",
    "    'bfi3', 'bfi4', 'bfi5', 'bfi8', 'bfi9', 'bfi11', 'bfi12', 'bfi16', 'bfi17',\n",
    "    'bfi22', 'bfi23', 'bfi24', 'bfi25', 'bfi26', 'bfi28', 'bfi29', 'bfi30',\n",
    "    'bfi31', 'bfi36', 'bfi37', 'bfi42', 'bfi44', 'bfi45', 'bfi47', 'bfi48',\n",
    "    'bfi49', 'bfi50', 'bfi51', 'bfi55', 'bfi58'\n",
    "]\n",
    "\n",
    "print(f\"\\nApplying reverse coding correction for {len(reverse_coded_items)} items...\")\n",
    "for item in reverse_coded_items:\n",
    "    if item in data_for_likert.columns:\n",
    "        data_for_likert[item] = 6 - data_for_likert[item]\n",
    "\n",
    "print(\"Reverse coding correction applied successfully\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created mapping for 60 BFI items\n",
      "Sample mappings:\n",
      "  reversed_bfi1 -> bfi1\n",
      "  reversed_bfi16 -> bfi16\n",
      "  reversed_bfi31 -> bfi31\n",
      "  reversed_bfi46 -> bfi46\n",
      "  reversed_bfi6 -> bfi6\n",
      "\n",
      "Renamed columns for likert processing:\n",
      "New columns: ['bfi1', 'bfi10', 'bfi11', 'bfi12', 'bfi13', 'bfi14', 'bfi15', 'bfi16', 'bfi17', 'bfi18', 'bfi19', 'bfi2', 'bfi20', 'bfi21', 'bfi22', 'bfi23', 'bfi24', 'bfi25', 'bfi26', 'bfi27', 'bfi28', 'bfi29', 'bfi3', 'bfi30', 'bfi31', 'bfi32', 'bfi33', 'bfi34', 'bfi35', 'bfi36', 'bfi37', 'bfi38', 'bfi39', 'bfi4', 'bfi40', 'bfi41', 'bfi42', 'bfi43', 'bfi44', 'bfi45', 'bfi46', 'bfi47', 'bfi48', 'bfi49', 'bfi5', 'bfi50', 'bfi51', 'bfi52', 'bfi53', 'bfi54', 'bfi55', 'bfi56', 'bfi57', 'bfi58', 'bfi59', 'bfi6', 'bfi60', 'bfi7', 'bfi8', 'bfi9']\n",
      "\n",
      "Applying reverse coding correction for 30 items...\n",
      "Reverse coding correction applied successfully\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T14:47:01.995734Z",
     "start_time": "2025-07-12T14:47:01.993196Z"
    }
   },
   "source": [
    "# Generate BFI column list for processing\n",
    "bfi_columns = [f\"bfi{i}\" for i in range(1, 61)]\n",
    "print(f\"Expected BFI columns: {len(bfi_columns)}\")\n",
    "print(f\"Available BFI columns: {len([col for col in data_for_likert.columns if col in bfi_columns])}\")\n",
    "\n",
    "# Verify all expected columns are present\n",
    "missing_cols = [col for col in bfi_columns if col not in data_for_likert.columns]\n",
    "if missing_cols:\n",
    "    print(f\"Warning: Missing columns: {missing_cols}\")\n",
    "else:\n",
    "    print(\"All BFI columns are present!\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected BFI columns: 60\n",
      "Available BFI columns: 60\n",
      "All BFI columns are present!\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T14:47:02.038279Z",
     "start_time": "2025-07-12T14:47:02.025Z"
    }
   },
   "source": [
    "# Map numeric values to Likert format descriptions\n",
    "def convert_values_to_string(series, mapping):\n",
    "    \"\"\"Convert numeric BFI values to likert format strings.\"\"\"\n",
    "    series_converted = series.copy()\n",
    "    if series.name in mapping:\n",
    "        series_converted = series_converted.apply(lambda x: f\"{mapping[series.name]} {x};\")\n",
    "    return series_converted\n",
    "\n",
    "print(\"Converting BFI values to Likert format descriptions...\")\n",
    "\n",
    "# Apply the mapping function to each BFI column\n",
    "mapped_data = data_for_likert[bfi_columns].apply(lambda df: convert_values_to_string(df, likert_scale))\n",
    "\n",
    "# Combine all BFI descriptions into a single personality description\n",
    "mapped_data['combined_bfi2'] = mapped_data[bfi_columns].apply(lambda row: ' '.join(row), axis=1)\n",
    "\n",
    "# Add combined description to both original data AND corrected data\n",
    "data['combined_bfi2'] = mapped_data['combined_bfi2']\n",
    "data_for_likert['combined_bfi2'] = mapped_data['combined_bfi2']\n",
    "\n",
    "print(\"Likert format personality descriptions created successfully\")\n",
    "print(f\"Final data shape: {data.shape}\")\n",
    "print(f\"Corrected data shape: {data_for_likert.shape}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting BFI values to Likert format descriptions...\n",
      "Likert format personality descriptions created successfully\n",
      "Final data shape: (200, 61)\n",
      "Corrected data shape: (200, 61)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T14:47:02.076562Z",
     "start_time": "2025-07-12T14:47:02.074151Z"
    }
   },
   "source": [
    "# Preview a personality description\n",
    "print(\"Sample Likert format personality description:\")\n",
    "print(\"=\" * 80)\n",
    "sample_description = data.iloc[0]['combined_bfi2']\n",
    "print(sample_description[:500] + \"...\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Full description length: {len(sample_description)} characters\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Likert format personality description:\n",
      "================================================================================\n",
      "Is outgoing, sociable: 3; Is compassionate, has a soft heart: 4; Tends to be disorganized: 5; Is relaxed, handles stress well: 1; Has few artistic interests: 1; Has an assertive personality: 2; Is respectful, treats others with respect: 4; Tends to be lazy: 3; Stays optimistic after experiencing a setback: 5; Is curious about many different things: 4; Rarely feels excited or eager: 3; Tends to find fault with others: 2; Is dependable, steady: 3; Is moody, has up and down mood swings: 5; Is inven...\n",
      "================================================================================\n",
      "Full description length: 2109 characters\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Test Prompt Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T14:47:02.091938Z",
     "start_time": "2025-07-12T14:47:02.089598Z"
    }
   },
   "source": [
    "# Test prompt generation with first participant\n",
    "first_participant = data.iloc[0]\n",
    "sample_prompt = get_likert_prompt(first_participant['combined_bfi2'])\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"COMPLETE LIKERT FORMAT PROMPT SENT TO LLM\")\n",
    "print(\"=\" * 80)\n",
    "print(sample_prompt)\n",
    "print(\"=\" * 80)\n",
    "print(f\"Prompt length: {len(sample_prompt)} characters\")\n",
    "print(f\"Prompt word count: {len(sample_prompt.split())} words\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPLETE LIKERT FORMAT PROMPT SENT TO LLM\n",
      "================================================================================\n",
      "### Your Assigned Personality ### \n",
      "The number indicates the extent to which you agree or disagree with that statement. 1 means 'Disagree Strongly', 3 means 'Neutral', and 5 means 'Agree Strongly'.\n",
      "\n",
      "Is outgoing, sociable: 3; Is compassionate, has a soft heart: 4; Tends to be disorganized: 5; Is relaxed, handles stress well: 1; Has few artistic interests: 1; Has an assertive personality: 2; Is respectful, treats others with respect: 4; Tends to be lazy: 3; Stays optimistic after experiencing a setback: 5; Is curious about many different things: 4; Rarely feels excited or eager: 3; Tends to find fault with others: 2; Is dependable, steady: 3; Is moody, has up and down mood swings: 5; Is inventive, finds clever ways to do things: 3; Tends to be quiet: 2; Feels little sympathy for others: 2; Is systematic, likes to keep things in order: 2; Can be tense: 5; Is fascinated by art, music, or literature: 4; Is dominant, acts as a leader: 2; Starts arguments with others: 3; Has difficulty getting started on tasks: 3; Feels secure, comfortable with self: 4; Avoids intellectual, philosophical discussions: 2; Is less active than other people: 2; Has a forgiving nature: 3; Can be somewhat careless: 3; Is emotionally stable, not easily upset: 2; Has little creativity: 3; Is sometimes shy, introverted: 4; Is helpful and unselfish with others: 3; Keeps things neat and tidy: 1; Worries a lot: 5; Values art and beauty: 4; Finds it hard to influence people: 3; Is sometimes rude to others: 1; Is efficient, gets things done: 3; Often feels sad: 3; Is complex, a deep thinker: 4; Is full of energy: 2; Is suspicious of others' intentions: 3; Is reliable, can always be counted on: 2; Keeps their emotions under control: 1; Has difficulty imagining things: 2; Is talkative: 3; Can be cold and uncaring: 2; Leaves a mess, doesn't clean up: 3; Rarely feels anxious or afraid: 2; Thinks poetry and plays are boring: 1; Prefers to have others take charge: 5; Is polite, courteous toward others: 5; Is persistent, works until the task is finished: 2; Tends to feel depressed, blue: 2; Has little interest in abstract ideas: 2; Shows a lot of enthusiasm: 3; Assumes the best about people: 4; Sometimes behaves irresponsibly: 4; Is temperamental, gets emotional easily: 4; Is original, comes up with new ideas: 3;\n",
      "\n",
      "### Context and Objective ###\n",
      "You are participating in a study to help us understand human personality.\n",
      "\n",
      "Your job is to fill out a personality questionnaire below. Your questionnaire answers should be reflective of your assigned personalities.\n",
      "\n",
      "### Response Format ###\n",
      "IMPORTANT: You must provide ratings for ALL 40 traits listed below.\n",
      "Return ONLY a JSON object where:\n",
      "- Keys are the exact trait names (e.g., \"Bashful\", \"Bold\", etc.)\n",
      "- Values are numbers from 1-9 based on the rating scale\n",
      "- Include ALL 40 traits - no more, no less\n",
      "- Do NOT include personality domains like \"Extraversion\" or \"Agreeableness\"\n",
      "- Do NOT add any text outside the JSON\n",
      "\n",
      "Example format:\n",
      "{\n",
      "    \"Bashful\": 7,\n",
      "    \"Bold\": 3,\n",
      "    \"Careless\": 2,\n",
      "    ...\n",
      "    \"Withdrawn\": 4\n",
      "}\n",
      "\n",
      "### Questionnaire Instruction ###\n",
      "I will provide you a list of descriptive traits. For each trait, take a deep breath and think about what personality you are assigned with then, choose a number indicating how accurately that trait describes you. Using the following rating scale:\n",
      "1 - Extremely Inaccurate \n",
      "2 - Very Inaccurate\n",
      "3 - Moderately Inaccurate\n",
      "4 - Slightly Inaccurate\n",
      "5 - Neutral / Not Applicable\n",
      "6 - Slightly Accurate\n",
      "7 - Moderately Accurate\n",
      "8 - Very Accurate\n",
      "9 - Extremely Accurate\n",
      "\n",
      "### Questionnaire Item ###\n",
      "1. Bashful _\n",
      "2. Bold _\n",
      "3. Careless _\n",
      "4. Cold _\n",
      "5. Complex _\n",
      "6. Cooperative _\n",
      "7. Creative _\n",
      "8. Deep _\n",
      "9. Disorganized _\n",
      "10. Efficient _\n",
      "11. Energetic _\n",
      "12. Envious _\n",
      "13. Extraverted _\n",
      "14. Fretful _\n",
      "15. Harsh _\n",
      "16. Imaginative _\n",
      "17. Inefficient _\n",
      "18. Intellectual _\n",
      "19. Jealous _\n",
      "20. Kind _\n",
      "21. Moody _\n",
      "22. Organized _\n",
      "23. Philosophical _\n",
      "24. Practical _\n",
      "25. Quiet _\n",
      "26. Relaxed _\n",
      "27. Rude _\n",
      "28. Shy _\n",
      "29. Sloppy _\n",
      "30. Sympathetic _\n",
      "31. Systematic _\n",
      "32. Talkative _\n",
      "33. Temperamental _\n",
      "34. Touchy _\n",
      "35. Uncreative _\n",
      "36. Unenvious _\n",
      "37. Unintellectual _\n",
      "38. Unsympathetic _\n",
      "39. Warm _\n",
      "40. Withdrawn _\n",
      "\n",
      "================================================================================\n",
      "Prompt length: 4178 characters\n",
      "Prompt word count: 723 words\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Multi-Model Simulation Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T14:47:02.110476Z",
     "start_time": "2025-07-12T14:47:02.104321Z"
    }
   },
   "source": [
    "# Configuration for different models and temperatures\n",
    "models_to_test = ['openai-gpt-3.5-turbo-0125',]\n",
    "                  # 'gpt-4', \n",
    "                  # 'gpt-4o', \n",
    "                  # 'llama', \n",
    "                  # 'deepseek']\n",
    "temperatures = [1]  # Use temperature 1 for stochastic responses\n",
    "batch_size = 25  # Smaller batch size for stability across different APIs\n",
    "\n",
    "# Create participant data list from corrected DataFrame\n",
    "participants_data = data_for_likert.to_dict('records')\n",
    "\n",
    "print(f\"Simulation Configuration:\")\n",
    "print(f\"  Models to test: {models_to_test}\")\n",
    "print(f\"  Temperatures: {temperatures}\")\n",
    "print(f\"  Batch size: {batch_size}\")\n",
    "print(f\"  Total combinations: {len(models_to_test) * len(temperatures)}\")\n",
    "print(f\"  Participants: {len(participants_data)}\")\n",
    "\n",
    "# Verify participant data structure\n",
    "print(f\"\\nSample participant data keys: {list(participants_data[0].keys())}\")\n",
    "print(f\"Has 'combined_bfi2' key: {'combined_bfi2' in participants_data[0]}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation Configuration:\n",
      "  Models to test: ['openai-gpt-3.5-turbo-0125']\n",
      "  Temperatures: [1]\n",
      "  Batch size: 25\n",
      "  Total combinations: 1\n",
      "  Participants: 200\n",
      "\n",
      "Sample participant data keys: ['bfi1', 'bfi16', 'bfi31', 'bfi46', 'bfi6', 'bfi21', 'bfi36', 'bfi51', 'bfi11', 'bfi26', 'bfi41', 'bfi56', 'bfi2', 'bfi17', 'bfi32', 'bfi47', 'bfi7', 'bfi22', 'bfi37', 'bfi52', 'bfi12', 'bfi27', 'bfi42', 'bfi57', 'bfi3', 'bfi18', 'bfi33', 'bfi48', 'bfi8', 'bfi23', 'bfi38', 'bfi53', 'bfi13', 'bfi28', 'bfi43', 'bfi58', 'bfi4', 'bfi19', 'bfi34', 'bfi49', 'bfi9', 'bfi24', 'bfi39', 'bfi54', 'bfi14', 'bfi29', 'bfi44', 'bfi59', 'bfi10', 'bfi25', 'bfi40', 'bfi55', 'bfi5', 'bfi20', 'bfi35', 'bfi50', 'bfi15', 'bfi30', 'bfi45', 'bfi60', 'combined_bfi2']\n",
      "Has 'combined_bfi2' key: True\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Run Multi-Model Simulations\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T14:50:04.518724Z",
     "start_time": "2025-07-12T14:47:02.123742Z"
    }
   },
   "source": [
    "import threading\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "\n",
    "# Thread-safe logging\n",
    "log_lock = threading.Lock()\n",
    "\n",
    "def safe_print(message, prefix=\"INFO\"):\n",
    "    \"\"\"Thread-safe printing with timestamp and prefix\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    with log_lock:\n",
    "        print(f\"[{timestamp}] {prefix}: {message}\")\n",
    "\n",
    "def run_simulation(model, temperature):\n",
    "    \"\"\"Run simulation for a single model-temperature combination.\"\"\"\n",
    "    simulation_id = f\"{model}_temp{temperature}\"\n",
    "    \n",
    "    # Start message\n",
    "    safe_print(f\"Starting simulation: {model} (temp={temperature})\", \"START\")\n",
    "    \n",
    "    config = SimulationConfig(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        batch_size=batch_size,\n",
    "        max_workers=10,\n",
    "        max_retries=5,  # Enhanced retry logic\n",
    "        base_wait_time=2.0,\n",
    "        max_wait_time=60.0\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Use enhanced simulation with format validation and auto-retry\n",
    "        results = run_enhanced_bfi_to_minimarker_simulation(\n",
    "            participants_data=participants_data,\n",
    "            config=config,\n",
    "            output_dir=\"study_3_likert_results\",\n",
    "            use_enhanced=True,  # Enable enhanced validation\n",
    "            prompt_generator=get_likert_prompt  # Use Likert-specific prompts\n",
    "        )\n",
    "        \n",
    "        # Check for failures\n",
    "        failed_count = sum(1 for r in results if isinstance(r, dict) and 'error' in r)\n",
    "        duration = time.time() - start_time\n",
    "        \n",
    "        if failed_count > 0:\n",
    "            safe_print(f\"Completed {simulation_id} in {duration:.1f}s - WARNING: {failed_count} participants failed\", \"WARN\")\n",
    "        else:\n",
    "            safe_print(f\"Completed {simulation_id} in {duration:.1f}s - All participants successful\", \"SUCCESS\")\n",
    "        \n",
    "        return (simulation_id, results)\n",
    "        \n",
    "    except Exception as e:\n",
    "        duration = time.time() - start_time\n",
    "        safe_print(f\"Failed {simulation_id} after {duration:.1f}s - Error: {str(e)}\", \"ERROR\")\n",
    "        return (simulation_id, {\"error\": str(e)})\n",
    "\n",
    "# Main execution\n",
    "print(\"=\" * 80)\n",
    "print(\"STARTING ENHANCED PARALLEL SIMULATIONS FOR STUDY 3\")\n",
    "print(f\"Models: {models_to_test}\")\n",
    "print(f\"Temperatures: {temperatures}\")\n",
    "print(f\"Total combinations: {len(models_to_test) * len(temperatures)}\")\n",
    "print(f\"Participants: {len(participants_data)}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "all_results = {}\n",
    "start_time = time.time()\n",
    "\n",
    "# Use ThreadPoolExecutor for parallel execution\n",
    "with ThreadPoolExecutor(max_workers=len(models_to_test)) as executor:\n",
    "    # Submit all jobs\n",
    "    futures = [\n",
    "        executor.submit(run_simulation, model, temperature)\n",
    "        for model in models_to_test\n",
    "        for temperature in temperatures\n",
    "    ]\n",
    "    \n",
    "    # Collect results as they complete\n",
    "    completed_count = 0\n",
    "    total_jobs = len(futures)\n",
    "    \n",
    "    for future in as_completed(futures):\n",
    "        key, result = future.result()\n",
    "        all_results[key] = result\n",
    "        completed_count += 1\n",
    "        \n",
    "        # Progress update\n",
    "        safe_print(f\"Progress: {completed_count}/{total_jobs} simulations completed\", \"PROGRESS\")\n",
    "\n",
    "total_duration = time.time() - start_time\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"ALL SIMULATIONS COMPLETED IN {total_duration:.1f} SECONDS\")\n",
    "print(f\"Results keys: {list(all_results.keys())}\")\n",
    "print(\"=\" * 80)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STARTING ENHANCED PARALLEL SIMULATIONS FOR STUDY 3\n",
      "Models: ['openai-gpt-3.5-turbo-0125']\n",
      "Temperatures: [1]\n",
      "Total combinations: 1\n",
      "Participants: 200\n",
      "================================================================================\n",
      "[22:47:02] START: Starting simulation: openai-gpt-3.5-turbo-0125 (temp=1)\n",
      "Starting simulation for 200 participants using openai-gpt-3.5-turbo-0125\n",
      "Temperature: 1, Batch size: 25\n",
      "Processing participants 0 to 24\n",
      "Completed batch 0 to 24\n",
      "Processing participants 25 to 49\n",
      "Completed batch 25 to 49\n",
      "Processing participants 50 to 74\n",
      "Completed batch 50 to 74\n",
      "Processing participants 75 to 99\n",
      "Completed batch 75 to 99\n",
      "Processing participants 100 to 124\n",
      "Completed batch 100 to 124\n",
      "Processing participants 125 to 149\n",
      "Completed batch 125 to 149\n",
      "Processing participants 150 to 174\n",
      "Completed batch 150 to 174\n",
      "Processing participants 175 to 199\n",
      "Completed batch 175 to 199\n",
      "Results saved to study_3_likert_results/bfi_to_minimarker_openai_gpt_3.5_turbo_0125_temp1.json\n",
      "[22:50:04] SUCCESS: Completed openai-gpt-3.5-turbo-0125_temp1 in 182.4s - All participants successful\n",
      "[22:50:04] PROGRESS: Progress: 1/1 simulations completed\n",
      "\n",
      "================================================================================\n",
      "ALL SIMULATIONS COMPLETED IN 182.4 SECONDS\n",
      "Results keys: ['openai-gpt-3.5-turbo-0125_temp1']\n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Retry Failed Participants\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T14:50:04.545686Z",
     "start_time": "2025-07-12T14:50:04.541095Z"
    }
   },
   "source": [
    "# Retry any failed participants\n",
    "print(\"Checking for failed participants and retrying if necessary...\")\n",
    "\n",
    "retry_count = 0\n",
    "for key, results in all_results.items():\n",
    "    if isinstance(results, list):\n",
    "        failed_count = sum(1 for r in results if isinstance(r, dict) and 'error' in r)\n",
    "        if failed_count > 0:\n",
    "            print(f\"Retrying {failed_count} failed participants for {key}\")\n",
    "            retry_count += 1\n",
    "            \n",
    "            # Extract model and temperature from key\n",
    "            model = key.split('_temp')[0]\n",
    "            temperature = float(key.split('_temp')[1])\n",
    "            \n",
    "            config = SimulationConfig(\n",
    "                model=model,\n",
    "                temperature=temperature,\n",
    "                batch_size=batch_size\n",
    "            )\n",
    "            \n",
    "            updated_results = retry_failed_participants(\n",
    "                results=results,\n",
    "                participants_data=participants_data,\n",
    "                prompt_generator=get_likert_prompt,  # Use likert-specific prompt function\n",
    "                config=config,\n",
    "                personality_key='combined_bfi2'\n",
    "            )\n",
    "            \n",
    "            all_results[key] = updated_results\n",
    "            \n",
    "            # Save updated results\n",
    "            from simulation_utils import save_simulation_results\n",
    "            save_simulation_results(updated_results, \"study_3_likert_results\", \"bfi_to_minimarker\", config)\n",
    "\n",
    "if retry_count == 0:\n",
    "    print(\"No failed participants found - all simulations successful!\")\n",
    "else:\n",
    "    print(f\"Retry process completed for {retry_count} model(s)\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for failed participants and retrying if necessary...\n",
      "No failed participants found - all simulations successful!\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Results Summary and Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T14:50:04.587803Z",
     "start_time": "2025-07-12T14:50:04.583918Z"
    }
   },
   "source": [
    "# Summary of all results\n",
    "print(\"=\" * 80)\n",
    "print(\"STUDY 3 LIKERT SIMULATION RESULTS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for key, results in all_results.items():\n",
    "    if isinstance(results, list):\n",
    "        total_participants = len(results)\n",
    "        successful_participants = sum(1 for r in results if isinstance(r, dict) and 'error' not in r)\n",
    "        failed_participants = total_participants - successful_participants\n",
    "        \n",
    "        print(f\"\\n{key}:\")\n",
    "        print(f\"  Total participants: {total_participants}\")\n",
    "        print(f\"  Successful: {successful_participants}\")\n",
    "        print(f\"  Failed: {failed_participants}\")\n",
    "        print(f\"  Success rate: {(successful_participants/total_participants)*100:.1f}%\")\n",
    "        \n",
    "        # Sample a successful response for validation\n",
    "        successful_responses = [r for r in results if isinstance(r, dict) and 'error' not in r]\n",
    "        if successful_responses:\n",
    "            sample_response = successful_responses[0]\n",
    "            print(f\"  Sample response keys: {list(sample_response.keys())[:10]}...\")  # Show first 10 keys\n",
    "            print(f\"  Sample response length: {len(sample_response)} traits\")\n",
    "    else:\n",
    "        print(f\"\\n{key}: FAILED - {results}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STUDY 3 LIKERT SIMULATION RESULTS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "openai-gpt-3.5-turbo-0125_temp1:\n",
      "  Total participants: 200\n",
      "  Successful: 200\n",
      "  Failed: 0\n",
      "  Success rate: 100.0%\n",
      "  Sample response keys: ['Bashful', 'Bold', 'Careless', 'Cold', 'Complex', 'Cooperative', 'Creative', 'Deep', 'Disorganized', 'Efficient']...\n",
      "  Sample response length: 40 traits\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Save Preprocessed Data and Final Results\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T14:50:04.614649Z",
     "start_time": "2025-07-12T14:50:04.601527Z"
    }
   },
   "source": [
    "# Save the preprocessed data for reference\n",
    "output_path = Path('study_3_likert_results')\n",
    "output_path.mkdir(exist_ok=True)\n",
    "\n",
    "# Save preprocessed data (with reverse coding corrections)\n",
    "data_for_likert.to_csv(output_path / 'study3_likert_preprocessed_data.csv', index=False)\n",
    "print(f\"Preprocessed data saved to {output_path / 'study3_likert_preprocessed_data.csv'}\")\n",
    "\n",
    "# Save simulation metadata\n",
    "metadata = {\n",
    "    'simulation_type': 'study_3_likert',\n",
    "    'models_tested': models_to_test,\n",
    "    'temperatures': temperatures,\n",
    "    'batch_size': batch_size,\n",
    "    'total_participants': len(participants_data),\n",
    "    'simulation_date': datetime.now().isoformat(),\n",
    "    'data_source': 'statistically_simulated_bfi2',\n",
    "    'format': 'likert',\n",
    "    'results_summary': {\n",
    "        key: {\n",
    "            'total': len(results) if isinstance(results, list) else 0,\n",
    "            'successful': sum(1 for r in results if isinstance(r, dict) and 'error' not in r) if isinstance(results, list) else 0\n",
    "        } for key, results in all_results.items()\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(output_path / 'simulation_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"Simulation metadata saved to {output_path / 'simulation_metadata.json'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STUDY 3 LIKERT FORMAT SIMULATION COMPLETE!\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Run convergent validity analysis on the results\")\n",
    "print(\"2. Compare with Study 2 results for format differences\")\n",
    "print(\"3. Results are saved in study_3_likert_results/ directory\")\n",
    "print(\"4. Enhanced validation and retry logic handled format issues\")\n",
    "print(\"=\" * 60)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data saved to study_3_likert_results/study3_likert_preprocessed_data.csv\n",
      "Simulation metadata saved to study_3_likert_results/simulation_metadata.json\n",
      "\n",
      "============================================================\n",
      "STUDY 3 LIKERT FORMAT SIMULATION COMPLETE!\n",
      "\n",
      "Next steps:\n",
      "1. Run convergent validity analysis on the results\n",
      "2. Compare with Study 2 results for format differences\n",
      "3. Results are saved in study_3_likert_results/ directory\n",
      "4. Enhanced validation and retry logic handled format issues\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T14:50:04.630466Z",
     "start_time": "2025-07-12T14:50:04.629235Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GenAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
