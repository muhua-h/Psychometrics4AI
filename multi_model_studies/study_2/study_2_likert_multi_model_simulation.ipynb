{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Model Personality Simulation - Study 2 (Likert Format)\n",
    "\n",
    "This notebook implements the original Study 2 BFI-2 to Mini-Marker simulation using **Likert format** personality descriptions across multiple LLM models using the unified portal.py interface.\n",
    "\n",
    "## Models to Test\n",
    "- GPT-4\n",
    "- GPT-4o  \n",
    "- Llama-3.3-70B-Instruct\n",
    "- DeepSeek-V3\n",
    "\n",
    "## Data Flow\n",
    "1. Load and preprocess Soto BFI-2 data\n",
    "2. Apply reverse coding to personality items\n",
    "3. Map numeric responses to **Likert format** descriptions (e.g., \"Is outgoing, sociable: 5\")\n",
    "4. Generate personality simulation prompts\n",
    "5. Run simulations across multiple models\n",
    "6. Save results for analysis\n",
    "\n",
    "## Key Difference from Expanded Format\n",
    "- Uses concise Likert-style descriptions instead of expanded narrative descriptions\n",
    "- Expected to show different personality assignment performance\n",
    "\n",
    "## Next Steps\n",
    "After running this notebook, use `study_2_likert_analysis.ipynb` for comprehensive analysis of the results."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T07:44:29.179866Z",
     "start_time": "2025-06-28T07:44:27.550488Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add shared modules to path\n",
    "sys.path.append('../shared')\n",
    "\n",
    "from simulation_utils import (\n",
    "    SimulationConfig, \n",
    "    run_bfi_to_minimarker_simulation,\n",
    "    retry_failed_participants\n",
    ")\n",
    "from schema_bfi2 import likert_scale\n",
    "from mini_marker_prompt import get_likert_prompt"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T07:44:31.022779Z",
     "start_time": "2025-06-28T07:44:29.196211Z"
    }
   },
   "source": [
    "# Load the Soto BFI-2 dataset\n",
    "data_path = Path('../../raw_data/Soto_data.xlsx')\n",
    "if not data_path.exists():\n",
    "    print(f\"Data file not found at {data_path}\")\n",
    "    print(\"Please ensure the raw_data/Soto_data.xlsx file exists in the project root\")\n",
    "    raise FileNotFoundError(f\"Data file not found: {data_path}\")\n",
    "\n",
    "data = pd.read_excel(data_path, sheet_name='data')\n",
    "print(f\"Loaded data shape: {data.shape}\")\n",
    "data.head()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data shape: (470, 704)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   case_id   age sex  ethnicity  rel_acquaintance  rel_friend  rel_roommate  \\\n",
       "0        1  27.0   M        2.0               NaN         NaN           NaN   \n",
       "1        2  26.0   M        3.0               NaN         NaN           NaN   \n",
       "2        3  24.0   F        4.0               NaN         NaN           NaN   \n",
       "3        4  33.0   M        3.0               NaN         1.0           NaN   \n",
       "4        5  23.0   F        5.0               NaN         NaN           NaN   \n",
       "\n",
       "   rel_boygirlfriend  rel_relative  rel_other  ... tneo_n3_dep  tneo_n4_sel  \\\n",
       "0                NaN           NaN        NaN  ...   51.250000    40.181818   \n",
       "1                NaN           NaN        NaN  ...   69.632353    60.636364   \n",
       "2                NaN           NaN        NaN  ...   60.441176    74.272727   \n",
       "3                NaN           NaN        NaN  ...   67.794118    58.363636   \n",
       "4                NaN           NaN        NaN  ...   62.279412    67.454545   \n",
       "\n",
       "   tneo_n5_imp  tneo_n6_vul  tneo_o1_fan  tneo_o2_aes  tneo_o3_fee  \\\n",
       "0    64.000000    55.102041    46.639344    46.969697         66.7   \n",
       "1    66.272727    65.306122    54.836066    56.439394         51.7   \n",
       "2    54.909091    65.306122    75.327869    56.439394         56.7   \n",
       "3    64.000000    52.551020    54.836066    50.757576         36.7   \n",
       "4    41.272727    60.204082    50.737705    48.863636         49.2   \n",
       "\n",
       "   tneo_o4_act  tneo_o5_ide  tneo_o6_val  \n",
       "0    57.065217    41.984127    58.039216  \n",
       "1    51.630435    51.904762    45.784314  \n",
       "2    40.760870    51.904762    58.039216  \n",
       "3    65.217391    63.809524    58.039216  \n",
       "4    46.195652    38.015873    38.431373  \n",
       "\n",
       "[5 rows x 704 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>rel_acquaintance</th>\n",
       "      <th>rel_friend</th>\n",
       "      <th>rel_roommate</th>\n",
       "      <th>rel_boygirlfriend</th>\n",
       "      <th>rel_relative</th>\n",
       "      <th>rel_other</th>\n",
       "      <th>...</th>\n",
       "      <th>tneo_n3_dep</th>\n",
       "      <th>tneo_n4_sel</th>\n",
       "      <th>tneo_n5_imp</th>\n",
       "      <th>tneo_n6_vul</th>\n",
       "      <th>tneo_o1_fan</th>\n",
       "      <th>tneo_o2_aes</th>\n",
       "      <th>tneo_o3_fee</th>\n",
       "      <th>tneo_o4_act</th>\n",
       "      <th>tneo_o5_ide</th>\n",
       "      <th>tneo_o6_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>M</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>51.250000</td>\n",
       "      <td>40.181818</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>55.102041</td>\n",
       "      <td>46.639344</td>\n",
       "      <td>46.969697</td>\n",
       "      <td>66.7</td>\n",
       "      <td>57.065217</td>\n",
       "      <td>41.984127</td>\n",
       "      <td>58.039216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>M</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>69.632353</td>\n",
       "      <td>60.636364</td>\n",
       "      <td>66.272727</td>\n",
       "      <td>65.306122</td>\n",
       "      <td>54.836066</td>\n",
       "      <td>56.439394</td>\n",
       "      <td>51.7</td>\n",
       "      <td>51.630435</td>\n",
       "      <td>51.904762</td>\n",
       "      <td>45.784314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>F</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>60.441176</td>\n",
       "      <td>74.272727</td>\n",
       "      <td>54.909091</td>\n",
       "      <td>65.306122</td>\n",
       "      <td>75.327869</td>\n",
       "      <td>56.439394</td>\n",
       "      <td>56.7</td>\n",
       "      <td>40.760870</td>\n",
       "      <td>51.904762</td>\n",
       "      <td>58.039216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>33.0</td>\n",
       "      <td>M</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>67.794118</td>\n",
       "      <td>58.363636</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>52.551020</td>\n",
       "      <td>54.836066</td>\n",
       "      <td>50.757576</td>\n",
       "      <td>36.7</td>\n",
       "      <td>65.217391</td>\n",
       "      <td>63.809524</td>\n",
       "      <td>58.039216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>F</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>62.279412</td>\n",
       "      <td>67.454545</td>\n",
       "      <td>41.272727</td>\n",
       "      <td>60.204082</td>\n",
       "      <td>50.737705</td>\n",
       "      <td>48.863636</td>\n",
       "      <td>49.2</td>\n",
       "      <td>46.195652</td>\n",
       "      <td>38.015873</td>\n",
       "      <td>38.431373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 704 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T07:44:31.162974Z",
     "start_time": "2025-06-28T07:44:31.159487Z"
    }
   },
   "source": [
    "tda_columns = [f\"tda{i}\" for i in range(1, 41)]\n",
    "sbfi_columns = [f\"bfi{i}\" for i in range(1, 61)]\n",
    "selected_columns = tda_columns + sbfi_columns\n",
    "\n",
    "print(f\"Original data shape: {data.shape}\")\n",
    "\n",
    "# Remove rows with missing values in the selected columns\n",
    "data = data.dropna(subset=selected_columns)\n",
    "print(f\"Data shape after removing missing values: {data.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape: (470, 704)\n",
      "Data shape after removing missing values: (438, 704)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T07:44:31.173731Z",
     "start_time": "2025-06-28T07:44:31.171906Z"
    }
   },
   "source": [
    "# NOTE: For Likert format, we do NOT apply reverse coding to the personality descriptions\n",
    "# The reverse coding is only applied during analysis, not during personality assignment\n",
    "# This matches the original study workflow exactly\n",
    "\n",
    "print(\"Likert format: Using original BFI-2 scores without reverse coding for personality descriptions\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likert format: Using original BFI-2 scores without reverse coding for personality descriptions\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T07:44:31.205941Z",
     "start_time": "2025-06-28T07:44:31.186817Z"
    }
   },
   "source": [
    "# Map numeric values to Likert format descriptions\n",
    "def convert_values_to_string(series, mapping):\n",
    "    # Copy the series to not alter the original data\n",
    "    series_converted = series.copy()\n",
    "    # Apply the string mapping\n",
    "    if series.name in mapping:\n",
    "        series_converted = series_converted.apply(lambda x: f\"{mapping[series.name]} {x};\")\n",
    "    return series_converted\n",
    "\n",
    "# Apply the mapping function to each row of the dataset\n",
    "mapped_data = data[sbfi_columns].apply(lambda df: convert_values_to_string(df, likert_scale))\n",
    "mapped_data['combined_bfi2'] = mapped_data[['bfi' + str(i) for i in range(1, 61)]].apply(lambda row: ' '.join(row), axis=1)\n",
    "\n",
    "# Add combined description to original data\n",
    "data['combined_bfi2'] = mapped_data['combined_bfi2']\n",
    "\n",
    "print(\"Likert format personality descriptions created successfully\")\n",
    "print(f\"Final data shape: {data.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likert format personality descriptions created successfully\n",
      "Final data shape: (438, 705)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T07:44:31.400186Z",
     "start_time": "2025-06-28T07:44:31.397608Z"
    }
   },
   "source": [
    "# Preview a personality description\n",
    "print(\"Sample Likert format personality description:\")\n",
    "print(data.iloc[0]['combined_bfi2'][:500] + \"...\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Likert format personality description:\n",
      "Is outgoing, sociable: 5; Is compassionate, has a soft heart: 5; Tends to be disorganized: 2; Is relaxed, handles stress well: 3; Has few artistic interests: 2; Has an assertive personality: 4; Is respectful, treats others with respect: 5; Tends to be lazy: 4; Stays optimistic after experiencing a setback: 5; Is curious about many different things: 2; Rarely feels excited or eager: 2; Tends to find fault with others: 2; Is dependable, steady: 5; Is moody, has up and down mood swings: 4; Is inven...\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T07:44:31.428664Z",
     "start_time": "2025-06-28T07:44:31.425670Z"
    }
   },
   "source": [
    " # Test prompt generation with first participant\n",
    "first_participant = data.iloc[0]\n",
    "sample_prompt = get_likert_prompt(first_participant['combined_bfi2'])\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"COMPLETE LIKERT FORMAT PROMPT SENT TO LLM\")\n",
    "print(\"=\"*80)\n",
    "print(sample_prompt)\n",
    "print(\"=\"*80)\n",
    "print(f\"Prompt length: {len(sample_prompt)} characters\")\n",
    "print(f\"Prompt word count: {len(sample_prompt.split())} words\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPLETE LIKERT FORMAT PROMPT SENT TO LLM\n",
      "================================================================================\n",
      "### Context ###\n",
      "You are participating in a personality psychology study. You have been assigned with personality traits.\n",
      "\n",
      "### Your Assigned Personality ### \n",
      "The number indicates the extent to which you agree or disagree with that statement. 1 means 'Disagree Strongly', 3 means 'Neutral', and 5 means 'Agree Strongly'.\n",
      "\n",
      "Is outgoing, sociable: 5; Is compassionate, has a soft heart: 5; Tends to be disorganized: 2; Is relaxed, handles stress well: 3; Has few artistic interests: 2; Has an assertive personality: 4; Is respectful, treats others with respect: 5; Tends to be lazy: 4; Stays optimistic after experiencing a setback: 5; Is curious about many different things: 2; Rarely feels excited or eager: 2; Tends to find fault with others: 2; Is dependable, steady: 5; Is moody, has up and down mood swings: 4; Is inventive, finds clever ways to do things: 4; Tends to be quiet: 2; Feels little sympathy for others: 1; Is systematic, likes to keep things in order: 2; Can be tense: 3; Is fascinated by art, music, or literature: 5; Is dominant, acts as a leader: 2; Starts arguments with others: 2; Has difficulty getting started on tasks: 4; Feels secure, comfortable with self: 5; Avoids intellectual, philosophical discussions: 2; Is less active than other people: 2; Has a forgiving nature: 5; Can be somewhat careless: 4; Is emotionally stable, not easily upset: 4; Has little creativity: 4; Is sometimes shy, introverted: 4; Is helpful and unselfish with others: 5; Keeps things neat and tidy: 3; Worries a lot: 4; Values art and beauty: 4; Finds it hard to influence people: 2; Is sometimes rude to others: 3; Is efficient, gets things done: 4; Often feels sad: 1; Is complex, a deep thinker: 2; Is full of energy: 5; Is suspicious of others' intentions: 2; Is reliable, can always be counted on: 4; Keeps their emotions under control: 4; Has difficulty imagining things: 2; Is talkative: 5; Can be cold and uncaring: 1; Leaves a mess, doesn't clean up: 2; Rarely feels anxious or afraid: 2; Thinks poetry and plays are boring: 2; Prefers to have others take charge: 1; Is polite, courteous toward others: 5; Is persistent, works until the task is finished: 4; Tends to feel depressed, blue: 3; Has little interest in abstract ideas: 4; Shows a lot of enthusiasm: 5; Assumes the best about people: 5; Sometimes behaves irresponsibly: 4; Is temperamental, gets emotional easily: 1; Is original, comes up with new ideas: 1;\n",
      "\n",
      "### Objective ###\n",
      "Fill out a personality questionnaire. Your questionnaire answers should be reflective of your assigned personalities.\n",
      "\n",
      "### Response Format ###\n",
      "ONLY return your response as a JSON file where the keys are the traits and the numbers indicate your endorsement to the statements.\n",
      "\n",
      "### Questionnaire Instruction ###\n",
      "I will provide you a list of descriptive traits. For each trait, take a deep breath and think about what personality you are assigned with then, choose a number indicating how accurately that trait describes you. Using the following rating scale:\n",
      "1 - Extremely Inaccurate \n",
      "2 - Very Inaccurate\n",
      "3 - Moderately Inaccurate\n",
      "4 - Slightly Inaccurate\n",
      "5 - Neutral / Not Applicable\n",
      "6 - Slightly Accurate\n",
      "7 - Moderately Accurate\n",
      "8 - Very Accurate\n",
      "9 - Extremely Accurate\n",
      "\n",
      "### Questionnaire Item ###\n",
      "1. Bashful _\n",
      "2. Bold _\n",
      "3. Careless _\n",
      "4. Cold _\n",
      "5. Complex _\n",
      "6. Cooperative _\n",
      "7. Creative _\n",
      "8. Deep _\n",
      "9. Disorganized _\n",
      "10. Efficient _\n",
      "11. Energetic _\n",
      "12. Envious _\n",
      "13. Extraverted _\n",
      "14. Fretful _\n",
      "15. Harsh _\n",
      "16. Imaginative _\n",
      "17. Inefficient _\n",
      "18. Intellectual _\n",
      "19. Jealous _\n",
      "20. Kind _\n",
      "21. Moody _\n",
      "22. Organized _\n",
      "23. Philosophical _\n",
      "24. Practical _\n",
      "25. Quiet _\n",
      "26. Relaxed _\n",
      "27. Rude _\n",
      "28. Shy _\n",
      "29. Sloppy _\n",
      "30. Sympathetic _\n",
      "31. Systematic _\n",
      "32. Talkative _\n",
      "33. Temperamental _\n",
      "34. Touchy _\n",
      "35. Uncreative _\n",
      "36. Unenvious _\n",
      "37. Unintellectual _\n",
      "38. Unsympathetic _\n",
      "39. Warm _\n",
      "40. Withdrawn _\n",
      "\n",
      "================================================================================\n",
      "Prompt length: 3844 characters\n",
      "Prompt word count: 664 words\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Model Simulation Configuration"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T07:44:31.545330Z",
     "start_time": "2025-06-28T07:44:31.500400Z"
    }
   },
   "source": [
    "# Configuration for different models and temperatures\n",
    "# models_to_test = ['openai-gpt-3.5-turbo-0125','gpt-4', 'gpt-4o', 'llama', 'deepseek'] # put all models that you want to test here \n",
    "models_to_test = ['openai-gpt-3.5-turbo-0125']\n",
    "temperatures = [1]  \n",
    "batch_size = 25  # Smaller batch size for stability across different APIs\n",
    "\n",
    "# Create participant data list from DataFrame\n",
    "participants_data = data.to_dict('records')\n",
    "print(f\"Prepared {len(participants_data)} participants for simulation\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 438 participants for simulation\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Simulations for All Models"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T07:50:23.590369Z",
     "start_time": "2025-06-28T07:44:32.156596Z"
    }
   },
   "source": [
    "import threading\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Thread-safe logging\n",
    "log_lock = threading.Lock()\n",
    "\n",
    "def safe_print(message, prefix=\"INFO\"):\n",
    "    \"\"\"Thread-safe printing with timestamp and prefix\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    with log_lock:\n",
    "        print(f\"[{timestamp}] {prefix}: {message}\")\n",
    "\n",
    "def run_simulation(model, temperature):\n",
    "    simulation_id = f\"{model}_temp{temperature}\"\n",
    "    \n",
    "    # Start message\n",
    "    safe_print(f\"Starting simulation: {model} (temp={temperature})\", \"START\")\n",
    "    \n",
    "    config = SimulationConfig(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        batch_size=batch_size,\n",
    "        max_workers=10\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        results = run_bfi_to_minimarker_simulation(\n",
    "            participants_data=participants_data,\n",
    "            config=config,\n",
    "            output_dir=\"study_2_likert_results\"\n",
    "        )\n",
    "        \n",
    "        # Check for failures\n",
    "        failed_count = sum(1 for r in results if isinstance(r, dict) and 'error' in r)\n",
    "        duration = time.time() - start_time\n",
    "        \n",
    "        if failed_count > 0:\n",
    "            safe_print(f\"Completed {simulation_id} in {duration:.1f}s - WARNING: {failed_count} participants failed\", \"WARN\")\n",
    "        else:\n",
    "            safe_print(f\"Completed {simulation_id} in {duration:.1f}s - All participants successful\", \"SUCCESS\")\n",
    "        \n",
    "        return (simulation_id, results)\n",
    "        \n",
    "    except Exception as e:\n",
    "        duration = time.time() - start_time\n",
    "        safe_print(f\"Failed {simulation_id} after {duration:.1f}s - Error: {str(e)}\", \"ERROR\")\n",
    "        return (simulation_id, {\"error\": str(e)})\n",
    "\n",
    "# Main execution\n",
    "print(\"=\"*80)\n",
    "print(\"STARTING PARALLEL SIMULATIONS\")\n",
    "print(f\"Models: {models_to_test}\")\n",
    "print(f\"Temperatures: {temperatures}\")\n",
    "print(f\"Total combinations: {len(models_to_test) * len(temperatures)}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "all_results = {}\n",
    "start_time = time.time()\n",
    "\n",
    "# Use ThreadPoolExecutor for parallel execution\n",
    "with ThreadPoolExecutor(max_workers=len(models_to_test)) as executor:\n",
    "    # Submit all jobs\n",
    "    futures = [\n",
    "        executor.submit(run_simulation, model, temperature)\n",
    "        for model in models_to_test\n",
    "        for temperature in temperatures\n",
    "    ]\n",
    "    \n",
    "    # Collect results as they complete\n",
    "    completed_count = 0\n",
    "    total_jobs = len(futures)\n",
    "    \n",
    "    for future in as_completed(futures):\n",
    "        key, result = future.result()\n",
    "        all_results[key] = result\n",
    "        completed_count += 1\n",
    "        \n",
    "        # Progress update\n",
    "        safe_print(f\"Progress: {completed_count}/{total_jobs} simulations completed\", \"PROGRESS\")\n",
    "\n",
    "total_duration = time.time() - start_time\n",
    "\n",
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SIMULATION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total time: {total_duration:.1f} seconds\")\n",
    "print(f\"Completed simulations: {len(all_results)}\")\n",
    "\n",
    "# Categorize results\n",
    "successful = []\n",
    "failed = []\n",
    "\n",
    "for key, result in all_results.items():\n",
    "    if isinstance(result, dict) and 'error' in result:\n",
    "        failed.append(key)\n",
    "    else:\n",
    "        # Check for partial failures\n",
    "        if isinstance(result, list):\n",
    "            failed_participants = sum(1 for r in result if isinstance(r, dict) and 'error' in r)\n",
    "            if failed_participants > 0:\n",
    "                print(f\"  {key}: SUCCESS (with {failed_participants} failed participants)\")\n",
    "            else:\n",
    "                print(f\"  {key}: SUCCESS\")\n",
    "            successful.append(key)\n",
    "        else:\n",
    "            successful.append(key)\n",
    "\n",
    "if failed:\n",
    "    print(f\"\\nFailed simulations ({len(failed)}):\")\n",
    "    for key in failed:\n",
    "        print(f\"  {key}: {all_results[key].get('error', 'Unknown error')}\")\n",
    "\n",
    "print(\"=\"*80)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STARTING PARALLEL SIMULATIONS\n",
      "Models: ['openai-gpt-3.5-turbo-0125']\n",
      "Temperatures: [1]\n",
      "Total combinations: 1\n",
      "================================================================================\n",
      "[15:44:32] START: Starting simulation: openai-gpt-3.5-turbo-0125 (temp=1)\n",
      "Starting simulation for 438 participants using openai-gpt-3.5-turbo-0125\n",
      "Temperature: 1, Batch size: 25\n",
      "Processing participants 0 to 24\n",
      "Completed batch 0 to 24\n",
      "Processing participants 25 to 49\n",
      "Completed batch 25 to 49\n",
      "Processing participants 50 to 74\n",
      "Completed batch 50 to 74\n",
      "Processing participants 75 to 99\n",
      "Completed batch 75 to 99\n",
      "Processing participants 100 to 124\n",
      "Completed batch 100 to 124\n",
      "Processing participants 125 to 149\n",
      "Completed batch 125 to 149\n",
      "Processing participants 150 to 174\n",
      "OpenAI API error: Request timed out.\n",
      "Error in get_personality_response: Request timed out.\n",
      "OpenAI API error: Request timed out.\n",
      "Error in get_personality_response: Request timed out.\n",
      "Completed batch 150 to 174\n",
      "Processing participants 175 to 199\n",
      "JSON parsing failed (attempt #1): Failed to parse JSON:\n",
      "{\n",
      "\"Bashful\": 2,\n",
      "\"Bold\": 4,\n",
      "\"Careless\": 4,\n",
      "\"Cold\": 2,\n",
      "\"Complex\": 4,\n",
      "\"Cooperative\": 5,\n",
      "\"Creative\": 4,\n",
      "\"Deep\": 3,\n",
      "\"Disorganized\": 5,\n",
      "\"Efficient\": 3,\n",
      "\"Energetic\": 4,\n",
      "\"Envious\": 2,\n",
      "\"Extraverted\": 5,\n",
      "\"Fretful\": 1,\n",
      "\"Harsh\": 2,\n",
      "\"Imaginative\": 3,\n",
      "\"Inefficient\": 5,\n",
      "\"Intellectual\": 3,\n",
      "\"Jealous\": 2,\n",
      "\"Kind\": 5,\n",
      "\"Moody\": 2,\n",
      "\"Organized\": 2,\n",
      "\"Philosophical\": 3,\n",
      "\"Practical\": 3,\n",
      "\"Quiet\": 2,\n",
      "\"Relaxed\": 5,\n",
      "\"Rude\": 2,\n",
      "\"Shy\": 3,\n",
      "\"Sloppy\": 4,\n",
      "\"Sympathetic\": 5,\n",
      "\"Systematic\": 2,\n",
      "\"Talkative\": 2,\n",
      "\"Temperamental\": 4,\n",
      "\"Touchy\": 2,\n",
      "\"Uncreative\": 4,\n",
      "\"Unenvious\": 5,\n",
      "\"Unintellectual\": 4,\n",
      "\"Unsympathetic\": 2,\n",
      "\"Warm\": 5,\n",
      "\"Withdrawn: 2\n",
      "}\n",
      "Error: unterminated string literal (detected at line 41) (<unknown>, line 41)\n",
      "Completed batch 175 to 199\n",
      "Processing participants 200 to 224\n",
      "Completed batch 200 to 224\n",
      "Processing participants 225 to 249\n",
      "Completed batch 225 to 249\n",
      "Processing participants 250 to 274\n",
      "Completed batch 250 to 274\n",
      "Processing participants 275 to 299\n",
      "Completed batch 275 to 299\n",
      "Processing participants 300 to 324\n",
      "Completed batch 300 to 324\n",
      "Processing participants 325 to 349\n",
      "Completed batch 325 to 349\n",
      "Processing participants 350 to 374\n",
      "Completed batch 350 to 374\n",
      "Processing participants 375 to 399\n",
      "Completed batch 375 to 399\n",
      "Processing participants 400 to 424\n",
      "Completed batch 400 to 424\n",
      "Processing participants 425 to 437\n",
      "Completed batch 425 to 437\n",
      "Results saved to study_2_likert_results/bfi_to_minimarker_openai_gpt_3.5_turbo_0125_temp1.json\n",
      "[15:50:23] SUCCESS: Completed openai-gpt-3.5-turbo-0125_temp1 in 351.4s - All participants successful\n",
      "[15:50:23] PROGRESS: Progress: 1/1 simulations completed\n",
      "\n",
      "================================================================================\n",
      "SIMULATION SUMMARY\n",
      "================================================================================\n",
      "Total time: 351.4 seconds\n",
      "Completed simulations: 1\n",
      "  openai-gpt-3.5-turbo-0125_temp1: SUCCESS\n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retry Failed Participants (if any)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T07:50:23.670215Z",
     "start_time": "2025-06-28T07:50:23.666064Z"
    }
   },
   "source": [
    "# Retry any failed participants\n",
    "for key, results in all_results.items():\n",
    "    if isinstance(results, list):\n",
    "        failed_count = sum(1 for r in results if isinstance(r, dict) and 'error' in r)\n",
    "        if failed_count > 0:\n",
    "            print(f\"Retrying {failed_count} failed participants for {key}\")\n",
    "            \n",
    "            # Extract model and temperature from key\n",
    "            model = key.split('_temp')[0]\n",
    "            temperature = float(key.split('_temp')[1])\n",
    "            \n",
    "            config = SimulationConfig(\n",
    "                model=model,\n",
    "                temperature=temperature,\n",
    "                batch_size=batch_size\n",
    "            )\n",
    "            \n",
    "            updated_results = retry_failed_participants(\n",
    "                results=results,\n",
    "                participants_data=participants_data,\n",
    "                prompt_generator=get_likert_prompt,  # Use likert-specific prompt function\n",
    "                config=config,\n",
    "                personality_key='combined_bfi2'\n",
    "            )\n",
    "            \n",
    "            all_results[key] = updated_results\n",
    "            \n",
    "            # Save updated results\n",
    "            from simulation_utils import save_simulation_results\n",
    "            save_simulation_results(updated_results, \"study_2_likert_results\", \"bfi_to_minimarker_likert_retried\", config)\n",
    "\n",
    "print(\"Retry process completed\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retry process completed\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T07:50:23.874781Z",
     "start_time": "2025-06-28T07:50:23.867911Z"
    }
   },
   "source": [
    "# Analyze results summary\n",
    "print(\"Likert Format Simulation Results Summary:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for key, results in all_results.items():\n",
    "    if isinstance(results, list):\n",
    "        total_participants = len(results)\n",
    "        successful = sum(1 for r in results if not (isinstance(r, dict) and 'error' in r))\n",
    "        failed = total_participants - successful\n",
    "        success_rate = (successful / total_participants) * 100\n",
    "        \n",
    "        print(f\"{key}:\")\n",
    "        print(f\"  Total: {total_participants}, Successful: {successful}, Failed: {failed}\")\n",
    "        print(f\"  Success Rate: {success_rate:.1f}%\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"{key}: FAILED - {results.get('error', 'Unknown error')}\")\n",
    "        print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likert Format Simulation Results Summary:\n",
      "==================================================\n",
      "openai-gpt-3.5-turbo-0125_temp1:\n",
      "  Total: 438, Successful: 438, Failed: 0\n",
      "  Success Rate: 100.0%\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T07:50:24.009560Z",
     "start_time": "2025-06-28T07:50:23.908935Z"
    }
   },
   "source": [
    "# Save the preprocessed data for reference\n",
    "output_path = Path('study_2_likert_results')\n",
    "output_path.mkdir(exist_ok=True)\n",
    "\n",
    "data.to_csv(output_path / 'study2_likert_preprocessed_data.csv', index=False)\n",
    "print(f\"Preprocessed data saved to {output_path / 'study2_likert_preprocessed_data.csv'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LIKERT FORMAT SIMULATION COMPLETE!\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Run study_2_likert_analysis.ipynb for comprehensive analysis\")\n",
    "print(\"2. Results are saved in study_2_likert_results/ directory\")\n",
    "print(\"3. Compare with expanded format results for format comparison\")\n",
    "print(\"4. Preprocessed data available for validation\")\n",
    "print(\"=\"*60)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data saved to study_2_likert_results/study2_likert_preprocessed_data.csv\n",
      "\n",
      "============================================================\n",
      "LIKERT FORMAT SIMULATION COMPLETE!\n",
      "\n",
      "Next steps:\n",
      "1. Run study_2_likert_analysis.ipynb for comprehensive analysis\n",
      "2. Results are saved in study_2_likert_results/ directory\n",
      "3. Compare with expanded format results for format comparison\n",
      "4. Preprocessed data available for validation\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GenAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
