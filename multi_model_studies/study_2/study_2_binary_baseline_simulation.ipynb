{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Study 2: Binary Baseline Multi-Model Simulation\n",
    "\n",
    "This notebook implements a simplified binary baseline approach where personality is classified as simply \"high\" or \"low\" on each of the Big Five domains based on whether domain scores are above or below 50% (2.5 on the 1-5 scale).\n",
    "\n",
    "This serves as a baseline comparison to the more complex expanded and likert formats.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T08:19:48.317044Z",
     "start_time": "2025-06-29T08:19:46.731492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary baseline simulation utilities loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Add shared utilities to path\n",
    "sys.path.append('../shared')\n",
    "\n",
    "from simulation_utils import SimulationConfig, run_batch_simulation\n",
    "from binary_baseline_prompt import (\n",
    "    generate_binary_personality_description, \n",
    "    get_binary_prompt,\n",
    "    create_binary_participant_data\n",
    ")\n",
    "\n",
    "print(\"Binary baseline simulation utilities loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T08:19:50.257459Z",
     "start_time": "2025-06-29T08:19:48.333855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DEBUGGING DATA STRUCTURE ===\n",
      "Loaded 470 participants from Soto dataset\n",
      "\n",
      "Total columns: 704\n",
      "All columns: ['case_id', 'age', 'sex', 'ethnicity', 'rel_acquaintance', 'rel_friend', 'rel_roommate', 'rel_boygirlfriend', 'rel_relative', 'rel_other', 'rel_description', 'bfi1', 'bfi2', 'bfi3', 'bfi4', 'bfi5', 'bfi6', 'bfi7', 'bfi8', 'bfi9', 'bfi10', 'bfi11', 'bfi12', 'bfi13', 'bfi14', 'bfi15', 'bfi16', 'bfi17', 'bfi18', 'bfi19', 'bfi20', 'bfi21', 'bfi22', 'bfi23', 'bfi24', 'bfi25', 'bfi26', 'bfi27', 'bfi28', 'bfi29', 'bfi30', 'bfi31', 'bfi32', 'bfi33', 'bfi34', 'bfi35', 'bfi36', 'bfi37', 'bfi38', 'bfi39', 'bfi40', 'bfi41', 'bfi42', 'bfi43', 'bfi44', 'bfi45', 'bfi46', 'bfi47', 'bfi48', 'bfi49', 'bfi50', 'bfi51', 'bfi52', 'bfi53', 'bfi54', 'bfi55', 'bfi56', 'bfi57', 'bfi58', 'bfi59', 'bfi60', 'pbfi1', 'pbfi2', 'pbfi3', 'pbfi4', 'pbfi5', 'pbfi6', 'pbfi7', 'pbfi8', 'pbfi9', 'pbfi10', 'pbfi11', 'pbfi12', 'pbfi13', 'pbfi14', 'pbfi15', 'pbfi16', 'pbfi17', 'pbfi18', 'pbfi19', 'pbfi20', 'pbfi21', 'pbfi22', 'pbfi23', 'pbfi24', 'pbfi25', 'pbfi26', 'pbfi27', 'pbfi28', 'pbfi29', 'pbfi30', 'pbfi31', 'pbfi32', 'pbfi33', 'pbfi34', 'pbfi35', 'pbfi36', 'pbfi37', 'pbfi38', 'pbfi39', 'pbfi40', 'pbfi41', 'pbfi42', 'pbfi43', 'pbfi44', 'pbfi45', 'pbfi46', 'pbfi47', 'pbfi48', 'pbfi49', 'pbfi50', 'pbfi51', 'pbfi52', 'pbfi53', 'pbfi54', 'pbfi55', 'pbfi56', 'pbfi57', 'pbfi58', 'pbfi59', 'pbfi60', 'sbfi1', 'sbfi2', 'sbfi3', 'sbfi4', 'sbfi5', 'sbfi6', 'sbfi7', 'sbfi8', 'sbfi9', 'sbfi10', 'sbfi11', 'sbfi12', 'sbfi13', 'sbfi14', 'sbfi15', 'sbfi16', 'sbfi17', 'sbfi18', 'sbfi19', 'sbfi20', 'sbfi21', 'sbfi22', 'sbfi23', 'sbfi24', 'sbfi25', 'sbfi26', 'sbfi27', 'sbfi28', 'sbfi29', 'sbfi30', 'sbfi31', 'sbfi32', 'sbfi33', 'sbfi34', 'sbfi35', 'sbfi36', 'sbfi37', 'sbfi38', 'sbfi39', 'sbfi40', 'sbfi41', 'sbfi42', 'sbfi43', 'sbfi44', 'sbfi45', 'sbfi46', 'sbfi47', 'sbfi48', 'sbfi49', 'sbfi50', 'sbfi51', 'sbfi52', 'sbfi53', 'sbfi54', 'sbfi55', 'sbfi56', 'sbfi57', 'sbfi58', 'sbfi59', 'sbfi60', 'bfi2_e_sociability', 'bfi2_e_assertiveness', 'bfi2_e_energy_level', 'bfi2_a_compassion', 'bfi2_a_respectfulness', 'bfi2_a_trust', 'bfi2_c_organization', 'bfi2_c_productiveness', 'bfi2_c_responsibility', 'bfi2_n_anxiety', 'bfi2_n_depression', 'bfi2_n_emotional_volatility', 'bfi2_o_intellectual_curiosity', 'bfi2_o_aesthetic_sensitivity', 'bfi2_o_creative_imagination', 'bfi2_e', 'bfi2_a', 'bfi2_c', 'bfi2_n', 'bfi2_o', 'pbfi2_e_sociability', 'pbfi2_e_assertiveness', 'pbfi2_e_energy_level', 'pbfi2_a_compassion', 'pbfi2_a_respectfulness', 'pbfi2_a_trust', 'pbfi2_c_organization', 'pbfi2_c_productiveness', 'pbfi2_c_responsibility', 'pbfi2_n_anxiety', 'pbfi2_n_depression', 'pbfi2_n_emotional_volatility', 'pbfi2_o_intellectual_curiosity', 'pbfi2_o_aesthetic_sensitivity', 'pbfi2_o_creative_imagination', 'pbfi2_e', 'pbfi2_a', 'pbfi2_c', 'pbfi2_n', 'pbfi2_o', 'sbfi2_e_sociability', 'sbfi2_e_assertiveness', 'sbfi2_e_energy_level', 'sbfi2_a_compassion', 'sbfi2_a_respectfulness', 'sbfi2_a_trust', 'sbfi2_c_organization', 'sbfi2_c_productiveness', 'sbfi2_c_responsibility', 'sbfi2_n_anxiety', 'sbfi2_n_depression', 'sbfi2_n_emotional_volatility', 'sbfi2_o_intellectual_curiosity', 'sbfi2_o_aesthetic_sensitivity', 'sbfi2_o_creative_imagination', 'sbfi2_e', 'sbfi2_a', 'sbfi2_c', 'sbfi2_n', 'sbfi2_o', 'tda1', 'tda2', 'tda3', 'tda4', 'tda5', 'tda6', 'tda7', 'tda8', 'tda9', 'tda10', 'tda11', 'tda12', 'tda13', 'tda14', 'tda15', 'tda16', 'tda17', 'tda18', 'tda19', 'tda20', 'tda21', 'tda22', 'tda23', 'tda24', 'tda25', 'tda26', 'tda27', 'tda28', 'tda29', 'tda30', 'tda31', 'tda32', 'tda33', 'tda34', 'tda35', 'tda36', 'tda37', 'tda38', 'tda39', 'tda40', 'bfas1', 'bfas2', 'bfas3', 'bfas4', 'bfas5', 'bfas6', 'bfas7', 'bfas8', 'bfas9', 'bfas10', 'bfas11', 'bfas12', 'bfas13', 'bfas14', 'bfas15', 'bfas16', 'bfas17', 'bfas18', 'bfas19', 'bfas20', 'bfas21', 'bfas22', 'bfas23', 'bfas24', 'bfas25', 'bfas26', 'bfas27', 'bfas28', 'bfas29', 'bfas30', 'bfas31', 'bfas32', 'bfas33', 'bfas34', 'bfas35', 'bfas36', 'bfas37', 'bfas38', 'bfas39', 'bfas40', 'bfas41', 'bfas42', 'bfas43', 'bfas44', 'bfas45', 'bfas46', 'bfas47', 'bfas48', 'bfas49', 'bfas50', 'bfas51', 'bfas52', 'bfas53', 'bfas54', 'bfas55', 'bfas56', 'bfas57', 'bfas58', 'bfas59', 'bfas60', 'bfas61', 'bfas62', 'bfas63', 'bfas64', 'bfas65', 'bfas66', 'bfas67', 'bfas68', 'bfas69', 'bfas70', 'bfas71', 'bfas72', 'bfas73', 'bfas74', 'bfas75', 'bfas76', 'bfas77', 'bfas78', 'bfas79', 'bfas80', 'bfas81', 'bfas82', 'bfas83', 'bfas84', 'bfas85', 'bfas86', 'bfas87', 'bfas88', 'bfas89', 'bfas90', 'bfas91', 'bfas92', 'bfas93', 'bfas94', 'bfas95', 'bfas96', 'bfas97', 'bfas98', 'bfas99', 'bfas100', 'neo1', 'neo2', 'neo3', 'neo4', 'neo5', 'neo6', 'neo7', 'neo8', 'neo9', 'neo10', 'neo11', 'neo12', 'neo13', 'neo14', 'neo15', 'neo16', 'neo17', 'neo18', 'neo19', 'neo20', 'neo21', 'neo22', 'neo23', 'neo24', 'neo25', 'neo26', 'neo27', 'neo28', 'neo29', 'neo30', 'neo31', 'neo32', 'neo33', 'neo34', 'neo35', 'neo36', 'neo37', 'neo38', 'neo39', 'neo40', 'neo41', 'neo42', 'neo43', 'neo44', 'neo45', 'neo46', 'neo47', 'neo48', 'neo49', 'neo50', 'neo51', 'neo52', 'neo53', 'neo54', 'neo55', 'neo56', 'neo57', 'neo58', 'neo59', 'neo60', 'neo61', 'neo62', 'neo63', 'neo64', 'neo65', 'neo66', 'neo67', 'neo68', 'neo69', 'neo70', 'neo71', 'neo72', 'neo73', 'neo74', 'neo75', 'neo76', 'neo77', 'neo78', 'neo79', 'neo80', 'neo81', 'neo82', 'neo83', 'neo84', 'neo85', 'neo86', 'neo87', 'neo88', 'neo89', 'neo90', 'neo91', 'neo92', 'neo93', 'neo94', 'neo95', 'neo96', 'neo97', 'neo98', 'neo99', 'neo100', 'neo101', 'neo102', 'neo103', 'neo104', 'neo105', 'neo106', 'neo107', 'neo108', 'neo109', 'neo110', 'neo111', 'neo112', 'neo113', 'neo114', 'neo115', 'neo116', 'neo117', 'neo118', 'neo119', 'neo120', 'neo121', 'neo122', 'neo123', 'neo124', 'neo125', 'neo126', 'neo127', 'neo128', 'neo129', 'neo130', 'neo131', 'neo132', 'neo133', 'neo134', 'neo135', 'neo136', 'neo137', 'neo138', 'neo139', 'neo140', 'neo141', 'neo142', 'neo143', 'neo144', 'neo145', 'neo146', 'neo147', 'neo148', 'neo149', 'neo150', 'neo151', 'neo152', 'neo153', 'neo154', 'neo155', 'neo156', 'neo157', 'neo158', 'neo159', 'neo160', 'neo161', 'neo162', 'neo163', 'neo164', 'neo165', 'neo166', 'neo167', 'neo168', 'neo169', 'neo170', 'neo171', 'neo172', 'neo173', 'neo174', 'neo175', 'neo176', 'neo177', 'neo178', 'neo179', 'neo180', 'neo181', 'neo182', 'neo183', 'neo184', 'neo185', 'neo186', 'neo187', 'neo188', 'neo189', 'neo190', 'neo191', 'neo192', 'neo193', 'neo194', 'neo195', 'neo196', 'neo197', 'neo198', 'neo199', 'neo200', 'neo201', 'neo202', 'neo203', 'neo204', 'neo205', 'neo206', 'neo207', 'neo208', 'neo209', 'neo210', 'neo211', 'neo212', 'neo213', 'neo214', 'neo215', 'neo216', 'neo217', 'neo218', 'neo219', 'neo220', 'neo221', 'neo222', 'neo223', 'neo224', 'neo225', 'neo226', 'neo227', 'neo228', 'neo229', 'neo230', 'neo231', 'neo232', 'neo233', 'neo234', 'neo235', 'neo236', 'neo237', 'neo238', 'neo239', 'neo240', 'tda_e', 'tda_a', 'tda_c', 'tda_n', 'tda_o', 'bfas_e', 'bfas_a', 'bfas_c', 'bfas_n', 'bfas_o', 'bfas_e_ent', 'bfas_e_ass', 'bfas_a_com', 'bfas_a_pol', 'bfas_c_ind', 'bfas_c_ord', 'bfas_n_wit', 'bfas_n_vol', 'bfas_o_int', 'bfas_o_ope', 'ffi_e', 'ffi_a', 'ffi_c', 'ffi_n', 'ffi_o', 'ffi_e_pos', 'ffi_e_soc', 'ffi_e_act', 'ffi_a_non', 'ffi_a_pro', 'ffi_c_ord', 'ffi_c_goa', 'ffi_c_dep', 'ffi_n_neg', 'ffi_n_sel', 'ffi_o_aes', 'ffi_o_int', 'ffi_o_unc', 'tneo_e', 'tneo_a', 'tneo_c', 'tneo_n', 'tneo_o', 'tneo_e1_war', 'tneo_e2_gre', 'tneo_e3_ass', 'tneo_e4_act', 'tneo_e5_exc', 'tneo_e6_pos', 'tneo_a1_tru', 'tneo_a2_str', 'tneo_a3_alt', 'tneo_a4_com', 'tneo_a5_mod', 'tneo_a6_ten', 'tneo_c1_com', 'tneo_c2_ord', 'tneo_c3_dut', 'tneo_c4_ach', 'tneo_c5_sel', 'tneo_c6_del', 'tneo_n1_anx', 'tneo_n2_ang', 'tneo_n3_dep', 'tneo_n4_sel', 'tneo_n5_imp', 'tneo_n6_vul', 'tneo_o1_fan', 'tneo_o2_aes', 'tneo_o3_fee', 'tneo_o4_act', 'tneo_o5_ide', 'tneo_o6_val']\n",
      "\n",
      "BFI-related columns found: ['bfi1', 'bfi2', 'bfi3', 'bfi4', 'bfi5', 'bfi6', 'bfi7', 'bfi8', 'bfi9', 'bfi10', 'bfi11', 'bfi12', 'bfi13', 'bfi14', 'bfi15', 'bfi16', 'bfi17', 'bfi18', 'bfi19', 'bfi20', 'bfi21', 'bfi22', 'bfi23', 'bfi24', 'bfi25', 'bfi26', 'bfi27', 'bfi28', 'bfi29', 'bfi30', 'bfi31', 'bfi32', 'bfi33', 'bfi34', 'bfi35', 'bfi36', 'bfi37', 'bfi38', 'bfi39', 'bfi40', 'bfi41', 'bfi42', 'bfi43', 'bfi44', 'bfi45', 'bfi46', 'bfi47', 'bfi48', 'bfi49', 'bfi50', 'bfi51', 'bfi52', 'bfi53', 'bfi54', 'bfi55', 'bfi56', 'bfi57', 'bfi58', 'bfi59', 'bfi60', 'pbfi1', 'pbfi2', 'pbfi3', 'pbfi4', 'pbfi5', 'pbfi6', 'pbfi7', 'pbfi8', 'pbfi9', 'pbfi10', 'pbfi11', 'pbfi12', 'pbfi13', 'pbfi14', 'pbfi15', 'pbfi16', 'pbfi17', 'pbfi18', 'pbfi19', 'pbfi20', 'pbfi21', 'pbfi22', 'pbfi23', 'pbfi24', 'pbfi25', 'pbfi26', 'pbfi27', 'pbfi28', 'pbfi29', 'pbfi30', 'pbfi31', 'pbfi32', 'pbfi33', 'pbfi34', 'pbfi35', 'pbfi36', 'pbfi37', 'pbfi38', 'pbfi39', 'pbfi40', 'pbfi41', 'pbfi42', 'pbfi43', 'pbfi44', 'pbfi45', 'pbfi46', 'pbfi47', 'pbfi48', 'pbfi49', 'pbfi50', 'pbfi51', 'pbfi52', 'pbfi53', 'pbfi54', 'pbfi55', 'pbfi56', 'pbfi57', 'pbfi58', 'pbfi59', 'pbfi60', 'sbfi1', 'sbfi2', 'sbfi3', 'sbfi4', 'sbfi5', 'sbfi6', 'sbfi7', 'sbfi8', 'sbfi9', 'sbfi10', 'sbfi11', 'sbfi12', 'sbfi13', 'sbfi14', 'sbfi15', 'sbfi16', 'sbfi17', 'sbfi18', 'sbfi19', 'sbfi20', 'sbfi21', 'sbfi22', 'sbfi23', 'sbfi24', 'sbfi25', 'sbfi26', 'sbfi27', 'sbfi28', 'sbfi29', 'sbfi30', 'sbfi31', 'sbfi32', 'sbfi33', 'sbfi34', 'sbfi35', 'sbfi36', 'sbfi37', 'sbfi38', 'sbfi39', 'sbfi40', 'sbfi41', 'sbfi42', 'sbfi43', 'sbfi44', 'sbfi45', 'sbfi46', 'sbfi47', 'sbfi48', 'sbfi49', 'sbfi50', 'sbfi51', 'sbfi52', 'sbfi53', 'sbfi54', 'sbfi55', 'sbfi56', 'sbfi57', 'sbfi58', 'sbfi59', 'sbfi60', 'bfi2_e_sociability', 'bfi2_e_assertiveness', 'bfi2_e_energy_level', 'bfi2_a_compassion', 'bfi2_a_respectfulness', 'bfi2_a_trust', 'bfi2_c_organization', 'bfi2_c_productiveness', 'bfi2_c_responsibility', 'bfi2_n_anxiety', 'bfi2_n_depression', 'bfi2_n_emotional_volatility', 'bfi2_o_intellectual_curiosity', 'bfi2_o_aesthetic_sensitivity', 'bfi2_o_creative_imagination', 'bfi2_e', 'bfi2_a', 'bfi2_c', 'bfi2_n', 'bfi2_o', 'pbfi2_e_sociability', 'pbfi2_e_assertiveness', 'pbfi2_e_energy_level', 'pbfi2_a_compassion', 'pbfi2_a_respectfulness', 'pbfi2_a_trust', 'pbfi2_c_organization', 'pbfi2_c_productiveness', 'pbfi2_c_responsibility', 'pbfi2_n_anxiety', 'pbfi2_n_depression', 'pbfi2_n_emotional_volatility', 'pbfi2_o_intellectual_curiosity', 'pbfi2_o_aesthetic_sensitivity', 'pbfi2_o_creative_imagination', 'pbfi2_e', 'pbfi2_a', 'pbfi2_c', 'pbfi2_n', 'pbfi2_o', 'sbfi2_e_sociability', 'sbfi2_e_assertiveness', 'sbfi2_e_energy_level', 'sbfi2_a_compassion', 'sbfi2_a_respectfulness', 'sbfi2_a_trust', 'sbfi2_c_organization', 'sbfi2_c_productiveness', 'sbfi2_c_responsibility', 'sbfi2_n_anxiety', 'sbfi2_n_depression', 'sbfi2_n_emotional_volatility', 'sbfi2_o_intellectual_curiosity', 'sbfi2_o_aesthetic_sensitivity', 'sbfi2_o_creative_imagination', 'sbfi2_e', 'sbfi2_a', 'sbfi2_c', 'sbfi2_n', 'sbfi2_o']\n",
      "\n",
      "Domain score columns found: ['rel_acquaintance', 'rel_other', 'bfi2_e_sociability', 'bfi2_e_assertiveness', 'bfi2_e_energy_level', 'bfi2_a_compassion', 'bfi2_a_respectfulness', 'bfi2_a_trust', 'bfi2_c_organization', 'bfi2_c_productiveness', 'bfi2_c_responsibility', 'bfi2_n_anxiety', 'bfi2_n_depression', 'bfi2_n_emotional_volatility', 'bfi2_o_intellectual_curiosity', 'bfi2_o_aesthetic_sensitivity', 'bfi2_o_creative_imagination', 'bfi2_e', 'bfi2_a', 'bfi2_c', 'bfi2_n', 'bfi2_o', 'pbfi2_e_sociability', 'pbfi2_e_assertiveness', 'pbfi2_e_energy_level', 'pbfi2_a_compassion', 'pbfi2_a_respectfulness', 'pbfi2_a_trust', 'pbfi2_c_organization', 'pbfi2_c_productiveness', 'pbfi2_c_responsibility', 'pbfi2_n_anxiety', 'pbfi2_n_depression', 'pbfi2_n_emotional_volatility', 'pbfi2_o_intellectual_curiosity', 'pbfi2_o_aesthetic_sensitivity', 'pbfi2_o_creative_imagination', 'pbfi2_e', 'pbfi2_a', 'pbfi2_c', 'pbfi2_n', 'pbfi2_o', 'sbfi2_e_sociability', 'sbfi2_e_assertiveness', 'sbfi2_e_energy_level', 'sbfi2_a_compassion', 'sbfi2_a_respectfulness', 'sbfi2_a_trust', 'sbfi2_c_organization', 'sbfi2_c_productiveness', 'sbfi2_c_responsibility', 'sbfi2_n_anxiety', 'sbfi2_n_depression', 'sbfi2_n_emotional_volatility', 'sbfi2_o_intellectual_curiosity', 'sbfi2_o_aesthetic_sensitivity', 'sbfi2_o_creative_imagination', 'sbfi2_e', 'sbfi2_a', 'sbfi2_c', 'sbfi2_n', 'sbfi2_o', 'tda_e', 'tda_a', 'tda_c', 'tda_n', 'tda_o', 'bfas_e', 'bfas_a', 'bfas_c', 'bfas_n', 'bfas_o', 'bfas_e_ent', 'bfas_e_ass', 'bfas_a_com', 'bfas_a_pol', 'bfas_c_ind', 'bfas_c_ord', 'bfas_n_wit', 'bfas_n_vol', 'bfas_o_int', 'bfas_o_ope', 'ffi_e', 'ffi_a', 'ffi_c', 'ffi_n', 'ffi_o', 'ffi_e_pos', 'ffi_e_soc', 'ffi_e_act', 'ffi_a_non', 'ffi_a_pro', 'ffi_c_ord', 'ffi_c_goa', 'ffi_c_dep', 'ffi_n_neg', 'ffi_n_sel', 'ffi_o_aes', 'ffi_o_int', 'ffi_o_unc', 'tneo_e', 'tneo_a', 'tneo_c', 'tneo_n', 'tneo_o', 'tneo_e1_war', 'tneo_e2_gre', 'tneo_e3_ass', 'tneo_e4_act', 'tneo_e5_exc', 'tneo_e6_pos', 'tneo_a1_tru', 'tneo_a2_str', 'tneo_a3_alt', 'tneo_a4_com', 'tneo_a5_mod', 'tneo_a6_ten', 'tneo_c1_com', 'tneo_c2_ord', 'tneo_c3_dut', 'tneo_c4_ach', 'tneo_c5_sel', 'tneo_c6_del', 'tneo_n1_anx', 'tneo_n2_ang', 'tneo_n3_dep', 'tneo_n4_sel', 'tneo_n5_imp', 'tneo_n6_vul', 'tneo_o1_fan', 'tneo_o2_aes', 'tneo_o3_fee', 'tneo_o4_act', 'tneo_o5_ide', 'tneo_o6_val']\n",
      "\n",
      "Sample BFI data:\n",
      "   bfi1  bfi2  bfi3  bfi4  bfi5  bfi6  bfi7  bfi8  bfi9  bfi10  ...  \\\n",
      "0     5     5     2     3     2     4     5     4     5      2  ...   \n",
      "1     4     4     4     4     4     2     4     4     4      4  ...   \n",
      "2     1     5     2     4     2     3     5     4     2      5  ...   \n",
      "3     4     4     4     2     4     3     4     4     2      5  ...   \n",
      "4     3     4     1     3     2     4     4     2     3      4  ...   \n",
      "\n",
      "   sbfi2_n_depression  sbfi2_n_emotional_volatility  \\\n",
      "0                 NaN                           NaN   \n",
      "1                 NaN                           NaN   \n",
      "2                 NaN                           NaN   \n",
      "3                 NaN                           NaN   \n",
      "4                 NaN                           NaN   \n",
      "\n",
      "   sbfi2_o_intellectual_curiosity  sbfi2_o_aesthetic_sensitivity  \\\n",
      "0                             NaN                            NaN   \n",
      "1                             NaN                            NaN   \n",
      "2                             NaN                            NaN   \n",
      "3                             NaN                            NaN   \n",
      "4                             NaN                            NaN   \n",
      "\n",
      "   sbfi2_o_creative_imagination  sbfi2_e  sbfi2_a  sbfi2_c  sbfi2_n  sbfi2_o  \n",
      "0                           NaN      NaN      NaN      NaN      NaN      NaN  \n",
      "1                           NaN      NaN      NaN      NaN      NaN      NaN  \n",
      "2                           NaN      NaN      NaN      NaN      NaN      NaN  \n",
      "3                           NaN      NaN      NaN      NaN      NaN      NaN  \n",
      "4                           NaN      NaN      NaN      NaN      NaN      NaN  \n",
      "\n",
      "[5 rows x 240 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load and examine the data structure\n",
    "print(\"=== DEBUGGING DATA STRUCTURE ===\")\n",
    "\n",
    "# Load the original Soto dataset\n",
    "data_path = Path('../../raw_data/Soto_data.xlsx')\n",
    "if not data_path.exists():\n",
    "    print(f\"Error: Data file not found at {data_path}\")\n",
    "    exit()\n",
    "\n",
    "data = pd.read_excel(data_path)\n",
    "print(f\"Loaded {len(data)} participants from Soto dataset\")\n",
    "\n",
    "# Check ALL available columns\n",
    "print(f\"\\nTotal columns: {len(data.columns)}\")\n",
    "print(f\"All columns: {list(data.columns)}\")\n",
    "\n",
    "# Check specifically for BFI columns\n",
    "bfi_cols = [col for col in data.columns if 'bfi' in col.lower()]\n",
    "print(f\"\\nBFI-related columns found: {bfi_cols}\")\n",
    "\n",
    "# Check for domain score columns specifically\n",
    "domain_cols = [col for col in data.columns if any(domain in col for domain in ['_e', '_a', '_c', '_n', '_o'])]\n",
    "print(f\"\\nDomain score columns found: {domain_cols}\")\n",
    "\n",
    "# Show sample data for BFI domain columns\n",
    "if len(bfi_cols) > 0:\n",
    "    print(f\"\\nSample BFI data:\")\n",
    "    print(data[bfi_cols].head())\n",
    "else:\n",
    "    print(\"\\nNo BFI columns found - showing first 10 columns:\")\n",
    "    print(data.iloc[:5, :10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T08:19:50.330738Z",
     "start_time": "2025-06-29T08:19:50.306227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CREATING PARTICIPANT DATA ===\n",
      "Using BFI-2 format columns\n",
      "Created 470 participant records\n",
      "\n",
      "Sample participant data:\n",
      "Participant 1: {'participant_id': 0, 'bfi2_e': 4.083333333333333, 'bfi2_a': 4.583333333333333, 'bfi2_c': 3.1666666666666665, 'bfi2_n': 2.4166666666666665, 'bfi2_o': 3.1666666666666665}\n",
      "Participant 2: {'participant_id': 1, 'bfi2_e': 2.9166666666666665, 'bfi2_a': 3.1666666666666665, 'bfi2_c': 3.0, 'bfi2_n': 3.0, 'bfi2_o': 3.3333333333333335}\n",
      "Participant 3: {'participant_id': 2, 'bfi2_e': 2.0833333333333335, 'bfi2_a': 4.083333333333333, 'bfi2_c': 3.8333333333333335, 'bfi2_n': 3.1666666666666665, 'bfi2_o': 4.416666666666667}\n",
      "\n",
      "=== GENERATING BINARY DESCRIPTIONS ===\n",
      "\n",
      "Sample binary personality descriptions:\n",
      "\n",
      "Participant 1:\n",
      "Domain scores: E=4.08, A=4.58, C=3.17, N=2.42, O=3.17\n",
      "Binary description: You are high in Extraversion. You are outgoing, sociable, assertive, and energetic. You are high in Agreeableness. You are compassionate, cooperative, trusting, and kind to others. You are high in Con...\n",
      "\n",
      "Participant 2:\n",
      "Domain scores: E=2.92, A=3.17, C=3.00, N=3.00, O=3.33\n",
      "Binary description: You are high in Extraversion. You are outgoing, sociable, assertive, and energetic. You are high in Agreeableness. You are compassionate, cooperative, trusting, and kind to others. You are high in Con...\n"
     ]
    }
   ],
   "source": [
    "# Create participant data with correct column names\n",
    "print(\"=== CREATING PARTICIPANT DATA ===\")\n",
    "\n",
    "# Use the actual column names found in the data\n",
    "participants_data = []\n",
    "\n",
    "# First, let's identify the correct BFI domain columns\n",
    "if 'bfi2_e' in data.columns:\n",
    "    # Use BFI-2 format\n",
    "    domain_columns = {\n",
    "        'bfi2_e': 'bfi2_e',\n",
    "        'bfi2_a': 'bfi2_a', \n",
    "        'bfi2_c': 'bfi2_c',\n",
    "        'bfi2_n': 'bfi2_n',\n",
    "        'bfi2_o': 'bfi2_o'\n",
    "    }\n",
    "    print(\"Using BFI-2 format columns\")\n",
    "elif 'bfi_e' in data.columns:\n",
    "    # Use alternative BFI format\n",
    "    domain_columns = {\n",
    "        'bfi2_e': 'bfi_e',\n",
    "        'bfi2_a': 'bfi_a', \n",
    "        'bfi2_c': 'bfi_c',\n",
    "        'bfi2_n': 'bfi_n',\n",
    "        'bfi2_o': 'bfi_o'\n",
    "    }\n",
    "    print(\"Using alternative BFI format columns\")\n",
    "else:\n",
    "    # Need to find the correct columns\n",
    "    print(\"ERROR: Cannot find standard BFI domain columns\")\n",
    "    print(\"Available columns that might be domain scores:\")\n",
    "    potential_cols = [col for col in data.columns if any(x in col.lower() for x in ['extra', 'agree', 'consc', 'neuro', 'open'])]\n",
    "    print(potential_cols)\n",
    "    \n",
    "    # For now, let's stop and ask user to clarify\n",
    "    raise Exception(\"Cannot identify BFI domain columns. Please check the data structure above.\")\n",
    "\n",
    "# Create participant data\n",
    "for idx, row in data.iterrows():\n",
    "    participant = {'participant_id': idx}\n",
    "    \n",
    "    # Map the data columns to the expected binary baseline format\n",
    "    for expected_col, actual_col in domain_columns.items():\n",
    "        if actual_col in data.columns:\n",
    "            participant[expected_col] = row[actual_col]\n",
    "        else:\n",
    "            print(f\"Warning: Column {actual_col} not found in data\")\n",
    "    \n",
    "    participants_data.append(participant)\n",
    "\n",
    "print(f\"Created {len(participants_data)} participant records\")\n",
    "\n",
    "# Show sample participant data\n",
    "print(\"\\nSample participant data:\")\n",
    "for i in range(min(3, len(participants_data))):\n",
    "    print(f\"Participant {i+1}: {participants_data[i]}\")\n",
    "\n",
    "# Generate binary personality descriptions\n",
    "print(\"\\n=== GENERATING BINARY DESCRIPTIONS ===\")\n",
    "participants_with_binary = create_binary_participant_data(participants_data)\n",
    "\n",
    "# Display sample binary descriptions\n",
    "print(\"\\nSample binary personality descriptions:\")\n",
    "for i, p in enumerate(participants_with_binary[:2]):\n",
    "    print(f\"\\nParticipant {i+1}:\")\n",
    "    print(f\"Domain scores: E={p['bfi2_e']:.2f}, A={p['bfi2_a']:.2f}, C={p['bfi2_c']:.2f}, N={p['bfi2_n']:.2f}, O={p['bfi2_o']:.2f}\")\n",
    "    print(f\"Binary description: {p['binary_personality'][:200]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T08:19:50.344107Z",
     "start_time": "2025-06-29T08:19:50.340269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SIMULATION CONFIGURATION ===\n",
      "Models to test: ['openai-gpt-3.5-turbo-0125']\n",
      "Temperature: 1.0\n",
      "Batch size: 20\n",
      "Max workers: 8\n",
      "\n",
      "Results will be saved to: study_2_binary_results\n",
      "\n",
      "Sample prompt length: 2197 characters\n",
      "Sample prompt preview:\n",
      "### Your Assigned Personality ### \n",
      "Based on your personality profile below, please rate yourself on the following traits. Consider how each trait applies to your high/low personality classification.\n",
      "You are high in Extraversion. You are outgoing, sociable, assertive, and energetic. You are high in A...\n"
     ]
    }
   ],
   "source": [
    "# Configure simulation parameters\n",
    "print(\"=== SIMULATION CONFIGURATION ===\")\n",
    "\n",
    "# Models to test - using correct model names from portal.py\n",
    "models_to_test = [\n",
    "    'openai-gpt-3.5-turbo-0125'\n",
    "    # \"gpt-4\",\n",
    "    # \"gpt-4o\", \n",
    "    # \"llama\",\n",
    "    # \"deepseek\",\n",
    "    # \"gpt-3.5-turbo\"  # Fixed model name\n",
    "]\n",
    "\n",
    "# Simulation parameters\n",
    "temperature = 1.0\n",
    "batch_size = 20\n",
    "max_workers = 8\n",
    "\n",
    "print(f\"Models to test: {models_to_test}\")\n",
    "print(f\"Temperature: {temperature}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Max workers: {max_workers}\")\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path(\"old_result/study_2_binary_results\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "print(f\"\\nResults will be saved to: {output_dir}\")\n",
    "\n",
    "# Test the prompt generator\n",
    "def binary_baseline_prompt_generator(personality_description):\n",
    "    \"\"\"\n",
    "    Generate a binary baseline prompt for a participant.\n",
    "    \n",
    "    Args:\n",
    "        personality_description (str): Binary personality description \n",
    "        \n",
    "    Returns:\n",
    "        str: Complete prompt for the LLM\n",
    "    \"\"\"\n",
    "    return get_binary_prompt(personality_description)\n",
    "\n",
    "# Test the prompt generator with first participant\n",
    "if participants_with_binary:\n",
    "    sample_personality = participants_with_binary[0]['binary_personality']\n",
    "    sample_prompt = binary_baseline_prompt_generator(sample_personality)\n",
    "    print(f\"\\nSample prompt length: {len(sample_prompt)} characters\")\n",
    "    print(\"Sample prompt preview:\")\n",
    "    print(sample_prompt[:300] + \"...\")\n",
    "else:\n",
    "    print(\"No participants available for testing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T08:25:00.757383Z",
     "start_time": "2025-06-29T08:19:50.365277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RUNNING BINARY BASELINE SIMULATION ===\n",
      "\n",
      "==================================================\n",
      "Running binary baseline simulation with openai-gpt-3.5-turbo-0125\n",
      "==================================================\n",
      "Starting simulation for 470 participants using openai-gpt-3.5-turbo-0125\n",
      "Temperature: 1.0, Batch size: 20\n",
      "Processing participants 0 to 19\n",
      "Completed batch 0 to 19\n",
      "Processing participants 20 to 39\n",
      "Completed batch 20 to 39\n",
      "Processing participants 40 to 59\n",
      "Completed batch 40 to 59\n",
      "Processing participants 60 to 79\n",
      "Completed batch 60 to 79\n",
      "Processing participants 80 to 99\n",
      "Completed batch 80 to 99\n",
      "Processing participants 100 to 119\n",
      "Completed batch 100 to 119\n",
      "Processing participants 120 to 139\n",
      "Completed batch 120 to 139\n",
      "Processing participants 140 to 159\n",
      "Completed batch 140 to 159\n",
      "Processing participants 160 to 179\n",
      "Completed batch 160 to 179\n",
      "Processing participants 180 to 199\n",
      "Completed batch 180 to 199\n",
      "Processing participants 200 to 219\n",
      "Completed batch 200 to 219\n",
      "Processing participants 220 to 239\n",
      "Completed batch 220 to 239\n",
      "Processing participants 240 to 259\n",
      "Completed batch 240 to 259\n",
      "Processing participants 260 to 279\n",
      "Completed batch 260 to 279\n",
      "Processing participants 280 to 299\n",
      "Completed batch 280 to 299\n",
      "Processing participants 300 to 319\n",
      "Completed batch 300 to 319\n",
      "Processing participants 320 to 339\n",
      "Completed batch 320 to 339\n",
      "Processing participants 340 to 359\n",
      "Completed batch 340 to 359\n",
      "Processing participants 360 to 379\n",
      "Completed batch 360 to 379\n",
      "Processing participants 380 to 399\n",
      "Completed batch 380 to 399\n",
      "Processing participants 400 to 419\n",
      "Completed batch 400 to 419\n",
      "Processing participants 420 to 439\n",
      "Completed batch 420 to 439\n",
      "Processing participants 440 to 459\n",
      "Completed batch 440 to 459\n",
      "Processing participants 460 to 469\n",
      "Completed batch 460 to 469\n",
      "Results saved to study_2_binary_results/bfi_to_minimarker_binary_openai_gpt_3.5_turbo_0125_temp1_0.json_openai_gpt_3.5_turbo_0125_temp1_0.json\n",
      "✓ Simulation completed for openai-gpt-3.5-turbo-0125\n",
      "  - Total participants: 470\n",
      "  - Successful responses: 470\n",
      "  - Failed responses: 0\n",
      "  - Results saved to: study_2_binary_results/bfi_to_minimarker_binary_openai_gpt_3.5_turbo_0125_temp1_0.json\n"
     ]
    }
   ],
   "source": [
    "# Run binary baseline simulation\n",
    "print(\"=== RUNNING BINARY BASELINE SIMULATION ===\")\n",
    "\n",
    "# Run simulation for each model\n",
    "all_results = {}\n",
    "\n",
    "for model in models_to_test:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Running binary baseline simulation with {model}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Create simulation configuration\n",
    "    config = SimulationConfig(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        batch_size=batch_size,\n",
    "        max_workers=max_workers\n",
    "    )\n",
    "    \n",
    "    # Create output filename\n",
    "    output_filename = f\"bfi_to_minimarker_binary_{model.replace('-', '_')}_temp{temperature:.0f}_0.json\"\n",
    "    \n",
    "    try:\n",
    "        # Run the simulation\n",
    "        results = run_batch_simulation(\n",
    "            participants_data=participants_with_binary,\n",
    "            prompt_generator=binary_baseline_prompt_generator,\n",
    "            config=config,\n",
    "            personality_key='binary_personality',\n",
    "            output_dir=str(output_dir),\n",
    "            output_filename=output_filename\n",
    "        )\n",
    "        \n",
    "        all_results[model] = results\n",
    "        \n",
    "        print(f\"✓ Simulation completed for {model}\")\n",
    "        print(f\"  - Total participants: {len(results)}\")\n",
    "        print(f\"  - Successful responses: {sum(1 for r in results if 'error' not in r)}\")\n",
    "        print(f\"  - Failed responses: {sum(1 for r in results if 'error' in r)}\")\n",
    "        print(f\"  - Results saved to: {output_dir / output_filename}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error running simulation for {model}: {str(e)}\")\n",
    "        all_results[model] = None\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Study 2: Binary Baseline Multi-Model Simulation\n",
    "\n",
    "This notebook implements a simplified binary baseline approach where personality is classified as simply \"high\" or \"low\" on each of the Big Five domains based on whether domain scores are above or below 50% (2.5 on the 1-5 scale).\n",
    "\n",
    "This serves as a baseline comparison to the more complex expanded and likert formats.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T08:08:25.814032Z",
     "start_time": "2025-06-29T08:08:24.102796Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary baseline simulation utilities loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Add shared utilities to path\n",
    "sys.path.append('../shared')\n",
    "\n",
    "from simulation_utils import SimulationConfig, run_batch_simulation\n",
    "from binary_baseline_prompt import (\n",
    "    generate_binary_personality_description, \n",
    "    get_binary_prompt,\n",
    "    create_binary_participant_data\n",
    ")\n",
    "\n",
    "print(\"Binary baseline simulation utilities loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Load and Prepare Participant Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T08:08:29.692658Z",
     "start_time": "2025-06-29T08:08:27.554924Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 470 participants from Soto dataset\n",
      "Available BFI domain columns: ['bfi2_e', 'bfi2_a', 'bfi2_c', 'bfi2_n', 'bfi2_o']\n",
      "\n",
      "Sample BFI domain scores:\n",
      "     bfi2_e    bfi2_a    bfi2_c    bfi2_n    bfi2_o\n",
      "0  4.083333  4.583333  3.166667  2.416667  3.166667\n",
      "1  2.916667  3.166667  3.000000  3.000000  3.333333\n",
      "2  2.083333  4.083333  3.833333  3.166667  4.416667\n",
      "3  3.333333  3.833333  2.416667  3.416667  4.000000\n",
      "4  3.250000  3.500000  4.500000  3.083333  3.333333\n"
     ]
    }
   ],
   "source": [
    "# Load the original Soto dataset with BFI-2 domain scores\n",
    "data_path = Path('../../raw_data/Soto_data.xlsx')\n",
    "if not data_path.exists():\n",
    "    print(f\"Error: Data file not found at {data_path}\")\n",
    "    print(\"Please ensure the Soto dataset is available in the raw_data directory\")\n",
    "else:\n",
    "    # Load the data\n",
    "    data = pd.read_excel(data_path)\n",
    "    print(f\"Loaded {len(data)} participants from Soto dataset\")\n",
    "    \n",
    "    # Check available columns for BFI domain scores\n",
    "    bfi_cols = [col for col in data.columns if col.startswith('bfi') and '_' in col and len(col) <= 6]\n",
    "    print(f\"Available BFI domain columns: {bfi_cols}\")\n",
    "    \n",
    "    # Display sample data\n",
    "    print(\"\\nSample BFI domain scores:\")\n",
    "    print(data[bfi_cols].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T08:08:35.960934Z",
     "start_time": "2025-06-29T08:08:35.931259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 470 participants for binary baseline simulation\n",
      "\n",
      "Sample binary personality descriptions:\n",
      "\n",
      "Participant 1:\n",
      "Domain scores: E=4.08, A=4.58, C=3.17, N=2.42, O=3.17\n",
      "Binary description: You are high in Extraversion. You are outgoing, sociable, assertive, and energetic. You are high in Agreeableness. You are compassionate, cooperative, trusting, and kind to others. You are high in Con...\n",
      "\n",
      "Participant 2:\n",
      "Domain scores: E=2.92, A=3.17, C=3.00, N=3.00, O=3.33\n",
      "Binary description: You are high in Extraversion. You are outgoing, sociable, assertive, and energetic. You are high in Agreeableness. You are compassionate, cooperative, trusting, and kind to others. You are high in Con...\n",
      "\n",
      "Participant 3:\n",
      "Domain scores: E=2.08, A=4.08, C=3.83, N=3.17, O=4.42\n",
      "Binary description: You are low in Extraversion. You are reserved, quiet, and prefer smaller social settings. You are high in Agreeableness. You are compassionate, cooperative, trusting, and kind to others. You are high ...\n"
     ]
    }
   ],
   "source": [
    "# Convert to participant list format for simulation\n",
    "participants_data = []\n",
    "\n",
    "for idx, row in data.iterrows():\n",
    "    participant = {\n",
    "        'participant_id': idx,\n",
    "        'bfi2_e': row['bfi2_e'],\n",
    "        'bfi2_a': row['bfi2_a'], \n",
    "        'bfi2_c': row['bfi2_c'],\n",
    "        'bfi2_n': row['bfi2_n'],\n",
    "        'bfi2_o': row['bfi2_o']\n",
    "    }\n",
    "    participants_data.append(participant)\n",
    "\n",
    "print(f\"Prepared {len(participants_data)} participants for binary baseline simulation\")\n",
    "\n",
    "# Generate binary personality descriptions\n",
    "participants_with_binary = create_binary_participant_data(participants_data)\n",
    "\n",
    "# Display sample binary descriptions\n",
    "print(\"\\nSample binary personality descriptions:\")\n",
    "for i, p in enumerate(participants_with_binary[:3]):\n",
    "    print(f\"\\nParticipant {i+1}:\")\n",
    "    print(f\"Domain scores: E={p['bfi2_e']:.2f}, A={p['bfi2_a']:.2f}, C={p['bfi2_c']:.2f}, N={p['bfi2_n']:.2f}, O={p['bfi2_o']:.2f}\")\n",
    "    print(f\"Binary description: {p['binary_personality'][:200]}...\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Configure Simulation Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T08:09:02.644670Z",
     "start_time": "2025-06-29T08:09:02.635089Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models to test: ['openai_gpt_3.5_turbo_0125']\n",
      "Temperature: 1.0\n",
      "Batch size: 20\n",
      "Max workers: 10\n",
      "\n",
      "Results will be saved to: study_2_binary_results\n"
     ]
    }
   ],
   "source": [
    "# Models to test\n",
    "models_to_test = [\n",
    "    # \"gpt-4\",\n",
    "    # \"gpt-4o\", \n",
    "    # \"llama\",\n",
    "    # \"deepseek\",\n",
    "    \"openai_gpt_3.5_turbo_0125\"\n",
    "]\n",
    "\n",
    "# Simulation parameters\n",
    "temperature = 1.0\n",
    "batch_size = 20\n",
    "max_workers = 10\n",
    "\n",
    "print(f\"Models to test: {models_to_test}\")\n",
    "print(f\"Temperature: {temperature}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Max workers: {max_workers}\")\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path(\"old_result/study_2_binary_results\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "print(f\"\\nResults will be saved to: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Define Binary Baseline Prompt Generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T08:09:08.154325Z",
     "start_time": "2025-06-29T08:09:08.145917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample binary baseline prompt (first 500 characters):\n",
      "### Your Assigned Personality ### \n",
      "Based on your personality profile below, please rate yourself on the following traits. Consider how each trait applies to your high/low personality classification.\n",
      "You are high in Extraversion. You are outgoing, sociable, assertive, and energetic. You are high in Agreeableness. You are compassionate, cooperative, trusting, and kind to others. You are high in Conscientiousness. You are organized, responsible, hardworking, and reliable. You are low in Neuroticism...\n"
     ]
    }
   ],
   "source": [
    "def binary_baseline_prompt_generator(participant_data):\n",
    "    \"\"\"\n",
    "    Generate a binary baseline prompt for a participant.\n",
    "    \n",
    "    Args:\n",
    "        participant_data (dict): Participant data with binary personality description\n",
    "        \n",
    "    Returns:\n",
    "        str: Complete prompt for the LLM\n",
    "    \"\"\"\n",
    "    if 'binary_personality' in participant_data:\n",
    "        personality_description = participant_data['binary_personality']\n",
    "    else:\n",
    "        # Generate on the fly if not present\n",
    "        personality_description = generate_binary_personality_description(participant_data)\n",
    "    \n",
    "    return get_binary_prompt(personality_description)\n",
    "\n",
    "# Test the prompt generator\n",
    "sample_prompt = binary_baseline_prompt_generator(participants_with_binary[0])\n",
    "print(\"Sample binary baseline prompt (first 500 characters):\")\n",
    "print(sample_prompt[:500] + \"...\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Run Multi-Model Simulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T08:09:32.042890Z",
     "start_time": "2025-06-29T08:09:29.388843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Running binary baseline simulation with openai_gpt_3.5_turbo_0125\n",
      "==================================================\n",
      "Starting simulation for 470 participants using openai_gpt_3.5_turbo_0125\n",
      "Temperature: 1.0, Batch size: 20\n",
      "Processing participants 0 to 19\n",
      "Warning: Domain bfi2_e not found in participant data\n",
      "Warning: Domain bfi2_a not found in participant data\n",
      "Warning: Domain bfi2_c not found in participant data\n",
      "Warning: Domain bfi2_n not found in participant data\n",
      "Warning: Domain bfi2_o not found in participant data\n",
      "JSON parsing failed (attempt #31): Unsupported model: openai_gpt_3.5_turbo_0125\n",
      "Warning: Domain bfi2_e not found in participant data\n",
      "Warning: Domain bfi2_a not found in participant data\n",
      "Warning: Domain bfi2_c not found in participant data\n",
      "Warning: Domain bfi2_n not found in participant data\n",
      "Warning: Domain bfi2_o not found in participant data\n",
      "JSON parsing failed (attempt #32): Unsupported model: openai_gpt_3.5_turbo_0125\n",
      "Warning: Domain bfi2_e not found in participant data\n",
      "Warning: Domain bfi2_a not found in participant data\n",
      "Warning: Domain bfi2_c not found in participant data\n",
      "Warning: Domain bfi2_n not found in participant data\n",
      "Warning: Domain bfi2_o not found in participant data\n",
      "JSON parsing failed (attempt #33): Unsupported model: openai_gpt_3.5_turbo_0125\n",
      "Warning: Domain bfi2_e not found in participant data\n",
      "Warning: Domain bfi2_a not found in participant data\n",
      "Warning: Domain bfi2_c not found in participant data\n",
      "Warning: Domain bfi2_n not found in participant data\n",
      "Warning: Domain bfi2_o not found in participant data\n",
      "JSON parsing failed (attempt #34): Unsupported model: openai_gpt_3.5_turbo_0125\n",
      "Warning: Domain bfi2_e not found in participant data\n",
      "Warning: Domain bfi2_a not found in participant data\n",
      "Warning: Domain bfi2_c not found in participant data\n",
      "Warning: Domain bfi2_n not found in participant data\n",
      "Warning: Domain bfi2_o not found in participant data\n",
      "JSON parsing failed (attempt #35): Unsupported model: openai_gpt_3.5_turbo_0125\n",
      "Warning: Domain bfi2_e not found in participant data\n",
      "Warning: Domain bfi2_a not found in participant data\n",
      "Warning: Domain bfi2_c not found in participant data\n",
      "Warning: Domain bfi2_n not found in participant data\n",
      "Warning: Domain bfi2_o not found in participant data\n",
      "JSON parsing failed (attempt #36): Unsupported model: openai_gpt_3.5_turbo_0125\n",
      "Warning: Domain bfi2_e not found in participant data\n",
      "Warning: Domain bfi2_a not found in participant data\n",
      "Warning: Domain bfi2_c not found in participant data\n",
      "Warning: Domain bfi2_n not found in participant data\n",
      "Warning: Domain bfi2_o not found in participant data\n",
      "JSON parsing failed (attempt #37): Unsupported model: openai_gpt_3.5_turbo_0125\n",
      "Warning: Domain bfi2_e not found in participant data\n",
      "Warning: Domain bfi2_a not found in participant data\n",
      "Warning: Domain bfi2_c not found in participant data\n",
      "Warning: Domain bfi2_n not found in participant data\n",
      "Warning: Domain bfi2_o not found in participant data\n",
      "JSON parsing failed (attempt #38): Unsupported model: openai_gpt_3.5_turbo_0125\n",
      "Warning: Domain bfi2_e not found in participant data\n",
      "Warning: Domain bfi2_a not found in participant data\n",
      "Warning: Domain bfi2_c not found in participant data\n",
      "Warning: Domain bfi2_n not found in participant data\n",
      "Warning: Domain bfi2_o not found in participant data\n",
      "JSON parsing failed (attempt #39): Unsupported model: openai_gpt_3.5_turbo_0125\n",
      "Warning: Domain bfi2_e not found in participant data\n",
      "Warning: Domain bfi2_a not found in participant data\n",
      "Warning: Domain bfi2_c not found in participant data\n",
      "Warning: Domain bfi2_n not found in participant data\n",
      "Warning: Domain bfi2_o not found in participant data\n",
      "JSON parsing failed (attempt #40): Unsupported model: openai_gpt_3.5_turbo_0125\n",
      "JSON parsing failed (attempt #41): Unsupported model: openai_gpt_3.5_turbo_0125JSON parsing failed (attempt #42): Unsupported model: openai_gpt_3.5_turbo_0125\n",
      "JSON parsing failed (attempt #43): Unsupported model: openai_gpt_3.5_turbo_0125\n",
      "\n",
      "JSON parsing failed (attempt #44): Unsupported model: openai_gpt_3.5_turbo_0125\n",
      "JSON parsing failed (attempt #45): Unsupported model: openai_gpt_3.5_turbo_0125\n",
      "JSON parsing failed (attempt #46): Unsupported model: openai_gpt_3.5_turbo_0125\n",
      "JSON parsing failed (attempt #47): Unsupported model: openai_gpt_3.5_turbo_0125\n",
      "JSON parsing failed (attempt #48): Unsupported model: openai_gpt_3.5_turbo_0125\n",
      "JSON parsing failed (attempt #49): Unsupported model: openai_gpt_3.5_turbo_0125\n",
      "JSON parsing failed (attempt #50): Unsupported model: openai_gpt_3.5_turbo_0125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[0;32m~/Psychometrics4AI_revision/multi_model_studies/study_2/../shared/simulation_utils.py:294\u001B[0m, in \u001B[0;36mrun_batch_simulation\u001B[0;34m(participants_data, prompt_generator, config, personality_key, output_dir, output_filename)\u001B[0m\n\u001B[1;32m    289\u001B[0m future_to_index \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    290\u001B[0m     executor\u001B[38;5;241m.\u001B[39msubmit(process_participant_with_index, i): i \n\u001B[1;32m    291\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(batch_start, batch_end)\n\u001B[1;32m    292\u001B[0m }\n\u001B[0;32m--> 294\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m future \u001B[38;5;129;01min\u001B[39;00m concurrent\u001B[38;5;241m.\u001B[39mfutures\u001B[38;5;241m.\u001B[39mas_completed(future_to_index):\n\u001B[1;32m    295\u001B[0m     index, result \u001B[38;5;241m=\u001B[39m future\u001B[38;5;241m.\u001B[39mresult()\n",
      "File \u001B[0;32m~/anaconda3/envs/GenAI/lib/python3.10/concurrent/futures/_base.py:245\u001B[0m, in \u001B[0;36mas_completed\u001B[0;34m(fs, timeout)\u001B[0m\n\u001B[1;32m    241\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m(\n\u001B[1;32m    242\u001B[0m                 \u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m (of \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m) futures unfinished\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m (\n\u001B[1;32m    243\u001B[0m                 \u001B[38;5;28mlen\u001B[39m(pending), total_futures))\n\u001B[0;32m--> 245\u001B[0m \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwait_timeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    247\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m waiter\u001B[38;5;241m.\u001B[39mlock:\n",
      "File \u001B[0;32m~/anaconda3/envs/GenAI/lib/python3.10/threading.py:607\u001B[0m, in \u001B[0;36mEvent.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    606\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m signaled:\n\u001B[0;32m--> 607\u001B[0m     signaled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cond\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    608\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m signaled\n",
      "File \u001B[0;32m~/anaconda3/envs/GenAI/lib/python3.10/threading.py:320\u001B[0m, in \u001B[0;36mCondition.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    319\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 320\u001B[0m     \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    321\u001B[0m     gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 22\u001B[0m\n\u001B[1;32m     18\u001B[0m output_filename \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbfi_to_minimarker_binary_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;250m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_temp\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtemperature\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.0f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_0.json\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     21\u001B[0m     \u001B[38;5;66;03m# Run the simulation\u001B[39;00m\n\u001B[0;32m---> 22\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[43mrun_batch_simulation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparticipants_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparticipants_with_binary\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     24\u001B[0m \u001B[43m        \u001B[49m\u001B[43mprompt_generator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbinary_baseline_prompt_generator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     26\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpersonality_key\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbinary_personality\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     27\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput_dir\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_filename\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_filename\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     31\u001B[0m     all_results[model] \u001B[38;5;241m=\u001B[39m results\n\u001B[1;32m     33\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m✓ Simulation completed for \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Psychometrics4AI_revision/multi_model_studies/study_2/../shared/simulation_utils.py:288\u001B[0m, in \u001B[0;36mrun_batch_simulation\u001B[0;34m(participants_data, prompt_generator, config, personality_key, output_dir, output_filename)\u001B[0m\n\u001B[1;32m    285\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m index, result\n\u001B[1;32m    287\u001B[0m \u001B[38;5;66;03m# Use ThreadPoolExecutor for concurrent processing\u001B[39;00m\n\u001B[0;32m--> 288\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m concurrent\u001B[38;5;241m.\u001B[39mfutures\u001B[38;5;241m.\u001B[39mThreadPoolExecutor(max_workers\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mmin\u001B[39m(config\u001B[38;5;241m.\u001B[39mmax_workers, config\u001B[38;5;241m.\u001B[39mbatch_size)) \u001B[38;5;28;01mas\u001B[39;00m executor:\n\u001B[1;32m    289\u001B[0m     future_to_index \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    290\u001B[0m         executor\u001B[38;5;241m.\u001B[39msubmit(process_participant_with_index, i): i \n\u001B[1;32m    291\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(batch_start, batch_end)\n\u001B[1;32m    292\u001B[0m     }\n\u001B[1;32m    294\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m future \u001B[38;5;129;01min\u001B[39;00m concurrent\u001B[38;5;241m.\u001B[39mfutures\u001B[38;5;241m.\u001B[39mas_completed(future_to_index):\n",
      "File \u001B[0;32m~/anaconda3/envs/GenAI/lib/python3.10/concurrent/futures/_base.py:649\u001B[0m, in \u001B[0;36mExecutor.__exit__\u001B[0;34m(self, exc_type, exc_val, exc_tb)\u001B[0m\n\u001B[1;32m    648\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__exit__\u001B[39m(\u001B[38;5;28mself\u001B[39m, exc_type, exc_val, exc_tb):\n\u001B[0;32m--> 649\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshutdown\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwait\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    650\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/GenAI/lib/python3.10/concurrent/futures/thread.py:235\u001B[0m, in \u001B[0;36mThreadPoolExecutor.shutdown\u001B[0;34m(self, wait, cancel_futures)\u001B[0m\n\u001B[1;32m    233\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m wait:\n\u001B[1;32m    234\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads:\n\u001B[0;32m--> 235\u001B[0m         \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/GenAI/lib/python3.10/threading.py:1096\u001B[0m, in \u001B[0;36mThread.join\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m   1093\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcannot join current thread\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1095\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1096\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_wait_for_tstate_lock\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1097\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1098\u001B[0m     \u001B[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001B[39;00m\n\u001B[1;32m   1099\u001B[0m     \u001B[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wait_for_tstate_lock(timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mmax\u001B[39m(timeout, \u001B[38;5;241m0\u001B[39m))\n",
      "File \u001B[0;32m~/anaconda3/envs/GenAI/lib/python3.10/threading.py:1116\u001B[0m, in \u001B[0;36mThread._wait_for_tstate_lock\u001B[0;34m(self, block, timeout)\u001B[0m\n\u001B[1;32m   1113\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m   1115\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1116\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mlock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43mblock\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m   1117\u001B[0m         lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m   1118\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stop()\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Run simulation for each model\n",
    "all_results = {}\n",
    "\n",
    "for model in models_to_test:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Running binary baseline simulation with {model}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Create simulation configuration\n",
    "    config = SimulationConfig(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        batch_size=batch_size,\n",
    "        max_workers=max_workers\n",
    "    )\n",
    "    \n",
    "    # Create output filename\n",
    "    output_filename = f\"bfi_to_minimarker_binary_{model.replace('-', '_')}_temp{temperature:.0f}_0.json\"\n",
    "    \n",
    "    try:\n",
    "        # Run the simulation\n",
    "        results = run_batch_simulation(\n",
    "            participants_data=participants_with_binary,\n",
    "            prompt_generator=binary_baseline_prompt_generator,\n",
    "            config=config,\n",
    "            personality_key='binary_personality',\n",
    "            output_dir=str(output_dir),\n",
    "            output_filename=output_filename\n",
    "        )\n",
    "        \n",
    "        all_results[model] = results\n",
    "        \n",
    "        print(f\"✓ Simulation completed for {model}\")\n",
    "        print(f\"  - Total participants: {len(results)}\")\n",
    "        print(f\"  - Successful responses: {sum(1 for r in results if 'error' not in r)}\")\n",
    "        print(f\"  - Failed responses: {sum(1 for r in results if 'error' in r)}\")\n",
    "        print(f\"  - Results saved to: {output_dir / output_filename}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error running simulation for {model}: {str(e)}\")\n",
    "        all_results[model] = None\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Simulation Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BINARY BASELINE SIMULATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "summary_data = []\n",
    "\n",
    "for model, results in all_results.items():\n",
    "    if results is not None:\n",
    "        total = len(results)\n",
    "        successful = sum(1 for r in results if 'error' not in r)\n",
    "        failed = sum(1 for r in results if 'error' in r)\n",
    "        success_rate = (successful / total) * 100 if total > 0 else 0\n",
    "        \n",
    "        summary_data.append({\n",
    "            'Model': model,\n",
    "            'Total': total,\n",
    "            'Successful': successful,\n",
    "            'Failed': failed,\n",
    "            'Success Rate (%)': f\"{success_rate:.1f}%\"\n",
    "        })\n",
    "        \n",
    "        print(f\"{model:25} | {total:5d} | {successful:5d} | {failed:5d} | {success_rate:6.1f}%\")\n",
    "    else:\n",
    "        print(f\"{model:25} | ERROR - Simulation failed\")\n",
    "\n",
    "# Save summary\n",
    "if summary_data:\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_df.to_csv(output_dir / 'binary_simulation_summary.csv', index=False)\n",
    "    print(f\"\\nSummary saved to: {output_dir / 'binary_simulation_summary.csv'}\")\n",
    "\n",
    "print(f\"\\nAll results saved in: {output_dir}\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Run convergent analysis to compare binary baseline with expanded/likert formats\")\n",
    "print(\"2. Analyze performance differences across models\")\n",
    "print(\"3. Evaluate which approach provides the most reliable personality simulation\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
