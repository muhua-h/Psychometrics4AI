{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "# Study 2: Binary Baseline Multi-Model Simulation\n",
    "\n",
    "This notebook implements a simplified binary baseline approach where personality is classified as simply \"high\" or \"low\" on each of the Big Five domains based on whether domain scores are above or below 50% (2.5 on the 1-5 scale).\n",
    "\n",
    "This serves as a baseline comparison to the more complex expanded and likert formats.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T10:06:06.694469Z",
     "start_time": "2025-07-06T10:06:04.964253Z"
    }
   },
   "cell_type": "code",
   "source": "import sys\nimport pandas as pd\nimport numpy as np\nfrom pathlib import Path\nimport json\n\n# Add shared utilities to path\nsys.path.append('../shared')\n\n# Updated imports to use the unified prompt system\nfrom simulation_utils import (\n    SimulationConfig, \n    run_batch_simulation,\n    run_enhanced_bfi_to_minimarker_simulation\n)\nfrom mini_marker_prompt import (\n    generate_binary_personality_description, \n    get_binary_prompt,\n    create_binary_participant_data,\n    validate_minimarker_response\n)\n\nprint(\"Binary baseline simulation utilities loaded successfully\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary baseline simulation utilities loaded successfully\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T10:06:06.705170Z",
     "start_time": "2025-07-06T10:06:06.702690Z"
    }
   },
   "cell_type": "code",
   "source": "# The validate_minimarker_response function is now imported from mini_marker_prompt\n# No need to redefine it here\n\nprint(\"Using unified prompt system from mini_marker_prompt.py\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using unified prompt system from mini_marker_prompt.py\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T10:06:09.022021Z",
     "start_time": "2025-07-06T10:06:06.743739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load and examine the data structure\n",
    "print(\"=== DEBUGGING DATA STRUCTURE ===\")\n",
    "\n",
    "# Load the original Soto dataset\n",
    "data_path = Path('../../raw_data/Soto_data.xlsx')\n",
    "if not data_path.exists():\n",
    "    print(f\"Error: Data file not found at {data_path}\")\n",
    "    exit()\n",
    "\n",
    "data = pd.read_excel(data_path)\n",
    "print(f\"Loaded {len(data)} participants from Soto dataset\")\n",
    "\n",
    "# Check ALL available columns\n",
    "print(f\"\\nTotal columns: {len(data.columns)}\")\n",
    "print(f\"All columns: {list(data.columns)}\")\n",
    "\n",
    "# Check specifically for BFI columns\n",
    "bfi_cols = [col for col in data.columns if 'bfi' in col.lower()]\n",
    "print(f\"\\nBFI-related columns found: {bfi_cols}\")\n",
    "\n",
    "# Check for domain score columns specifically\n",
    "domain_cols = [col for col in data.columns if any(domain in col for domain in ['_e', '_a', '_c', '_n', '_o'])]\n",
    "print(f\"\\nDomain score columns found: {domain_cols}\")\n",
    "\n",
    "# Show sample data for BFI domain columns\n",
    "if len(bfi_cols) > 0:\n",
    "    print(f\"\\nSample BFI data:\")\n",
    "    print(data[bfi_cols].head())\n",
    "else:\n",
    "    print(\"\\nNo BFI columns found - showing first 10 columns:\")\n",
    "    print(data.iloc[:5, :10])\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DEBUGGING DATA STRUCTURE ===\n",
      "Loaded 470 participants from Soto dataset\n",
      "\n",
      "Total columns: 704\n",
      "All columns: ['case_id', 'age', 'sex', 'ethnicity', 'rel_acquaintance', 'rel_friend', 'rel_roommate', 'rel_boygirlfriend', 'rel_relative', 'rel_other', 'rel_description', 'bfi1', 'bfi2', 'bfi3', 'bfi4', 'bfi5', 'bfi6', 'bfi7', 'bfi8', 'bfi9', 'bfi10', 'bfi11', 'bfi12', 'bfi13', 'bfi14', 'bfi15', 'bfi16', 'bfi17', 'bfi18', 'bfi19', 'bfi20', 'bfi21', 'bfi22', 'bfi23', 'bfi24', 'bfi25', 'bfi26', 'bfi27', 'bfi28', 'bfi29', 'bfi30', 'bfi31', 'bfi32', 'bfi33', 'bfi34', 'bfi35', 'bfi36', 'bfi37', 'bfi38', 'bfi39', 'bfi40', 'bfi41', 'bfi42', 'bfi43', 'bfi44', 'bfi45', 'bfi46', 'bfi47', 'bfi48', 'bfi49', 'bfi50', 'bfi51', 'bfi52', 'bfi53', 'bfi54', 'bfi55', 'bfi56', 'bfi57', 'bfi58', 'bfi59', 'bfi60', 'pbfi1', 'pbfi2', 'pbfi3', 'pbfi4', 'pbfi5', 'pbfi6', 'pbfi7', 'pbfi8', 'pbfi9', 'pbfi10', 'pbfi11', 'pbfi12', 'pbfi13', 'pbfi14', 'pbfi15', 'pbfi16', 'pbfi17', 'pbfi18', 'pbfi19', 'pbfi20', 'pbfi21', 'pbfi22', 'pbfi23', 'pbfi24', 'pbfi25', 'pbfi26', 'pbfi27', 'pbfi28', 'pbfi29', 'pbfi30', 'pbfi31', 'pbfi32', 'pbfi33', 'pbfi34', 'pbfi35', 'pbfi36', 'pbfi37', 'pbfi38', 'pbfi39', 'pbfi40', 'pbfi41', 'pbfi42', 'pbfi43', 'pbfi44', 'pbfi45', 'pbfi46', 'pbfi47', 'pbfi48', 'pbfi49', 'pbfi50', 'pbfi51', 'pbfi52', 'pbfi53', 'pbfi54', 'pbfi55', 'pbfi56', 'pbfi57', 'pbfi58', 'pbfi59', 'pbfi60', 'sbfi1', 'sbfi2', 'sbfi3', 'sbfi4', 'sbfi5', 'sbfi6', 'sbfi7', 'sbfi8', 'sbfi9', 'sbfi10', 'sbfi11', 'sbfi12', 'sbfi13', 'sbfi14', 'sbfi15', 'sbfi16', 'sbfi17', 'sbfi18', 'sbfi19', 'sbfi20', 'sbfi21', 'sbfi22', 'sbfi23', 'sbfi24', 'sbfi25', 'sbfi26', 'sbfi27', 'sbfi28', 'sbfi29', 'sbfi30', 'sbfi31', 'sbfi32', 'sbfi33', 'sbfi34', 'sbfi35', 'sbfi36', 'sbfi37', 'sbfi38', 'sbfi39', 'sbfi40', 'sbfi41', 'sbfi42', 'sbfi43', 'sbfi44', 'sbfi45', 'sbfi46', 'sbfi47', 'sbfi48', 'sbfi49', 'sbfi50', 'sbfi51', 'sbfi52', 'sbfi53', 'sbfi54', 'sbfi55', 'sbfi56', 'sbfi57', 'sbfi58', 'sbfi59', 'sbfi60', 'bfi2_e_sociability', 'bfi2_e_assertiveness', 'bfi2_e_energy_level', 'bfi2_a_compassion', 'bfi2_a_respectfulness', 'bfi2_a_trust', 'bfi2_c_organization', 'bfi2_c_productiveness', 'bfi2_c_responsibility', 'bfi2_n_anxiety', 'bfi2_n_depression', 'bfi2_n_emotional_volatility', 'bfi2_o_intellectual_curiosity', 'bfi2_o_aesthetic_sensitivity', 'bfi2_o_creative_imagination', 'bfi2_e', 'bfi2_a', 'bfi2_c', 'bfi2_n', 'bfi2_o', 'pbfi2_e_sociability', 'pbfi2_e_assertiveness', 'pbfi2_e_energy_level', 'pbfi2_a_compassion', 'pbfi2_a_respectfulness', 'pbfi2_a_trust', 'pbfi2_c_organization', 'pbfi2_c_productiveness', 'pbfi2_c_responsibility', 'pbfi2_n_anxiety', 'pbfi2_n_depression', 'pbfi2_n_emotional_volatility', 'pbfi2_o_intellectual_curiosity', 'pbfi2_o_aesthetic_sensitivity', 'pbfi2_o_creative_imagination', 'pbfi2_e', 'pbfi2_a', 'pbfi2_c', 'pbfi2_n', 'pbfi2_o', 'sbfi2_e_sociability', 'sbfi2_e_assertiveness', 'sbfi2_e_energy_level', 'sbfi2_a_compassion', 'sbfi2_a_respectfulness', 'sbfi2_a_trust', 'sbfi2_c_organization', 'sbfi2_c_productiveness', 'sbfi2_c_responsibility', 'sbfi2_n_anxiety', 'sbfi2_n_depression', 'sbfi2_n_emotional_volatility', 'sbfi2_o_intellectual_curiosity', 'sbfi2_o_aesthetic_sensitivity', 'sbfi2_o_creative_imagination', 'sbfi2_e', 'sbfi2_a', 'sbfi2_c', 'sbfi2_n', 'sbfi2_o', 'tda1', 'tda2', 'tda3', 'tda4', 'tda5', 'tda6', 'tda7', 'tda8', 'tda9', 'tda10', 'tda11', 'tda12', 'tda13', 'tda14', 'tda15', 'tda16', 'tda17', 'tda18', 'tda19', 'tda20', 'tda21', 'tda22', 'tda23', 'tda24', 'tda25', 'tda26', 'tda27', 'tda28', 'tda29', 'tda30', 'tda31', 'tda32', 'tda33', 'tda34', 'tda35', 'tda36', 'tda37', 'tda38', 'tda39', 'tda40', 'bfas1', 'bfas2', 'bfas3', 'bfas4', 'bfas5', 'bfas6', 'bfas7', 'bfas8', 'bfas9', 'bfas10', 'bfas11', 'bfas12', 'bfas13', 'bfas14', 'bfas15', 'bfas16', 'bfas17', 'bfas18', 'bfas19', 'bfas20', 'bfas21', 'bfas22', 'bfas23', 'bfas24', 'bfas25', 'bfas26', 'bfas27', 'bfas28', 'bfas29', 'bfas30', 'bfas31', 'bfas32', 'bfas33', 'bfas34', 'bfas35', 'bfas36', 'bfas37', 'bfas38', 'bfas39', 'bfas40', 'bfas41', 'bfas42', 'bfas43', 'bfas44', 'bfas45', 'bfas46', 'bfas47', 'bfas48', 'bfas49', 'bfas50', 'bfas51', 'bfas52', 'bfas53', 'bfas54', 'bfas55', 'bfas56', 'bfas57', 'bfas58', 'bfas59', 'bfas60', 'bfas61', 'bfas62', 'bfas63', 'bfas64', 'bfas65', 'bfas66', 'bfas67', 'bfas68', 'bfas69', 'bfas70', 'bfas71', 'bfas72', 'bfas73', 'bfas74', 'bfas75', 'bfas76', 'bfas77', 'bfas78', 'bfas79', 'bfas80', 'bfas81', 'bfas82', 'bfas83', 'bfas84', 'bfas85', 'bfas86', 'bfas87', 'bfas88', 'bfas89', 'bfas90', 'bfas91', 'bfas92', 'bfas93', 'bfas94', 'bfas95', 'bfas96', 'bfas97', 'bfas98', 'bfas99', 'bfas100', 'neo1', 'neo2', 'neo3', 'neo4', 'neo5', 'neo6', 'neo7', 'neo8', 'neo9', 'neo10', 'neo11', 'neo12', 'neo13', 'neo14', 'neo15', 'neo16', 'neo17', 'neo18', 'neo19', 'neo20', 'neo21', 'neo22', 'neo23', 'neo24', 'neo25', 'neo26', 'neo27', 'neo28', 'neo29', 'neo30', 'neo31', 'neo32', 'neo33', 'neo34', 'neo35', 'neo36', 'neo37', 'neo38', 'neo39', 'neo40', 'neo41', 'neo42', 'neo43', 'neo44', 'neo45', 'neo46', 'neo47', 'neo48', 'neo49', 'neo50', 'neo51', 'neo52', 'neo53', 'neo54', 'neo55', 'neo56', 'neo57', 'neo58', 'neo59', 'neo60', 'neo61', 'neo62', 'neo63', 'neo64', 'neo65', 'neo66', 'neo67', 'neo68', 'neo69', 'neo70', 'neo71', 'neo72', 'neo73', 'neo74', 'neo75', 'neo76', 'neo77', 'neo78', 'neo79', 'neo80', 'neo81', 'neo82', 'neo83', 'neo84', 'neo85', 'neo86', 'neo87', 'neo88', 'neo89', 'neo90', 'neo91', 'neo92', 'neo93', 'neo94', 'neo95', 'neo96', 'neo97', 'neo98', 'neo99', 'neo100', 'neo101', 'neo102', 'neo103', 'neo104', 'neo105', 'neo106', 'neo107', 'neo108', 'neo109', 'neo110', 'neo111', 'neo112', 'neo113', 'neo114', 'neo115', 'neo116', 'neo117', 'neo118', 'neo119', 'neo120', 'neo121', 'neo122', 'neo123', 'neo124', 'neo125', 'neo126', 'neo127', 'neo128', 'neo129', 'neo130', 'neo131', 'neo132', 'neo133', 'neo134', 'neo135', 'neo136', 'neo137', 'neo138', 'neo139', 'neo140', 'neo141', 'neo142', 'neo143', 'neo144', 'neo145', 'neo146', 'neo147', 'neo148', 'neo149', 'neo150', 'neo151', 'neo152', 'neo153', 'neo154', 'neo155', 'neo156', 'neo157', 'neo158', 'neo159', 'neo160', 'neo161', 'neo162', 'neo163', 'neo164', 'neo165', 'neo166', 'neo167', 'neo168', 'neo169', 'neo170', 'neo171', 'neo172', 'neo173', 'neo174', 'neo175', 'neo176', 'neo177', 'neo178', 'neo179', 'neo180', 'neo181', 'neo182', 'neo183', 'neo184', 'neo185', 'neo186', 'neo187', 'neo188', 'neo189', 'neo190', 'neo191', 'neo192', 'neo193', 'neo194', 'neo195', 'neo196', 'neo197', 'neo198', 'neo199', 'neo200', 'neo201', 'neo202', 'neo203', 'neo204', 'neo205', 'neo206', 'neo207', 'neo208', 'neo209', 'neo210', 'neo211', 'neo212', 'neo213', 'neo214', 'neo215', 'neo216', 'neo217', 'neo218', 'neo219', 'neo220', 'neo221', 'neo222', 'neo223', 'neo224', 'neo225', 'neo226', 'neo227', 'neo228', 'neo229', 'neo230', 'neo231', 'neo232', 'neo233', 'neo234', 'neo235', 'neo236', 'neo237', 'neo238', 'neo239', 'neo240', 'tda_e', 'tda_a', 'tda_c', 'tda_n', 'tda_o', 'bfas_e', 'bfas_a', 'bfas_c', 'bfas_n', 'bfas_o', 'bfas_e_ent', 'bfas_e_ass', 'bfas_a_com', 'bfas_a_pol', 'bfas_c_ind', 'bfas_c_ord', 'bfas_n_wit', 'bfas_n_vol', 'bfas_o_int', 'bfas_o_ope', 'ffi_e', 'ffi_a', 'ffi_c', 'ffi_n', 'ffi_o', 'ffi_e_pos', 'ffi_e_soc', 'ffi_e_act', 'ffi_a_non', 'ffi_a_pro', 'ffi_c_ord', 'ffi_c_goa', 'ffi_c_dep', 'ffi_n_neg', 'ffi_n_sel', 'ffi_o_aes', 'ffi_o_int', 'ffi_o_unc', 'tneo_e', 'tneo_a', 'tneo_c', 'tneo_n', 'tneo_o', 'tneo_e1_war', 'tneo_e2_gre', 'tneo_e3_ass', 'tneo_e4_act', 'tneo_e5_exc', 'tneo_e6_pos', 'tneo_a1_tru', 'tneo_a2_str', 'tneo_a3_alt', 'tneo_a4_com', 'tneo_a5_mod', 'tneo_a6_ten', 'tneo_c1_com', 'tneo_c2_ord', 'tneo_c3_dut', 'tneo_c4_ach', 'tneo_c5_sel', 'tneo_c6_del', 'tneo_n1_anx', 'tneo_n2_ang', 'tneo_n3_dep', 'tneo_n4_sel', 'tneo_n5_imp', 'tneo_n6_vul', 'tneo_o1_fan', 'tneo_o2_aes', 'tneo_o3_fee', 'tneo_o4_act', 'tneo_o5_ide', 'tneo_o6_val']\n",
      "\n",
      "BFI-related columns found: ['bfi1', 'bfi2', 'bfi3', 'bfi4', 'bfi5', 'bfi6', 'bfi7', 'bfi8', 'bfi9', 'bfi10', 'bfi11', 'bfi12', 'bfi13', 'bfi14', 'bfi15', 'bfi16', 'bfi17', 'bfi18', 'bfi19', 'bfi20', 'bfi21', 'bfi22', 'bfi23', 'bfi24', 'bfi25', 'bfi26', 'bfi27', 'bfi28', 'bfi29', 'bfi30', 'bfi31', 'bfi32', 'bfi33', 'bfi34', 'bfi35', 'bfi36', 'bfi37', 'bfi38', 'bfi39', 'bfi40', 'bfi41', 'bfi42', 'bfi43', 'bfi44', 'bfi45', 'bfi46', 'bfi47', 'bfi48', 'bfi49', 'bfi50', 'bfi51', 'bfi52', 'bfi53', 'bfi54', 'bfi55', 'bfi56', 'bfi57', 'bfi58', 'bfi59', 'bfi60', 'pbfi1', 'pbfi2', 'pbfi3', 'pbfi4', 'pbfi5', 'pbfi6', 'pbfi7', 'pbfi8', 'pbfi9', 'pbfi10', 'pbfi11', 'pbfi12', 'pbfi13', 'pbfi14', 'pbfi15', 'pbfi16', 'pbfi17', 'pbfi18', 'pbfi19', 'pbfi20', 'pbfi21', 'pbfi22', 'pbfi23', 'pbfi24', 'pbfi25', 'pbfi26', 'pbfi27', 'pbfi28', 'pbfi29', 'pbfi30', 'pbfi31', 'pbfi32', 'pbfi33', 'pbfi34', 'pbfi35', 'pbfi36', 'pbfi37', 'pbfi38', 'pbfi39', 'pbfi40', 'pbfi41', 'pbfi42', 'pbfi43', 'pbfi44', 'pbfi45', 'pbfi46', 'pbfi47', 'pbfi48', 'pbfi49', 'pbfi50', 'pbfi51', 'pbfi52', 'pbfi53', 'pbfi54', 'pbfi55', 'pbfi56', 'pbfi57', 'pbfi58', 'pbfi59', 'pbfi60', 'sbfi1', 'sbfi2', 'sbfi3', 'sbfi4', 'sbfi5', 'sbfi6', 'sbfi7', 'sbfi8', 'sbfi9', 'sbfi10', 'sbfi11', 'sbfi12', 'sbfi13', 'sbfi14', 'sbfi15', 'sbfi16', 'sbfi17', 'sbfi18', 'sbfi19', 'sbfi20', 'sbfi21', 'sbfi22', 'sbfi23', 'sbfi24', 'sbfi25', 'sbfi26', 'sbfi27', 'sbfi28', 'sbfi29', 'sbfi30', 'sbfi31', 'sbfi32', 'sbfi33', 'sbfi34', 'sbfi35', 'sbfi36', 'sbfi37', 'sbfi38', 'sbfi39', 'sbfi40', 'sbfi41', 'sbfi42', 'sbfi43', 'sbfi44', 'sbfi45', 'sbfi46', 'sbfi47', 'sbfi48', 'sbfi49', 'sbfi50', 'sbfi51', 'sbfi52', 'sbfi53', 'sbfi54', 'sbfi55', 'sbfi56', 'sbfi57', 'sbfi58', 'sbfi59', 'sbfi60', 'bfi2_e_sociability', 'bfi2_e_assertiveness', 'bfi2_e_energy_level', 'bfi2_a_compassion', 'bfi2_a_respectfulness', 'bfi2_a_trust', 'bfi2_c_organization', 'bfi2_c_productiveness', 'bfi2_c_responsibility', 'bfi2_n_anxiety', 'bfi2_n_depression', 'bfi2_n_emotional_volatility', 'bfi2_o_intellectual_curiosity', 'bfi2_o_aesthetic_sensitivity', 'bfi2_o_creative_imagination', 'bfi2_e', 'bfi2_a', 'bfi2_c', 'bfi2_n', 'bfi2_o', 'pbfi2_e_sociability', 'pbfi2_e_assertiveness', 'pbfi2_e_energy_level', 'pbfi2_a_compassion', 'pbfi2_a_respectfulness', 'pbfi2_a_trust', 'pbfi2_c_organization', 'pbfi2_c_productiveness', 'pbfi2_c_responsibility', 'pbfi2_n_anxiety', 'pbfi2_n_depression', 'pbfi2_n_emotional_volatility', 'pbfi2_o_intellectual_curiosity', 'pbfi2_o_aesthetic_sensitivity', 'pbfi2_o_creative_imagination', 'pbfi2_e', 'pbfi2_a', 'pbfi2_c', 'pbfi2_n', 'pbfi2_o', 'sbfi2_e_sociability', 'sbfi2_e_assertiveness', 'sbfi2_e_energy_level', 'sbfi2_a_compassion', 'sbfi2_a_respectfulness', 'sbfi2_a_trust', 'sbfi2_c_organization', 'sbfi2_c_productiveness', 'sbfi2_c_responsibility', 'sbfi2_n_anxiety', 'sbfi2_n_depression', 'sbfi2_n_emotional_volatility', 'sbfi2_o_intellectual_curiosity', 'sbfi2_o_aesthetic_sensitivity', 'sbfi2_o_creative_imagination', 'sbfi2_e', 'sbfi2_a', 'sbfi2_c', 'sbfi2_n', 'sbfi2_o']\n",
      "\n",
      "Domain score columns found: ['rel_acquaintance', 'rel_other', 'bfi2_e_sociability', 'bfi2_e_assertiveness', 'bfi2_e_energy_level', 'bfi2_a_compassion', 'bfi2_a_respectfulness', 'bfi2_a_trust', 'bfi2_c_organization', 'bfi2_c_productiveness', 'bfi2_c_responsibility', 'bfi2_n_anxiety', 'bfi2_n_depression', 'bfi2_n_emotional_volatility', 'bfi2_o_intellectual_curiosity', 'bfi2_o_aesthetic_sensitivity', 'bfi2_o_creative_imagination', 'bfi2_e', 'bfi2_a', 'bfi2_c', 'bfi2_n', 'bfi2_o', 'pbfi2_e_sociability', 'pbfi2_e_assertiveness', 'pbfi2_e_energy_level', 'pbfi2_a_compassion', 'pbfi2_a_respectfulness', 'pbfi2_a_trust', 'pbfi2_c_organization', 'pbfi2_c_productiveness', 'pbfi2_c_responsibility', 'pbfi2_n_anxiety', 'pbfi2_n_depression', 'pbfi2_n_emotional_volatility', 'pbfi2_o_intellectual_curiosity', 'pbfi2_o_aesthetic_sensitivity', 'pbfi2_o_creative_imagination', 'pbfi2_e', 'pbfi2_a', 'pbfi2_c', 'pbfi2_n', 'pbfi2_o', 'sbfi2_e_sociability', 'sbfi2_e_assertiveness', 'sbfi2_e_energy_level', 'sbfi2_a_compassion', 'sbfi2_a_respectfulness', 'sbfi2_a_trust', 'sbfi2_c_organization', 'sbfi2_c_productiveness', 'sbfi2_c_responsibility', 'sbfi2_n_anxiety', 'sbfi2_n_depression', 'sbfi2_n_emotional_volatility', 'sbfi2_o_intellectual_curiosity', 'sbfi2_o_aesthetic_sensitivity', 'sbfi2_o_creative_imagination', 'sbfi2_e', 'sbfi2_a', 'sbfi2_c', 'sbfi2_n', 'sbfi2_o', 'tda_e', 'tda_a', 'tda_c', 'tda_n', 'tda_o', 'bfas_e', 'bfas_a', 'bfas_c', 'bfas_n', 'bfas_o', 'bfas_e_ent', 'bfas_e_ass', 'bfas_a_com', 'bfas_a_pol', 'bfas_c_ind', 'bfas_c_ord', 'bfas_n_wit', 'bfas_n_vol', 'bfas_o_int', 'bfas_o_ope', 'ffi_e', 'ffi_a', 'ffi_c', 'ffi_n', 'ffi_o', 'ffi_e_pos', 'ffi_e_soc', 'ffi_e_act', 'ffi_a_non', 'ffi_a_pro', 'ffi_c_ord', 'ffi_c_goa', 'ffi_c_dep', 'ffi_n_neg', 'ffi_n_sel', 'ffi_o_aes', 'ffi_o_int', 'ffi_o_unc', 'tneo_e', 'tneo_a', 'tneo_c', 'tneo_n', 'tneo_o', 'tneo_e1_war', 'tneo_e2_gre', 'tneo_e3_ass', 'tneo_e4_act', 'tneo_e5_exc', 'tneo_e6_pos', 'tneo_a1_tru', 'tneo_a2_str', 'tneo_a3_alt', 'tneo_a4_com', 'tneo_a5_mod', 'tneo_a6_ten', 'tneo_c1_com', 'tneo_c2_ord', 'tneo_c3_dut', 'tneo_c4_ach', 'tneo_c5_sel', 'tneo_c6_del', 'tneo_n1_anx', 'tneo_n2_ang', 'tneo_n3_dep', 'tneo_n4_sel', 'tneo_n5_imp', 'tneo_n6_vul', 'tneo_o1_fan', 'tneo_o2_aes', 'tneo_o3_fee', 'tneo_o4_act', 'tneo_o5_ide', 'tneo_o6_val']\n",
      "\n",
      "Sample BFI data:\n",
      "   bfi1  bfi2  bfi3  bfi4  bfi5  bfi6  bfi7  bfi8  bfi9  bfi10  ...  \\\n",
      "0     5     5     2     3     2     4     5     4     5      2  ...   \n",
      "1     4     4     4     4     4     2     4     4     4      4  ...   \n",
      "2     1     5     2     4     2     3     5     4     2      5  ...   \n",
      "3     4     4     4     2     4     3     4     4     2      5  ...   \n",
      "4     3     4     1     3     2     4     4     2     3      4  ...   \n",
      "\n",
      "   sbfi2_n_depression  sbfi2_n_emotional_volatility  \\\n",
      "0                 NaN                           NaN   \n",
      "1                 NaN                           NaN   \n",
      "2                 NaN                           NaN   \n",
      "3                 NaN                           NaN   \n",
      "4                 NaN                           NaN   \n",
      "\n",
      "   sbfi2_o_intellectual_curiosity  sbfi2_o_aesthetic_sensitivity  \\\n",
      "0                             NaN                            NaN   \n",
      "1                             NaN                            NaN   \n",
      "2                             NaN                            NaN   \n",
      "3                             NaN                            NaN   \n",
      "4                             NaN                            NaN   \n",
      "\n",
      "   sbfi2_o_creative_imagination  sbfi2_e  sbfi2_a  sbfi2_c  sbfi2_n  sbfi2_o  \n",
      "0                           NaN      NaN      NaN      NaN      NaN      NaN  \n",
      "1                           NaN      NaN      NaN      NaN      NaN      NaN  \n",
      "2                           NaN      NaN      NaN      NaN      NaN      NaN  \n",
      "3                           NaN      NaN      NaN      NaN      NaN      NaN  \n",
      "4                           NaN      NaN      NaN      NaN      NaN      NaN  \n",
      "\n",
      "[5 rows x 240 columns]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T10:06:09.062629Z",
     "start_time": "2025-07-06T10:06:09.034813Z"
    }
   },
   "cell_type": "code",
   "source": "# Generate column names for TDA (Mini-Marker) and BFI-2 items\ntda_columns = [f\"tda{i}\" for i in range(1, 41)]\nsbfi_columns = [f\"bfi{i}\" for i in range(1, 61)]\nselected_columns = tda_columns + sbfi_columns\n\nprint(f\"Original data shape: {data.shape}\")\n\n# Remove rows with missing values in the selected columns - SAME AS LIKERT/EXPANDED\ndata = data.dropna(subset=selected_columns)\nprint(f\"Data shape after removing missing values: {data.shape}\")\n\n# Create participant data with correct column names\nprint(\"=== CREATING PARTICIPANT DATA ===\")\n\n# Use the actual column names found in the data\nparticipants_data = []\n\n# First, let's identify the correct BFI domain columns\nif 'bfi2_e' in data.columns:\n    # Use BFI-2 format\n    domain_columns = {\n        'bfi2_e': 'bfi2_e',\n        'bfi2_a': 'bfi2_a', \n        'bfi2_c': 'bfi2_c',\n        'bfi2_n': 'bfi2_n',\n        'bfi2_o': 'bfi2_o'\n    }\n    print(\"Using BFI-2 format columns\")\nelif 'bfi_e' in data.columns:\n    # Use alternative BFI format\n    domain_columns = {\n        'bfi2_e': 'bfi_e',\n        'bfi2_a': 'bfi_a', \n        'bfi2_c': 'bfi_c',\n        'bfi2_n': 'bfi_n',\n        'bfi2_o': 'bfi_o'\n    }\n    print(\"Using alternative BFI format columns\")\nelse:\n    # Need to find the correct columns\n    print(\"ERROR: Cannot find standard BFI domain columns\")\n    print(\"Available columns that might be domain scores:\")\n    potential_cols = [col for col in data.columns if any(x in col.lower() for x in ['extra', 'agree', 'consc', 'neuro', 'open'])]\n    print(potential_cols)\n    \n    # For now, let's stop and ask user to clarify\n    raise Exception(\"Cannot identify BFI domain columns. Please check the data structure above.\")\n\n# Create participant data\nfor idx, row in data.iterrows():\n    participant = {'participant_id': idx}\n    \n    # Map the data columns to the expected binary baseline format\n    for expected_col, actual_col in domain_columns.items():\n        if actual_col in data.columns:\n            participant[expected_col] = row[actual_col]\n        else:\n            print(f\"Warning: Column {actual_col} not found in data\")\n    \n    participants_data.append(participant)\n\nprint(f\"Created {len(participants_data)} participant records\")\n\n# Show sample participant data\nprint(\"\\nSample participant data:\")\nfor i in range(min(3, len(participants_data))):\n    print(f\"Participant {i+1}: {participants_data[i]}\")\n\n# Generate binary personality descriptions\nprint(\"\\n=== GENERATING BINARY DESCRIPTIONS ===\")\nparticipants_with_binary = create_binary_participant_data(participants_data)\n\n# Display sample binary descriptions\nprint(\"\\nSample binary personality descriptions:\")\nfor i, p in enumerate(participants_with_binary[:2]):\n    print(f\"\\nParticipant {i+1}:\")\n    print(f\"Domain scores: E={p['bfi2_e']:.2f}, A={p['bfi2_a']:.2f}, C={p['bfi2_c']:.2f}, N={p['bfi2_n']:.2f}, O={p['bfi2_o']:.2f}\")\n    print(f\"Binary description: {p['binary_personality'][:200]}...\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape: (470, 704)\n",
      "Data shape after removing missing values: (438, 704)\n",
      "=== CREATING PARTICIPANT DATA ===\n",
      "Using BFI-2 format columns\n",
      "Created 438 participant records\n",
      "\n",
      "Sample participant data:\n",
      "Participant 1: {'participant_id': 0, 'bfi2_e': 4.083333333333333, 'bfi2_a': 4.583333333333333, 'bfi2_c': 3.1666666666666665, 'bfi2_n': 2.4166666666666665, 'bfi2_o': 3.1666666666666665}\n",
      "Participant 2: {'participant_id': 1, 'bfi2_e': 2.9166666666666665, 'bfi2_a': 3.1666666666666665, 'bfi2_c': 3.0, 'bfi2_n': 3.0, 'bfi2_o': 3.3333333333333335}\n",
      "Participant 3: {'participant_id': 2, 'bfi2_e': 2.0833333333333335, 'bfi2_a': 4.083333333333333, 'bfi2_c': 3.8333333333333335, 'bfi2_n': 3.1666666666666665, 'bfi2_o': 4.416666666666667}\n",
      "\n",
      "=== GENERATING BINARY DESCRIPTIONS ===\n",
      "\n",
      "Sample binary personality descriptions:\n",
      "\n",
      "Participant 1:\n",
      "Domain scores: E=4.08, A=4.58, C=3.17, N=2.42, O=3.17\n",
      "Binary description: You are high in Extraversion. You are outgoing, sociable, assertive, and energetic. You are high in Agreeableness. You are compassionate, cooperative, trusting, and kind to others. You are high in Con...\n",
      "\n",
      "Participant 2:\n",
      "Domain scores: E=2.92, A=3.17, C=3.00, N=3.00, O=3.33\n",
      "Binary description: You are high in Extraversion. You are outgoing, sociable, assertive, and energetic. You are high in Agreeableness. You are compassionate, cooperative, trusting, and kind to others. You are high in Con...\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T10:06:09.076668Z",
     "start_time": "2025-07-06T10:06:09.073515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configure simulation parameters\n",
    "print(\"=== SIMULATION CONFIGURATION ===\")\n",
    "\n",
    "# Models to test - using correct model names from portal.py\n",
    "models_to_test = [\n",
    "    'openai-gpt-3.5-turbo-0125',\n",
    "    \"gpt-4\",\n",
    "    \"gpt-4o\",\n",
    "    \"llama\",\n",
    "    \"deepseek\"\n",
    "]\n",
    "\n",
    "# Simulation parameters\n",
    "temperature = 1.0\n",
    "batch_size = 25  # Smaller batch size for stability across different APIs\n",
    "max_workers = 8\n",
    "\n",
    "print(f\"Models to test: {models_to_test}\")\n",
    "print(f\"Temperature: {temperature}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Max workers: {max_workers}\")\n",
    "\n",
    "print(f\"Using {len(participants_with_binary)} participants for simulation\")\n",
    "\n",
    "# Test the prompt generator with first participant\n",
    "if participants_with_binary:\n",
    "    sample_personality = participants_with_binary[0]['binary_personality']\n",
    "    sample_prompt = get_binary_prompt(sample_personality)\n",
    "    print(f\"\\nSample prompt length: {len(sample_prompt)} characters\")\n",
    "    print(\"Sample prompt preview:\")\n",
    "    print(sample_prompt)\n",
    "else:\n",
    "    print(\"No participants available for testing\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SIMULATION CONFIGURATION ===\n",
      "Models to test: ['openai-gpt-3.5-turbo-0125', 'llama']\n",
      "Temperature: 1.0\n",
      "Batch size: 25\n",
      "Max workers: 8\n",
      "Using 438 participants for simulation\n",
      "\n",
      "Sample prompt length: 2463 characters\n",
      "Sample prompt preview:\n",
      "### Your Assigned Personality ### \n",
      "Based on your personality profile below, please rate yourself on the following traits.\n",
      "You are high in Extraversion. You are outgoing, sociable, assertive, and energetic. You are high in Agreeableness. You are compassionate, cooperative, trusting, and kind to others. You are high in Conscientiousness. You are organized, responsible, hardworking, and reliable. You are low in Neuroticism. You are emotionally stable, calm, and resilient under stress. You are high in Openness. You are curious, creative, open to new experiences, and intellectually engaged.\n",
      "\n",
      "### Context and Objective ###\n",
      "You are participating in a study to help us understand human personality.\n",
      "\n",
      "Your job is to fill out a personality questionnaire below. Your questionnaire answers should be reflective of your assigned personalities.\n",
      "\n",
      "### Response Format ###\n",
      "IMPORTANT: You must provide ratings for ALL 40 traits listed below.\n",
      "Return ONLY a JSON object where:\n",
      "- Keys are the exact trait names (e.g., \"Bashful\", \"Bold\", etc.)\n",
      "- Values are numbers from 1-9 based on the rating scale\n",
      "- Include ALL 40 traits - no more, no less\n",
      "- Do NOT include personality domains like \"Extraversion\" or \"Agreeableness\"\n",
      "- Do NOT add any text outside the JSON\n",
      "\n",
      "Example format:\n",
      "{\n",
      "    \"Bashful\": 7,\n",
      "    \"Bold\": 3,\n",
      "    \"Careless\": 2,\n",
      "    ...\n",
      "    \"Withdrawn\": 4\n",
      "}\n",
      "\n",
      "### Questionnaire Instruction ###\n",
      "I will provide you a list of descriptive traits. For each trait, take a deep breath and think about what personality you are assigned with then, choose a number indicating how accurately that trait describes you. Using the following rating scale:\n",
      "1 - Extremely Inaccurate \n",
      "2 - Very Inaccurate\n",
      "3 - Moderately Inaccurate\n",
      "4 - Slightly Inaccurate\n",
      "5 - Neutral / Not Applicable\n",
      "6 - Slightly Accurate\n",
      "7 - Moderately Accurate\n",
      "8 - Very Accurate\n",
      "9 - Extremely Accurate\n",
      "\n",
      "### Questionnaire Item ###\n",
      "1. Bashful _\n",
      "2. Bold _\n",
      "3. Careless _\n",
      "4. Cold _\n",
      "5. Complex _\n",
      "6. Cooperative _\n",
      "7. Creative _\n",
      "8. Deep _\n",
      "9. Disorganized _\n",
      "10. Efficient _\n",
      "11. Energetic _\n",
      "12. Envious _\n",
      "13. Extraverted _\n",
      "14. Fretful _\n",
      "15. Harsh _\n",
      "16. Imaginative _\n",
      "17. Inefficient _\n",
      "18. Intellectual _\n",
      "19. Jealous _\n",
      "20. Kind _\n",
      "21. Moody _\n",
      "22. Organized _\n",
      "23. Philosophical _\n",
      "24. Practical _\n",
      "25. Quiet _\n",
      "26. Relaxed _\n",
      "27. Rude _\n",
      "28. Shy _\n",
      "29. Sloppy _\n",
      "30. Sympathetic _\n",
      "31. Systematic _\n",
      "32. Talkative _\n",
      "33. Temperamental _\n",
      "34. Touchy _\n",
      "35. Uncreative _\n",
      "36. Unenvious _\n",
      "37. Unintellectual _\n",
      "38. Unsympathetic _\n",
      "39. Warm _\n",
      "40. Withdrawn _\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T11:55:45.608484Z",
     "start_time": "2025-07-06T10:06:09.087334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import threading\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Thread-safe logging\n",
    "log_lock = threading.Lock()\n",
    "\n",
    "def safe_print(message, prefix=\"INFO\"):\n",
    "    \"\"\"Thread-safe printing with timestamp and prefix\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    with log_lock:\n",
    "        print(f\"[{timestamp}] {prefix}: {message}\")\n",
    "\n",
    "def run_simulation(model, temperature):\n",
    "    simulation_id = f\"{model}_temp{temperature}\"\n",
    "    \n",
    "    # Start message\n",
    "    safe_print(f\"Starting simulation: {model} (temp={temperature})\", \"START\")\n",
    "    \n",
    "    config = SimulationConfig(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        batch_size=batch_size,\n",
    "        max_workers=10,\n",
    "        max_retries=5,  # Enhanced retry logic\n",
    "        base_wait_time=2.0,\n",
    "        max_wait_time=60.0\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Use run_batch_simulation with the correct personality_key for binary format\n",
    "        results = run_batch_simulation(\n",
    "            participants_data=participants_with_binary,\n",
    "            prompt_generator=get_binary_prompt,\n",
    "            config=config,\n",
    "            personality_key='binary_personality',  # Correct key for binary format\n",
    "            # output_dir=\"study_2_binary_results\",\n",
    "            output_dir=\"study_2_elaborated_binary_results\",\n",
    "            output_filename=\"bfi_to_minimarker_binary\"\n",
    "        )\n",
    "        \n",
    "        # Check for failures\n",
    "        failed_count = sum(1 for r in results if isinstance(r, dict) and 'error' in r)\n",
    "        duration = time.time() - start_time\n",
    "        \n",
    "        if failed_count > 0:\n",
    "            safe_print(f\"Completed {simulation_id} in {duration:.1f}s - WARNING: {failed_count} participants failed\", \"WARN\")\n",
    "        else:\n",
    "            safe_print(f\"Completed {simulation_id} in {duration:.1f}s - All participants successful\", \"SUCCESS\")\n",
    "        \n",
    "        return (simulation_id, results)\n",
    "        \n",
    "    except Exception as e:\n",
    "        duration = time.time() - start_time\n",
    "        safe_print(f\"Failed {simulation_id} after {duration:.1f}s - Error: {str(e)}\", \"ERROR\")\n",
    "        return (simulation_id, {\"error\": str(e)})\n",
    "\n",
    "# Main execution\n",
    "print(\"=\"*80)\n",
    "print(\"STARTING ENHANCED BINARY BASELINE SIMULATIONS\")\n",
    "print(f\"Models: {models_to_test}\")\n",
    "print(f\"Temperature: {temperature}\")\n",
    "print(f\"Total models: {len(models_to_test)}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "all_results = {}\n",
    "start_time = time.time()\n",
    "\n",
    "# Use ThreadPoolExecutor for parallel execution\n",
    "with ThreadPoolExecutor(max_workers=len(models_to_test)) as executor:\n",
    "    # Submit all jobs\n",
    "    futures = [\n",
    "        executor.submit(run_simulation, model, temperature)\n",
    "        for model in models_to_test\n",
    "    ]\n",
    "    \n",
    "    # Collect results as they complete\n",
    "    completed_count = 0\n",
    "    total_jobs = len(futures)\n",
    "    \n",
    "    for future in as_completed(futures):\n",
    "        key, result = future.result()\n",
    "        all_results[key] = result\n",
    "        completed_count += 1\n",
    "        \n",
    "        # Progress update\n",
    "        safe_print(f\"Progress: {completed_count}/{total_jobs} simulations completed\", \"PROGRESS\")\n",
    "\n",
    "total_duration = time.time() - start_time\n",
    "\n",
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BINARY BASELINE SIMULATION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total time: {total_duration:.1f} seconds\")\n",
    "print(f\"Completed simulations: {len(all_results)}\")\n",
    "\n",
    "# Categorize results\n",
    "successful = []\n",
    "failed = []\n",
    "\n",
    "for key, result in all_results.items():\n",
    "    if isinstance(result, dict) and 'error' in result:\n",
    "        failed.append(key)\n",
    "    else:\n",
    "        # Check for partial failures\n",
    "        if isinstance(result, list):\n",
    "            failed_participants = sum(1 for r in result if isinstance(r, dict) and 'error' in r)\n",
    "            if failed_participants > 0:\n",
    "                print(f\"  {key}: SUCCESS (with {failed_participants} failed participants)\")\n",
    "            else:\n",
    "                print(f\"  {key}: SUCCESS\")\n",
    "            successful.append(key)\n",
    "        else:\n",
    "            successful.append(key)\n",
    "\n",
    "if failed:\n",
    "    print(f\"\\nFailed simulations ({len(failed)}):\")\n",
    "    for key in failed:\n",
    "        print(f\"  {key}: {all_results[key].get('error', 'Unknown error')}\")\n",
    "\n",
    "print(\"=\"*80)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STARTING ENHANCED BINARY BASELINE SIMULATIONS\n",
      "Models: ['openai-gpt-3.5-turbo-0125', 'llama']\n",
      "Temperature: 1.0\n",
      "Total models: 2\n",
      "================================================================================\n",
      "[18:06:09] START: Starting simulation: openai-gpt-3.5-turbo-0125 (temp=1.0)\n",
      "Starting simulation for 438 participants using openai-gpt-3.5-turbo-0125\n",
      "Temperature: 1.0, Batch size: 25\n",
      "Processing participants 0 to 24\n",
      "[18:06:09] START: Starting simulation: llama (temp=1.0)\n",
      "Starting simulation for 438 participants using llama\n",
      "Temperature: 1.0, Batch size: 25\n",
      "Processing participants 0 to 24\n",
      "Completed batch 0 to 24\n",
      "Processing participants 25 to 49\n",
      "Completed batch 25 to 49\n",
      "Processing participants 50 to 74\n",
      "Completed batch 50 to 74\n",
      "Processing participants 75 to 99\n",
      "Completed batch 75 to 99\n",
      "Processing participants 100 to 124\n",
      "Completed batch 100 to 124\n",
      "Processing participants 125 to 149\n",
      "Completed batch 125 to 149\n",
      "Processing participants 150 to 174\n",
      "Completed batch 150 to 174\n",
      "Processing participants 175 to 199\n",
      "Completed batch 175 to 199\n",
      "Processing participants 200 to 224\n",
      "Completed batch 200 to 224\n",
      "Completed batch 0 to 24\n",
      "Processing participants 225 to 249\n",
      "Processing participants 25 to 49\n",
      "Completed batch 225 to 249\n",
      "Processing participants 250 to 274\n",
      "Completed batch 250 to 274\n",
      "Processing participants 275 to 299\n",
      "Completed batch 275 to 299\n",
      "Processing participants 300 to 324\n",
      "Completed batch 300 to 324\n",
      "Processing participants 325 to 349\n",
      "Completed batch 325 to 349\n",
      "Processing participants 350 to 374\n",
      "Completed batch 350 to 374\n",
      "Processing participants 375 to 399\n",
      "Completed batch 375 to 399\n",
      "Processing participants 400 to 424\n",
      "Completed batch 400 to 424\n",
      "Processing participants 425 to 437\n",
      "Completed batch 425 to 437\n",
      "Results saved to study_2_binary_results/bfi_to_minimarker_binary_openai_gpt_3.5_turbo_0125_temp1_0.json\n",
      "[18:11:06] SUCCESS: Completed openai-gpt-3.5-turbo-0125_temp1.0 in 297.3s - All participants successful\n",
      "[18:11:06] PROGRESS: Progress: 1/2 simulations completed\n",
      "Completed batch 25 to 49\n",
      "Processing participants 50 to 74\n",
      "Completed batch 50 to 74\n",
      "Processing participants 75 to 99\n",
      "Llama error: HTTPSConnectionPool(host='allmodelapi3225011299.services.ai.azure.com', port=443): Read timed out. (read timeout=300)\n",
      "Error in get_personality_response: HTTPSConnectionPool(host='allmodelapi3225011299.services.ai.azure.com', port=443): Read timed out. (read timeout=300)\n",
      "Completed batch 75 to 99\n",
      "Processing participants 100 to 124\n",
      "Completed batch 100 to 124\n",
      "Processing participants 125 to 149\n",
      "Llama error: HTTPSConnectionPool(host='allmodelapi3225011299.services.ai.azure.com', port=443): Read timed out. (read timeout=300)\n",
      "Error in get_personality_response: HTTPSConnectionPool(host='allmodelapi3225011299.services.ai.azure.com', port=443): Read timed out. (read timeout=300)\n",
      "Llama error: HTTPSConnectionPool(host='allmodelapi3225011299.services.ai.azure.com', port=443): Read timed out. (read timeout=300)\n",
      "Error in get_personality_response: HTTPSConnectionPool(host='allmodelapi3225011299.services.ai.azure.com', port=443): Read timed out. (read timeout=300)\n",
      "Completed batch 125 to 149\n",
      "Processing participants 150 to 174\n",
      "Completed batch 150 to 174\n",
      "Processing participants 175 to 199\n",
      "Completed batch 175 to 199\n",
      "Processing participants 200 to 224\n",
      "Completed batch 200 to 224\n",
      "Processing participants 225 to 249\n",
      "Completed batch 225 to 249\n",
      "Processing participants 250 to 274\n",
      "Llama error: HTTPSConnectionPool(host='allmodelapi3225011299.services.ai.azure.com', port=443): Read timed out. (read timeout=300)\n",
      "Error in get_personality_response: HTTPSConnectionPool(host='allmodelapi3225011299.services.ai.azure.com', port=443): Read timed out. (read timeout=300)\n",
      "Llama error: HTTPSConnectionPool(host='allmodelapi3225011299.services.ai.azure.com', port=443): Read timed out. (read timeout=300)\n",
      "Error in get_personality_response: HTTPSConnectionPool(host='allmodelapi3225011299.services.ai.azure.com', port=443): Read timed out. (read timeout=300)\n",
      "Llama error: HTTPSConnectionPool(host='allmodelapi3225011299.services.ai.azure.com', port=443): Read timed out. (read timeout=300)\n",
      "Error in get_personality_response: HTTPSConnectionPool(host='allmodelapi3225011299.services.ai.azure.com', port=443): Read timed out. (read timeout=300)\n",
      "Completed batch 250 to 274\n",
      "Processing participants 275 to 299\n",
      "Llama error: HTTPSConnectionPool(host='allmodelapi3225011299.services.ai.azure.com', port=443): Read timed out. (read timeout=300)\n",
      "Error in get_personality_response: HTTPSConnectionPool(host='allmodelapi3225011299.services.ai.azure.com', port=443): Read timed out. (read timeout=300)\n",
      "Completed batch 275 to 299\n",
      "Processing participants 300 to 324\n",
      "Completed batch 300 to 324\n",
      "Processing participants 325 to 349\n",
      "Llama error: HTTPSConnectionPool(host='allmodelapi3225011299.services.ai.azure.com', port=443): Read timed out. (read timeout=300)\n",
      "Error in get_personality_response: HTTPSConnectionPool(host='allmodelapi3225011299.services.ai.azure.com', port=443): Read timed out. (read timeout=300)\n",
      "Llama error: HTTPSConnectionPool(host='allmodelapi3225011299.services.ai.azure.com', port=443): Read timed out. (read timeout=300)\n",
      "Error in get_personality_response: HTTPSConnectionPool(host='allmodelapi3225011299.services.ai.azure.com', port=443): Read timed out. (read timeout=300)\n",
      "Llama error: HTTPSConnectionPool(host='allmodelapi3225011299.services.ai.azure.com', port=443): Read timed out. (read timeout=300)\n",
      "Error in get_personality_response: HTTPSConnectionPool(host='allmodelapi3225011299.services.ai.azure.com', port=443): Read timed out. (read timeout=300)\n",
      "Completed batch 325 to 349\n",
      "Processing participants 350 to 374\n",
      "Completed batch 350 to 374\n",
      "Processing participants 375 to 399\n",
      "Llama error: <urllib3.connection.HTTPSConnection object at 0x32da42ef0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not knownLlama error: <urllib3.connection.HTTPSConnection object at 0x32e907eb0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x32e907eb0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Llama error: <urllib3.connection.HTTPSConnection object at 0x32e1ff160>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x32e1ff160>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Llama error: <urllib3.connection.HTTPSConnection object at 0x316f0c910>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x316f0c910>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x32da42ef0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Llama error: <urllib3.connection.HTTPSConnection object at 0x316f0f790>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x316f0f790>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Llama error: <urllib3.connection.HTTPSConnection object at 0x316f0ca90>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x316f0ca90>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Llama error: <urllib3.connection.HTTPSConnection object at 0x316f0f5b0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x316f0f5b0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Llama error: <urllib3.connection.HTTPSConnection object at 0x32e123dc0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x32e123dc0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Llama error: <urllib3.connection.HTTPSConnection object at 0x32da74550>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x32da74550>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Llama error: <urllib3.connection.HTTPSConnection object at 0x32da75270>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x32da75270>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Llama error: <urllib3.connection.HTTPSConnection object at 0x32da42320>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not knownLlama error: <urllib3.connection.HTTPSConnection object at 0x32e13baf0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x32e13baf0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Llama error: <urllib3.connection.HTTPSConnection object at 0x32da42e00>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x32da42e00>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x32da42320>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Llama error: <urllib3.connection.HTTPSConnection object at 0x32da41570>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x32da41570>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Llama error: <urllib3.connection.HTTPSConnection object at 0x32da42200>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x32da42200>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Llama error: <urllib3.connection.HTTPSConnection object at 0x32e120be0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x32e120be0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Llama error: <urllib3.connection.HTTPSConnection object at 0x32da423b0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x32da423b0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Llama error: <urllib3.connection.HTTPSConnection object at 0x32da42ef0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x32da42ef0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Llama error: <urllib3.connection.HTTPSConnection object at 0x32e123e80>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x32e123e80>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Llama error: <urllib3.connection.HTTPSConnection object at 0x32e13bee0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x32e13bee0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Llama error: <urllib3.connection.HTTPSConnection object at 0x316f0f400>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x316f0f400>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Llama error: <urllib3.connection.HTTPSConnection object at 0x316f0e770>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x316f0e770>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Llama error: <urllib3.connection.HTTPSConnection object at 0x32e1069e0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x32e1069e0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Llama error: <urllib3.connection.HTTPSConnection object at 0x316f0f970>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x316f0f970>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Llama error: <urllib3.connection.HTTPSConnection object at 0x32e106b90>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x32e106b90>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Llama error: <urllib3.connection.HTTPSConnection object at 0x316f0f310>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x316f0f310>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Llama error: <urllib3.connection.HTTPSConnection object at 0x32f061510>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x32f061510>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Llama error: <urllib3.connection.HTTPSConnection object at 0x32f063df0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x32f063df0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Llama error: <urllib3.connection.HTTPSConnection object at 0x32f061600>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x32f061600>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Llama error: <urllib3.connection.HTTPSConnection object at 0x32f063c10>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x32f063c10>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Llama error: <urllib3.connection.HTTPSConnection object at 0x32da763e0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not knownLlama error: <urllib3.connection.HTTPSConnection object at 0x32e189360>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x32e189360>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Llama error: <urllib3.connection.HTTPSConnection object at 0x32f0bacb0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x32f0bacb0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Llama error: <urllib3.connection.HTTPSConnection object at 0x32e9ec040>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x32e9ec040>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Llama error: <urllib3.connection.HTTPSConnection object at 0x32e10cfa0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x32e10cfa0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Llama error: <urllib3.connection.HTTPSConnection object at 0x32f0bbfa0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x32f0bbfa0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Llama error: <urllib3.connection.HTTPSConnection object at 0x32e10c940>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x32e10c940>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x32da763e0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Llama error: <urllib3.connection.HTTPSConnection object at 0x32e189270>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x32e189270>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Llama error: <urllib3.connection.HTTPSConnection object at 0x32f0baa70>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x32f0baa70>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Llama error: <urllib3.connection.HTTPSConnection object at 0x3111b2c20>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Error in get_personality_response: <urllib3.connection.HTTPSConnection object at 0x3111b2c20>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "Llama error: HTTPSConnectionPool(host='allmodelapi3225011299.services.ai.azure.com', port=443): Read timed out. (read timeout=300)\n",
      "Error in get_personality_response: HTTPSConnectionPool(host='allmodelapi3225011299.services.ai.azure.com', port=443): Read timed out. (read timeout=300)\n",
      "Completed batch 375 to 399\n",
      "Processing participants 400 to 424\n",
      "Completed batch 400 to 424\n",
      "Processing participants 425 to 437\n",
      "Completed batch 425 to 437\n",
      "Results saved to study_2_binary_results/bfi_to_minimarker_binary_llama_temp1_0.json\n",
      "[19:55:45] SUCCESS: Completed llama_temp1.0 in 6576.5s - All participants successful\n",
      "[19:55:45] PROGRESS: Progress: 2/2 simulations completed\n",
      "\n",
      "================================================================================\n",
      "BINARY BASELINE SIMULATION SUMMARY\n",
      "================================================================================\n",
      "Total time: 6576.5 seconds\n",
      "Completed simulations: 2\n",
      "  openai-gpt-3.5-turbo-0125_temp1.0: SUCCESS\n",
      "  llama_temp1.0: SUCCESS\n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
