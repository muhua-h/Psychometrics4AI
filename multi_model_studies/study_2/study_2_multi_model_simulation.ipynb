{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Model Personality Simulation - Study 2\n",
    "\n",
    "This notebook refactors the original Study 2 BFI-2 to Mini-Marker simulation to work with multiple LLM models using the unified portal.py interface.\n",
    "\n",
    "## Models to Test\n",
    "- GPT-4\n",
    "- GPT-4o  \n",
    "- Llama-3.3-70B-Instruct\n",
    "- DeepSeek-V3\n",
    "\n",
    "## Data Flow\n",
    "1. Load and preprocess Soto BFI-2 data\n",
    "2. Apply reverse coding to personality items\n",
    "3. Map numeric responses to expanded format descriptions\n",
    "4. Generate personality simulation prompts\n",
    "5. Run simulations across multiple models\n",
    "6. Save results for analysis\n",
    "\n",
    "## Next Steps\n",
    "After running this notebook, use `study_2_analysis.ipynb` for comprehensive analysis of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add shared modules to path\n",
    "sys.path.append('../shared')\n",
    "\n",
    "from simulation_utils import (\n",
    "    SimulationConfig, \n",
    "    run_bfi_to_minimarker_simulation,\n",
    "    retry_failed_participants\n",
    ")\n",
    "from schema_bfi2 import expanded_scale\n",
    "from mini_marker_prompt import get_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Soto BFI-2 dataset\n",
    "data_path = Path('../../raw_data/Soto_data.xlsx')\n",
    "if not data_path.exists():\n",
    "    print(f\"Data file not found at {data_path}\")\n",
    "    print(\"Please ensure the raw_data/Soto_data.xlsx file exists in the project root\")\n",
    "    raise FileNotFoundError(f\"Data file not found: {data_path}\")\n",
    "\n",
    "data = pd.read_excel(data_path, sheet_name='data')\n",
    "print(f\"Loaded data shape: {data.shape}\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate column names for TDA (Mini-Marker) and BFI-2 items\n",
    "tda_columns = [f\"tda{i}\" for i in range(1, 41)]\n",
    "sbfi_columns = [f\"bfi{i}\" for i in range(1, 61)]\n",
    "selected_columns = tda_columns + sbfi_columns\n",
    "\n",
    "print(f\"Original data shape: {data.shape}\")\n",
    "\n",
    "# Remove rows with missing values in the selected columns\n",
    "data = data.dropna(subset=selected_columns)\n",
    "print(f\"Data shape after removing missing values: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse coding map for BFI-2 items\n",
    "reverse_coding_map = {\n",
    "    'bfi1': 'bfi1', 'bfi2': 'bfi2', 'bfi3': 'bfi3R', 'bfi4': 'bfi4R', 'bfi5': 'bfi5R',\n",
    "    'bfi6': 'bfi6', 'bfi7': 'bfi7', 'bfi8': 'bfi8R', 'bfi9': 'bfi9R', 'bfi10': 'bfi10',\n",
    "    'bfi11': 'bfi11R', 'bfi12': 'bfi12R', 'bfi13': 'bfi13', 'bfi14': 'bfi14', 'bfi15': 'bfi15',\n",
    "    'bfi16': 'bfi16R', 'bfi17': 'bfi17R', 'bfi18': 'bfi18', 'bfi19': 'bfi19', 'bfi20': 'bfi20',\n",
    "    'bfi21': 'bfi21', 'bfi22': 'bfi22R', 'bfi23': 'bfi23R', 'bfi24': 'bfi24R', 'bfi25': 'bfi25R',\n",
    "    'bfi26': 'bfi26R', 'bfi27': 'bfi27', 'bfi28': 'bfi28R', 'bfi29': 'bfi29R', 'bfi30': 'bfi30R',\n",
    "    'bfi31': 'bfi31R', 'bfi32': 'bfi32', 'bfi33': 'bfi33', 'bfi34': 'bfi34', 'bfi35': 'bfi35',\n",
    "    'bfi36': 'bfi36R', 'bfi37': 'bfi37R', 'bfi38': 'bfi38', 'bfi39': 'bfi39', 'bfi40': 'bfi40',\n",
    "    'bfi41': 'bfi41', 'bfi42': 'bfi42R', 'bfi43': 'bfi43', 'bfi44': 'bfi44R', 'bfi45': 'bfi45R',\n",
    "    'bfi46': 'bfi46', 'bfi47': 'bfi47R', 'bfi48': 'bfi48R', 'bfi49': 'bfi49R', 'bfi50': 'bfi50R',\n",
    "    'bfi51': 'bfi51R', 'bfi52': 'bfi52', 'bfi53': 'bfi53', 'bfi54': 'bfi54', 'bfi55': 'bfi55R',\n",
    "    'bfi56': 'bfi56', 'bfi57': 'bfi57', 'bfi58': 'bfi58R', 'bfi59': 'bfi59', 'bfi60': 'bfi60'\n",
    "}\n",
    "\n",
    "# Apply reverse coding\n",
    "for key, value in reverse_coding_map.items():\n",
    "    if value.endswith('R'):  # Reverse coded\n",
    "        data[key] = 6 - data[key]\n",
    "    # else: keep original value\n",
    "\n",
    "print(\"Reverse coding applied successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map numeric values to expanded format descriptions\n",
    "def map_values(row):\n",
    "    mapped_row = row.copy()\n",
    "    for key in expanded_scale:\n",
    "        if pd.notna(row[key]):  # Check if the value is not NaN\n",
    "            index = int(row[key]) - 1  # Convert to 0-index\n",
    "            mapped_row[key] = expanded_scale[key][index]  # Replace with corresponding string\n",
    "    return mapped_row\n",
    "\n",
    "# Apply mapping to BFI columns\n",
    "mapped_data = data[sbfi_columns].apply(map_values, axis=1)\n",
    "\n",
    "# Create combined BFI-2 description\n",
    "mapped_data['combined_bfi2'] = mapped_data[[f'bfi{i}' for i in range(1, 61)]].apply(\n",
    "    lambda row: ' '.join(row), axis=1\n",
    ")\n",
    "\n",
    "# Add combined description to original data\n",
    "data['combined_bfi2'] = mapped_data['combined_bfi2']\n",
    "\n",
    "print(\"Personality descriptions created successfully\")\n",
    "print(f\"Final data shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview a personality description\n",
    "print(\"Sample personality description:\")\n",
    "print(data.iloc[0]['combined_bfi2'][:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Model Simulation Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for different models and temperatures\n",
    "models_to_test = ['gpt-4', 'gpt-4o', 'llama', 'deepseek']\n",
    "temperatures = [0.0, 1.0]  # Test both deterministic and stochastic responses\n",
    "batch_size = 25  # Smaller batch size for stability across different APIs\n",
    "\n",
    "# Create participant data list from DataFrame\n",
    "participants_data = data.to_dict('records')\n",
    "print(f\"Prepared {len(participants_data)} participants for simulation\")\n",
    "\n",
    "# For testing: uncomment these lines to use a subset\n",
    "# models_to_test = ['deepseek']\n",
    "# participants_data = participants_data[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Simulations for All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run simulations for all model-temperature combinations\n",
    "all_results = {}\n",
    "\n",
    "for model in models_to_test:\n",
    "    for temperature in temperatures:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Starting simulation: {model} with temperature {temperature}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        config = SimulationConfig(\n",
    "            model=model,\n",
    "            temperature=temperature,\n",
    "            batch_size=batch_size,\n",
    "            max_workers=10\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            results = run_bfi_to_minimarker_simulation(\n",
    "                participants_data=participants_data,\n",
    "                config=config,\n",
    "                output_dir=\"study_2_results\"\n",
    "            )\n",
    "            \n",
    "            # Store results\n",
    "            key = f\"{model}_temp{temperature}\"\n",
    "            all_results[key] = results\n",
    "            \n",
    "            # Check for any failed participants\n",
    "            failed_count = sum(1 for r in results if isinstance(r, dict) and 'error' in r)\n",
    "            if failed_count > 0:\n",
    "                print(f\"Warning: {failed_count} participants failed. Consider retrying.\")\n",
    "                \n",
    "            print(f\"Completed simulation: {model} with temperature {temperature}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in simulation {model} temp {temperature}: {str(e)}\")\n",
    "            all_results[f\"{model}_temp{temperature}\"] = {\"error\": str(e)}\n",
    "\n",
    "print(f\"\\nCompleted all simulations. Results keys: {list(all_results.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retry Failed Participants (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retry any failed participants\n",
    "for key, results in all_results.items():\n",
    "    if isinstance(results, list):\n",
    "        failed_count = sum(1 for r in results if isinstance(r, dict) and 'error' in r)\n",
    "        if failed_count > 0:\n",
    "            print(f\"Retrying {failed_count} failed participants for {key}\")\n",
    "            \n",
    "            # Extract model and temperature from key\n",
    "            model = key.split('_temp')[0]\n",
    "            temperature = float(key.split('_temp')[1])\n",
    "            \n",
    "            config = SimulationConfig(\n",
    "                model=model,\n",
    "                temperature=temperature,\n",
    "                batch_size=batch_size\n",
    "            )\n",
    "            \n",
    "            updated_results = retry_failed_participants(\n",
    "                results=results,\n",
    "                participants_data=participants_data,\n",
    "                prompt_generator=get_prompt,  # Use imported get_prompt function\n",
    "                config=config,\n",
    "                personality_key='combined_bfi2'\n",
    "            )\n",
    "            \n",
    "            all_results[key] = updated_results\n",
    "            \n",
    "            # Save updated results\n",
    "            from simulation_utils import save_simulation_results\n",
    "            save_simulation_results(updated_results, \"study_2_results\", \"bfi_to_minimarker_retried\", config)\n",
    "\n",
    "print(\"Retry process completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze results summary\n",
    "print(\"Simulation Results Summary:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for key, results in all_results.items():\n",
    "    if isinstance(results, list):\n",
    "        total_participants = len(results)\n",
    "        successful = sum(1 for r in results if not (isinstance(r, dict) and 'error' in r))\n",
    "        failed = total_participants - successful\n",
    "        success_rate = (successful / total_participants) * 100\n",
    "        \n",
    "        print(f\"{key}:\")\n",
    "        print(f\"  Total: {total_participants}, Successful: {successful}, Failed: {failed}\")\n",
    "        print(f\"  Success Rate: {success_rate:.1f}%\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"{key}: FAILED - {results.get('error', 'Unknown error')}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the preprocessed data for reference\n",
    "output_path = Path('study_2_results')\n",
    "output_path.mkdir(exist_ok=True)\n",
    "\n",
    "data.to_csv(output_path / 'study2_preprocessed_data.csv', index=False)\n",
    "print(f\"Preprocessed data saved to {output_path / 'study2_preprocessed_data.csv'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SIMULATION COMPLETE!\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Run study_2_analysis.ipynb for comprehensive analysis\")\n",
    "print(\"2. Results are saved in study_2_results/ directory\")\n",
    "print(\"3. Preprocessed data available for validation\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}